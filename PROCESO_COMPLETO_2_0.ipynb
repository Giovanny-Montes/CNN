{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "j0rXUDaBFmgB",
        "outputId": "53c5c0ed-cb7e-45c9-acf3-0673ce14c785"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n'''\\n       COLEGIO DE POSTGRADUADOS\\n          CAMPUS MONTECILLO\\n\\nPOSGRADO EN SOCIOECONOMÍA, ESTADÍSTICA E\\n             INFORMÁTICA\\n          CÓMPUTO APLICADO\\n\\nAUTOR: GIOVANNY MONTES RODRIGUEZ\\nCOLABORADOR: DR. JUAN MANUEL GONZÁLEZ CAMACHO\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "'''\n",
        "       COLEGIO DE POSTGRADUADOS\n",
        "          CAMPUS MONTECILLO\n",
        "\n",
        "POSGRADO EN SOCIOECONOMÍA, ESTADÍSTICA E\n",
        "             INFORMÁTICA\n",
        "          CÓMPUTO APLICADO\n",
        "\n",
        "AUTOR: GIOVANNY MONTES RODRIGUEZ\n",
        "COLABORADOR: DR. JUAN MANUEL GONZÁLEZ CAMACHO\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "5ufcf5mqG-H8",
        "outputId": "380e300c-31ab-4132-f8be-cdbb6d94f66c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nEl presente documento contiene todas las etapas para la implementacion de redes neuronales convolucionales CNN Estandar, CNN-VGG16 y CNN-MobileNetV2\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "\"\"\"\n",
        "El presente documento contiene todas las etapas para la implementacion de redes neuronales convolucionales CNN Estandar, CNN-VGG16 y CNN-MobileNetV2\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43ssF9E5I-lc"
      },
      "outputs": [],
      "source": [
        "#DESCARGA DE IMAGENES\n",
        "\n",
        "\"\"\"\n",
        "Descargaremos el dataset y utilizaremos solo las carpetas TRAIN,TEST y VALIDATION(las otras carpetas tiene imagenes repetidas)\n",
        "Cada imágen será introducida en una nueva carpeta del mismo nombre, mientras las otras clases serán ignoradas.\n",
        "Afzaal, U.; Bhattarai, B.; Pandeya, Y.R.; Lee, J. An Instance Segmentation Model for Strawberry Diseases Based on Mask R-CNN. Sensors 2021, 21, 6565.\n",
        "URL:https://www.kaggle.com/datasets/usmanafzaal/strawberry-disease-detection-dataset?resource=download\n",
        "\n",
        "TOTAL DE IMÁGENES POR CARPETA:\n",
        "angular_leafspot:435\n",
        "leaf_spot:615\n",
        "mildew _leaf:533\n",
        "\n",
        "Descargaremos el dataset de  Plantvillage para la clase hojas de fresa sana:\n",
        "Hughes, D. P., & Salathé, M. (2015). An open access repository of images on plant health to enable the development of mobile disease diagnostics. ArXiv. doi: 10.48550/arXiv.1511.08060\n",
        "URL:https://www.kaggle.com/datasets/abdallahalidev/plantvillage-dataset\n",
        "\n",
        "TOTAL DE IMÁGENES POR CARPETA:\n",
        "healthy_leaf:450\n",
        "\n",
        "Tendremos 4 carpetas con el nombre de las clases y dentro las imágenes correspondientes\n",
        "CARPETA BASE/\n",
        "----------->/angular_leafspot/\n",
        "----------->/leaf_spot/\n",
        "----------->/mildew _leaf/\n",
        "----------->/hojas_sanas/\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZ18KspmgWeI"
      },
      "outputs": [],
      "source": [
        "#librerias que usaremos:\n",
        "import os, shutil, cv2, numpy as np, tensorflow as tf, keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, models, utils\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from keras import Input, optimizers, activations\n",
        "from google.colab import drive, auth\n",
        "import seaborn as sns, matplotlib.pyplot as plt, statistics\n",
        "import time as g\n",
        "from keras.applications import vgg16 as vgg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"AUÍ DEFINIMOS EL TAMAÑO DE IMÁGEN CON EL QUE TRABAJAREMOS\"\"\"\n",
        "dst_size = (224, 224) #Tamaño estandar de entrada para MoibleNetV2: 224 x 224 PIXELES"
      ],
      "metadata": {
        "id": "HUuUN-QHpVgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directorio de origen de las imágenes\n",
        "src_directory = r\"/content/drive/MyDrive/CARPETA BASE\"\n",
        "\n",
        "# Directorio de destino\n",
        "dst_directory =r\"/content/drive/MyDrive/CARPETA BASE/TAM224x224\""
      ],
      "metadata": {
        "id": "JTbWd-Sb_TO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#EL PROPOSITO DE ESTE BLOQUE ES TOMAR TODOS LOS ARCHIVOS Y RENOMBRARLOS CON TERMINACIÓN JPG\n",
        "#ADEMAS DE TENERLOS ORDENADOS, EN EL PASO SIGUIENTE SERAN GUARDADOS EN EL MISMO FORMATO\n",
        "def renombrar(ruta, nombre):\n",
        "    contador = 1\n",
        "    lista = os.listdir(ruta)\n",
        "    for i in lista:\n",
        "        if i.endswith('.jpg') or i.endswith('.jpeg') or i.endswith('.png'):  # Verifica que el archivo tenga extensión .jpg\n",
        "            nuevo_nombre = os.path.join(ruta, \"{}{}.jpg\".format(nombre, contador))\n",
        "            while os.path.exists(nuevo_nombre):\n",
        "                contador += 1\n",
        "                nuevo_nombre = os.path.join(ruta, \"{}{}.jpg\".format(nombre, contador))\n",
        "            os.rename(os.path.join(ruta, i), nuevo_nombre)\n",
        "            contador += 1\n",
        "    return \"Archivos renombrados: {}\".format(nombre)\n",
        "\n",
        "carpeta_base = src_directory #Qué carpeta analizaremos?\n",
        "nombres_carpetas = os.listdir(carpeta_base)\n",
        "\n",
        "for s in nombres_carpetas:\n",
        "    ruta_carpeta = os.path.join(carpeta_base, s)\n",
        "    if os.path.isdir(ruta_carpeta):\n",
        "        print(renombrar(ruta_carpeta, s))"
      ],
      "metadata": {
        "id": "yHUoHuVAmPS6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6771355b-02b6-4458-f37d-f387d1e8c9cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivos renombrados: hojas_sanas\n",
            "Archivos renombrados: angular_leafspot\n",
            "Archivos renombrados: leaf_spot\n",
            "Archivos renombrados: powdery_mildew\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "REDIMENSIONAR TODAS LAS IMÁGENES A 224X224"
      ],
      "metadata": {
        "id": "HzOWloS3l-vr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creamos las mismas carpetas en el destino\n",
        "lista_carpetas_destino=[]\n",
        "subcarpetas_carpeta_original= os.listdir(src_directory)\n",
        "if not os.path.exists(dst_directory):\n",
        "    os.makedirs(dst_directory)\n",
        "\n",
        "for carpetas in subcarpetas_carpeta_original:\n",
        "    nueva_carpeta=os.path.join(dst_directory,carpetas)\n",
        "    if not os.path.exists(nueva_carpeta):\n",
        "        os.makedirs(nueva_carpeta)\n",
        "    lista_carpetas_destino.append(nueva_carpeta)\n",
        "\n",
        "\n",
        "# Recorremos las imágenes en el directorio\n",
        "for carpetas_origen in subcarpetas_carpeta_original:#tengo los nombres de carpetas\n",
        "    ruta=os.path.join(src_directory,carpetas_origen)\n",
        "    for filename in os.listdir(ruta):# por cada archivo dentro de la carpeta#nombres_archivo_por_carpeta\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\") or filename.endswith(\".png\"):\n",
        "            # Leemos la imagen\n",
        "\n",
        "            src = cv2.imread(os.path.join(ruta, filename))\n",
        "\n",
        "            # Redimensionamos la imagen\n",
        "            dst = cv2.resize(src, dst_size)\n",
        "\n",
        "            # Construimos el nombre de archivo de destino\n",
        "            dst_filename1 = os.path.join(dst_directory, carpetas_origen)\n",
        "            dst_filename2 = os.path.join(dst_filename1, filename)\n",
        "            # Guardamos la imagen redimensionada\n",
        "            cv2.imwrite(dst_filename2, dst)"
      ],
      "metadata": {
        "id": "9Psa8bGaf9o6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2KcWe6osK8YM"
      },
      "outputs": [],
      "source": [
        "#FUNCION PARA EXPLORAR LAS CARPETAS Y CONTAR LOS ARCHIVOS POR CARPETA\n",
        "indent_level = 0\n",
        "def count_files_in_directory(path):\n",
        "    count = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(path):\n",
        "        count += len(filenames)\n",
        "    return count\n",
        "\n",
        "\n",
        "def print_directory_tree(path):\n",
        "    global indent_level\n",
        "    dirnames = [child for child in os.listdir(path) if os.path.isdir(os.path.join(path, child))]\n",
        "    for child in os.listdir(path):\n",
        "        child_path = os.path.join(path, child)\n",
        "        if os.path.isdir(child_path):\n",
        "            print(\" \" * indent_level + child + \"/\")\n",
        "            indent_level += 4\n",
        "            print_directory_tree(child_path)\n",
        "            indent_level -= 4\n",
        "\n",
        "    if not dirnames:\n",
        "        print(\" \" * indent_level + \"Numero de Archivos:{}\".format(count_files_in_directory(path)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Árbol de directorios:\")\n",
        "print_directory_tree(dst_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJKROBVO-KIX",
        "outputId": "fd78a797-5565-4e1f-de72-756d800fa68f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Árbol de directorios:\n",
            "hojas_sanas/\n",
            "    Numero de Archivos:874\n",
            "angular_leafspot/\n",
            "    Numero de Archivos:541\n",
            "leaf_spot/\n",
            "    Numero de Archivos:650\n",
            "powdery_mildew/\n",
            "    Numero de Archivos:558\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#FUNCION PARA COPIAR LOS ARCHIVOS A SU RESPECTIVA CARPETA MANTENIENDO UNA DISTRIBUCIÓN EQUITATIVA ENTRE TRAIN, VALIDATION Y TEST\n",
        "\"\"\"Comienza bloque de creación de carpetas\"\"\"\n",
        "#Creamos las 3 carpetas principales: TRAIN VALIDATION Y TEST\n",
        "\n",
        "particion=0.8 #80% de los datos para TRAIN\n",
        "division=[\"TRAIN\",\"TEST\",\"VALIDATION\"]\n",
        "\n",
        "\n",
        "base_dir=r\"/content/drive/MyDrive/CARPETA BASE/PRUEBA\"\n",
        "if not os.path.exists(base_dir):\n",
        "  os.mkdir(base_dir)\n",
        "src_directory=\"/content/drive/MyDrive/CARPETA BASE/TAM224x224\"\n",
        "nombres_carpetas=os.listdir(src_directory)\n",
        "\n",
        "lista_elementos=np.arange(4, dtype=object)#AREMOS UNA LISTA DE LISTAS CON RUTAS DE LOS ARCHIVOS\n",
        "\n",
        "\n",
        "for i in division:\n",
        "  b=0\n",
        "  dir = os.path.join(base_dir, i)\n",
        "  os.mkdir(dir)\n",
        "  for j in nombres_carpetas:\n",
        "    dir_class=os.path.join(dir,j)\n",
        "    os.mkdir(dir_class)#hasta aqui he creado la carpeta de la clase dentro de \"TRAIN\"\n",
        "\n",
        "    if i==\"TRAIN\":\n",
        "      origin=os.path.join(src_directory,j)\n",
        "      lista_elementos[b]=os.listdir(origin)#obteniendo la lista de elementos por carpeta desde TAM224x224\n",
        "      fnames = np.random.choice(lista_elementos[b], replace=False, size=round(len(lista_elementos[b])*particion))#copiaremos el 80% de las imágenes de cada carpeta y las meteremos a su destino\n",
        "      for fname in fnames:\n",
        "          src = os.path.join(origin, fname)\n",
        "          dst = os.path.join(dir_class, fname)\n",
        "          shutil.copyfile(src, dst)\n",
        "      #acabando de copiar los archivos, quitaremos de la lista los que ya usamos y los restantes serán distribuidos en las carpetas restantes\n",
        "      lista_elementos[b] = np.setdiff1d(lista_elementos[b], fnames)\n",
        "\n",
        "    if i==\"TEST\":\n",
        "      #fnames contiene 10% de las imágenes  de forma aleatoria obtenidas en el paso anterior\n",
        "      origin=os.path.join(src_directory,j)\n",
        "      fnames = np.random.choice(lista_elementos[b], replace=False, size=round(len(lista_elementos[b])*.5))\n",
        "      for fname in fnames:\n",
        "          src = os.path.join(origin, fname)\n",
        "          dst = os.path.join(dir_class, fname)\n",
        "          shutil.copyfile(src, dst)\n",
        "      #acabando de copiar los archivos, quitaremos de la lista los que ya usamos y los restantes serán distribuidos en las carpetas restantes\n",
        "      lista_elementos[b] = np.setdiff1d(lista_elementos[b], fnames)\n",
        "\n",
        "    if i==\"VALIDATION\":\n",
        "      origin=os.path.join(src_directory,j)\n",
        "      #fnames contiene 10% de las imágenes  de forma aleatoria obtenidas en el paso anterior\n",
        "      fnames = lista_elementos[b]\n",
        "      for fname in fnames:\n",
        "          src = os.path.join(origin, fname)\n",
        "          dst = os.path.join(dir_class, fname)\n",
        "          shutil.copyfile(src, dst)\n",
        "\n",
        "    b+=1"
      ],
      "metadata": {
        "id": "2TFmvslIajG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#CONTAMOS LOS ARCHIVOS EN EL DIRECTORIO DE DESTINO PARA VERIFICAR QUE ESTÉ CORRECTO\n",
        "print_directory_tree(base_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7Hpzb9C0k_S",
        "outputId": "eb070134-2232-47d0-b768-fd64c558ad9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN/\n",
            "    hojas_sanas/\n",
            "        Numero de Archivos:699\n",
            "    angular_leafspot/\n",
            "        Numero de Archivos:433\n",
            "    leaf_spot/\n",
            "        Numero de Archivos:520\n",
            "    powdery_mildew/\n",
            "        Numero de Archivos:446\n",
            "TEST/\n",
            "    hojas_sanas/\n",
            "        Numero de Archivos:88\n",
            "    angular_leafspot/\n",
            "        Numero de Archivos:54\n",
            "    leaf_spot/\n",
            "        Numero de Archivos:65\n",
            "    powdery_mildew/\n",
            "        Numero de Archivos:56\n",
            "VALIDATION/\n",
            "    hojas_sanas/\n",
            "        Numero de Archivos:87\n",
            "    angular_leafspot/\n",
            "        Numero de Archivos:54\n",
            "    leaf_spot/\n",
            "        Numero de Archivos:65\n",
            "    powdery_mildew/\n",
            "        Numero de Archivos:56\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AUMENTANDO LA BASE DE DATOS"
      ],
      "metadata": {
        "id": "nWEvpCDm-BAl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54f8a5a4-9161-4c15-e614-0e97f3f57802",
        "id": "DKQ_CnW1Lc8w"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 699 images belonging to 1 classes.\n",
            "Found 433 images belonging to 1 classes.\n",
            "Found 520 images belonging to 1 classes.\n",
            "Found 446 images belonging to 1 classes.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"Aumentaremos 4 veces la base de entrenamiento mediante trasformaciones\"\"\"\n",
        "\n",
        "#la carpeta donde están las carpetas del proceso anterior están en base_dir\n",
        "train_dir = base_dir+'/TRAIN'\n",
        "\n",
        "\"\"\"Definimos las transformaciones que llevaremos a cabo\"\"\"\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,           #transformacion de escala\n",
        "    rotation_range=25,        #Angulo de rotación\n",
        "    width_shift_range=0.2,    #Traslación Orizontal\n",
        "    height_shift_range=0.2,   #Traslación Vertical\n",
        "    shear_range=0.2,          #Distorción\n",
        "    zoom_range=0.2,           #Zoom o acercamiento\n",
        "    horizontal_flip=True,     #Volteado Horizontal\n",
        "    brightness_range=(0.5,2), #Rango de brillo; 1=sin_cambio, 1.5=brilloso, 0.5=Obscuro\n",
        "    vertical_flip=True)       #Volteado Vertical\n",
        "\n",
        "# Crear un generador de datos para cada subcarpeta\n",
        "for subdir in os.listdir(train_dir):\n",
        "    subdir_path = os.path.join(train_dir, subdir)\n",
        "    if os.path.isdir(subdir_path):\n",
        "        generator = datagen.flow_from_directory(\n",
        "            train_dir,\n",
        "            target_size=dst_size,\n",
        "            color_mode=\"rgb\",\n",
        "            #Si la clases no están balanceadas lo dejamos así. y si están balanceadas podemos cambiarlo por: rango_train\n",
        "            batch_size=len(os.listdir(subdir_path)),\n",
        "            save_to_dir=subdir_path,\n",
        "            save_prefix='aumentado',\n",
        "            classes=[subdir],\n",
        "            class_mode=\"categorical\",\n",
        "            save_format=\"jpg\",)\n",
        "            #si tomamos el número total de imágenes y la procesamos 4 veces , es decir habremos generado 4 transformaciones por cada imagen\n",
        "        for i in range(4):\n",
        "            generator.next()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Imágenes de TRAIN despues del aumento:\")\n",
        "print_directory_tree(train_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qVPkibzfvb6",
        "outputId": "2a0e8733-5cab-4934-9b2f-02d53223d786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imágenes de TRAIN despues del aumento:\n",
            "hojas_sanas/\n",
            "    Numero de Archivos:3495\n",
            "angular_leafspot/\n",
            "    Numero de Archivos:2165\n",
            "leaf_spot/\n",
            "    Numero de Archivos:2600\n",
            "powdery_mildew/\n",
            "    Numero de Archivos:2230\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QydNfOMmZJoI"
      },
      "source": [
        "#COMIENZA LA ETAPA DE ENTRENAMIENTO DE LOS MODELOS\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MAZMyPFZaRa"
      },
      "outputs": [],
      "source": [
        "\"\"\" SÍ TODO LO ANTERIOR SE EJECUTÓ CORRECTAMENTE PUEDE SEGUIR DESDE AQUÍ\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W9C3HghfE77B"
      },
      "outputs": [],
      "source": [
        "#Cargaremos los directorios que utilizaremos en el proceso:\n",
        "original_dataset_dir=\"/content/drive/MyDrive/CARPETA BASE\"#todos los archivos para el experimento estarán dentro de esta carpeta\n",
        "base_dir=original_dataset_dir+\"/PRUEBA\"\n",
        "train_dir = base_dir+'/TRAIN'\n",
        "validation_dir = base_dir+'/VALIDATION'\n",
        "test_dir = base_dir+'/TEST'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT-tBEpeGl8t"
      },
      "source": [
        "#Carga de funciones para obtener métricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4n55io8RWBDS"
      },
      "outputs": [],
      "source": [
        "#Función para graficar la curva de aprendizaje\n",
        "def graficar_curva_aprendizaje(history=None,plt=plt):\n",
        "    accuracy = history.history[\"accuracy\"]\n",
        "    val_accuracy = history.history[\"val_accuracy\"]\n",
        "    loss = history.history[\"loss\"]\n",
        "    val_loss = history.history[\"val_loss\"]\n",
        "    epochs = range(1, len(accuracy) + 1)\n",
        "    plt.plot(epochs, accuracy, \"bo\", label=\"Precisión en Entrenamiento\")\n",
        "    plt.plot(epochs, val_accuracy, \"b\", label=\"Precisión en Validación\")\n",
        "    plt.title(\"Precisión en Entrenamiento y Validación\")\n",
        "    plt.legend()\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, loss, \"bo\", label=\"Pérdida en Entrenamiento\")\n",
        "    plt.plot(epochs, val_loss, \"b\", label=\"Pérdida en Validación\")\n",
        "    plt.title(\"Pérdida en Entrenamiento y Validación\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okr9yH72WK32"
      },
      "outputs": [],
      "source": [
        "#función para obtener las etiquetas del dataset y del modelo\n",
        "def get_actual_predicted_labels(dataset=None,model=None):\n",
        "\n",
        "  actual = [labels for _, labels in dataset.unbatch()]\n",
        "  actual = tf.argmax(actual, axis=1)\n",
        "\n",
        "  predicted = model.predict(dataset)\n",
        "  predicted = tf.argmax(predicted, axis=1)\n",
        "\n",
        "  return actual, predicted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6xdV31VWMu4"
      },
      "outputs": [],
      "source": [
        "#función para graficar la matriz de confusión\n",
        "def graficar_matriz_confusion(actual, predicted, labels):\n",
        "    cm = tf.math.confusion_matrix(actual, predicted)\n",
        "    cm_normalized = cm / np.sum(cm, axis=1, keepdims=True) # Normalizar la matriz de confusión\n",
        "    ax = sns.heatmap(cm_normalized, annot=True, fmt='.2f')\n",
        "    sns.set(rc={'figure.figsize': (9, 11)})\n",
        "    sns.set(font_scale=1.4)\n",
        "    ax.set_title('')\n",
        "    ax.set_xlabel('Predicho')\n",
        "    ax.set_ylabel('Observado')\n",
        "    plt.xticks(rotation=0)\n",
        "    plt.yticks(rotation=0)\n",
        "    ax.xaxis.set_ticklabels([\"A\",\"B\",\"C\",\"D\"])\n",
        "    #ax.xaxis.set_ticklabels(labels)\n",
        "    ax.yaxis.set_ticklabels([\"A\",\"B\",\"C\",\"D\"])\n",
        "    #ax.yaxis.set_ticklabels(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "barzfXOxWRdK"
      },
      "outputs": [],
      "source": [
        "#función para calcula la precisión y la sensibilidad del modelo\n",
        "def calcular_precision_recall(y_actual, y_pred, labels):\n",
        "  \"\"\"\n",
        "    Calcula la precision y recall de un modelo de clasificación usando the los valores observados y los predichos.\n",
        "\n",
        "    Args:\n",
        "      y_actual: valores observados.\n",
        "      y_pred: valores predichos.\n",
        "      labels: lista de etiquedas.\n",
        "\n",
        "    Return:\n",
        "      Precisión y recall.\n",
        "  \"\"\"\n",
        "  cm = tf.math.confusion_matrix(y_actual,y_pred)\n",
        "  # La diagonal representa los verdaderos positivos\n",
        "  tp = np.diag(cm)\n",
        "  precision = dict()\n",
        "  recall = dict()\n",
        "  for i in range(len(labels)):\n",
        "    col = cm[:, i]\n",
        "    row = cm[i, :]\n",
        "    # La suma de la columna menos el verdadero positivo es un falso negativo\n",
        "    fp = np.sum(row) - tp[i]\n",
        "\n",
        "        # La suma de la columna menos el verdadero positivo es un falso negativo\n",
        "    fn = np.sum(col) - tp[i]\n",
        "\n",
        "    precision[labels[i]] = tp[i] / (tp[i] + fp) # Precision\n",
        "\n",
        "    recall[labels[i]] = tp[i] / (tp[i] + fn) # Sensibilidad (Recall)\n",
        "\n",
        "  return  precision, recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEKrrh8rWWXs"
      },
      "outputs": [],
      "source": [
        "#funcion para calcular F1 score\n",
        "def calcular_f1_score(precision, recall):\n",
        "  \"\"\"\n",
        "    Calcula la puntuación F1 del modelo utilizando los valores de precisión y sensibilidad(recall).\n",
        "\n",
        "    Args:\n",
        "      precision: diccionario que contiene valores de precisión para cada clase.\n",
        "      recall: diccionario que contiene valores de recuperación para cada clase.\n",
        "\n",
        "    Return:\n",
        "      F1 score para cada clase.\n",
        "  \"\"\"\n",
        "  f1_scores = dict()\n",
        "  for label in precision.keys():\n",
        "    precision_val = precision[label]\n",
        "    recall_val = recall[label]\n",
        "    f1_scores[label] = 2 * (precision_val * recall_val) / (precision_val + recall_val)\n",
        "\n",
        "  return f1_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fmv2v2_uKX1a"
      },
      "outputs": [],
      "source": [
        "#Definimos los directorios donde guardaremos los resultados para cada modelo:\n",
        "modelos=original_dataset_dir+\"/Modelos\"\n",
        "if not os.path.exists(modelos):\n",
        "  os.makedirs(modelos)\n",
        "\n",
        "Guardar_CNN=modelos+\"/OPTIMO(CNN)\"\n",
        "if not os.path.exists(Guardar_CNN):\n",
        "  os.makedirs(Guardar_CNN)\n",
        "\n",
        "Guardar_CNNVGG=modelos+\"/OPTIMO(CNN-VGG16)\"\n",
        "if not os.path.exists(Guardar_CNNVGG):\n",
        "  os.makedirs(Guardar_CNNVGG)\n",
        "\n",
        "Guardar_CNNMobilNetV2=modelos+\"/OPTIMO(CNN-MobilNetV2)\"\n",
        "if not os.path.exists(Guardar_CNNMobilNetV2):\n",
        "  os.makedirs(Guardar_CNNMobilNetV2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLiIye5fbjyT"
      },
      "source": [
        "#ENTRENAMIENTO DEL MODELO CNN ESTÁNDAR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGf8mDrVtv0j"
      },
      "outputs": [],
      "source": [
        "\n",
        "inicio=g.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6AZTtIwNSz8"
      },
      "outputs": [],
      "source": [
        "#MODELO CNN Estándar\n",
        "\n",
        "def Propio(kernel=3,dropout=0.5,activacion=\"softmax\",perdida=\"categorical_crossentropy\",metrica=\"accuracy\",neuronas=500,optimizador=\"Adamax\",pix=dst_size[0]):\n",
        "\n",
        "    inputs = Input(shape=(pix,pix,3))\n",
        "    x = layers.Rescaling(1./255)(inputs)\n",
        "    x= layers.Conv2D(filters=32, kernel_size=kernel, activation='relu')(x)\n",
        "    x= layers.MaxPooling2D(pool_size=2)(x)\n",
        "    x= layers.Conv2D(filters=64, kernel_size=kernel, activation='relu')(x)\n",
        "    x= layers.MaxPooling2D(pool_size=2)(x)\n",
        "    x= layers.Conv2D(filters=128, kernel_size=kernel, activation='relu')(x)\n",
        "    x= layers.MaxPooling2D(pool_size=2)(x)\n",
        "    x= layers.Flatten()(x)\n",
        "    x= layers.Dropout(dropout)(x)\n",
        "    x= layers.Dense(neuronas, activation='relu')(x)\n",
        "    x= layers.Dense(neuronas, activation='relu')(x)\n",
        "    x= layers.Dropout(dropout)(x)\n",
        "    x= layers.Dense(4, activation='softmax')(x)\n",
        "    outputs = layers.Dense(4, activation=activacion)(x)\n",
        "\n",
        "    model = models.Model(inputs, outputs)\n",
        "    model.compile(loss=perdida,\n",
        "                  optimizer=optimizador,\n",
        "                  metrics=[metrica])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JBkTC2q9Npgv",
        "outputId": "758bed7b-edc3-4201-f423-236bdb73113d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " rescaling (Rescaling)       (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 52, 52, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 26, 26, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 86528)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 86528)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 500)               43264500  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 500)               250500    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 500)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 2004      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 20        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,610,272\n",
            "Trainable params: 43,610,272\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#Revisamos brevemente como se compone la red\n",
        "revision_modelo=Propio()\n",
        "revision_modelo.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlS6h12CSFB7",
        "outputId": "4aeaec48-01fb-4828-e396-1a3fbae454e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10490 files belonging to 4 classes.\n",
            "Found 262 files belonging to 4 classes.\n",
            "Found 263 files belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "#Funciones de carga de imágenes\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=dst_size,\n",
        "    batch_size=50,\n",
        "    seed=5,\n",
        "    label_mode=\"categorical\",\n",
        ")\n",
        "\n",
        "\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    image_size=dst_size,\n",
        "    batch_size=10,\n",
        "    seed=5,\n",
        "    label_mode=\"categorical\",\n",
        ")\n",
        "\n",
        "\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    image_size=dst_size,\n",
        "    batch_size=10,\n",
        "    label_mode=\"categorical\",\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxJOBblnSWZ1"
      },
      "outputs": [],
      "source": [
        "#FASE DE ENTRENAMIENTO DEL MODELO\n",
        "\n",
        "callbacks = [\n",
        "keras.callbacks.ModelCheckpoint(\n",
        "filepath=Guardar_CNN,\n",
        "save_best_only=True,\n",
        "monitor='val_accuracy'),\n",
        "tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=5,\n",
        "    verbose=0,\n",
        "    mode='auto',\n",
        "    start_from_epoch=3)\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KaG2Ja79SbiN"
      },
      "outputs": [],
      "source": [
        "def obtener_mejores_metricas_CNN(rangos_drop, rangos_neu, rangos_opt, rangos_ker):\n",
        "    mejores_metricas = np.zeros([5])\n",
        "\n",
        "    for drop in rangos_drop:\n",
        "        for neu in rangos_neu:\n",
        "            for opt in rangos_opt:\n",
        "                for ker in rangos_ker:\n",
        "                    modelo = Propio(kernel=ker, dropout=drop, neuronas=neu, optimizador=opt)\n",
        "                    history = modelo.fit(train_dataset, epochs=100, validation_data=validation_dataset, callbacks=callbacks)\n",
        "                    accuracy = history.history[\"val_accuracy\"][-1]\n",
        "\n",
        "                    if accuracy >= 0.90:\n",
        "                        nueva_fila = np.array([drop, neu, opt, ker, accuracy])\n",
        "                        mejores_metricas = np.vstack([mejores_metricas, nueva_fila])\n",
        "\n",
        "    return mejores_metricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oEUO7EepT4YE"
      },
      "outputs": [],
      "source": [
        "mejores_metricas = obtener_mejores_metricas_CNN(rangos_drop=[0.3, 0.5, 0.7], rangos_neu=[300, 400, 600, 800], rangos_opt=[\"Adamax\", \"RMSprop\", \"adadelta\", \"adam\"], rangos_ker=[2, 3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "M7lxmlAxt0OI",
        "outputId": "61925dcf-6122-41e7-e613-44413605d1d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tiempo total de ejecución de CNN Estándar:13541.54141831398 Seg\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Tiempo de 6 horas'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final=g.time()\n",
        "print(\"Tiempo total de ejecución de CNN Estándar:{} Seg\".format(final-inicio))\n",
        "\"\"\"Tiempo de 6 horas\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfdj6l4x1VT3",
        "outputId": "ab7021d3-f9f9-49a6-f6ef-16e07ad355f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['0.0', '0.0', '0.0', '0.0', '0.0'],\n",
              "       ['0.3', '300', 'Adamax', '3', '0.9742646813392639'],\n",
              "       ['0.3', '300', 'RMSprop', '2', '0.9375'],\n",
              "       ['0.3', '400', 'Adamax', '3', '0.970588207244873'],\n",
              "       ['0.3', '400', 'RMSprop', '2', '0.9338235259056091'],\n",
              "       ['0.3', '600', 'RMSprop', '3', '0.9595588445663452'],\n",
              "       ['0.5', '300', 'RMSprop', '2', '0.9522058963775635'],\n",
              "       ['0.5', '400', 'RMSprop', '2', '0.9485294222831726'],\n",
              "       ['0.5', '800', 'RMSprop', '2', '0.9264705777168274'],\n",
              "       ['0.7', '300', 'Adamax', '3', '0.9522058963775635'],\n",
              "       ['0.7', '300', 'RMSprop', '2', '0.9375'],\n",
              "       ['0.7', '400', 'Adamax', '2', '0.970588207244873'],\n",
              "       ['0.7', '400', 'RMSprop', '2', '0.9485294222831726'],\n",
              "       ['0.7', '600', 'RMSprop', '2', '0.9411764740943909'],\n",
              "       ['0.7', '800', 'RMSprop', '2', '0.9375'],\n",
              "       ['0.7', '800', 'RMSprop', '3', '0.9227941036224365']], dtype='<U32')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mejores_metricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-Cn-6rIUDeS"
      },
      "outputs": [],
      "source": [
        "#guardar los resultados al archivo de txt\n",
        "file = open(Guardar_CNN+\"/resultados_de_busqueda_por_rejilla.txt\", \"w+\")\n",
        "content = str(mejores_metricas)\n",
        "file.write(content)\n",
        "file.close()\n",
        "\n",
        "\n",
        "# Obtener el índice de la fila con el máximo valor de accuracy\n",
        "max_index = np.argmax(mejores_metricas[:, -1])\n",
        "\n",
        "# Obtener los parámetros correspondientes a la fila con el máximo valor de accuracy\n",
        "kernel_max = int(mejores_metricas[max_index, 3])\n",
        "dropout_max = float(mejores_metricas[max_index, 0])\n",
        "neuronas_max = int(mejores_metricas[max_index, 1])\n",
        "optimizador_max = str(mejores_metricas[max_index, 2])\n",
        "\n",
        "# Recuperamos un modelo CNN estandar con la función Propio() con los parámetros correspondientes al máximo valor de accuracy\n",
        "modelo_CNN = Propio(kernel=kernel_max, dropout=dropout_max, neuronas=neuronas_max, optimizador=optimizador_max)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wmOZCWlVsCI",
        "outputId": "cea0580f-0b0a-424a-a43a-19b1fc3046fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "126/126 [==============================] - 12s 78ms/step - loss: 1.2059 - accuracy: 0.5503 - val_loss: 1.1133 - val_accuracy: 0.6581\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 10s 77ms/step - loss: 1.0590 - accuracy: 0.6948 - val_loss: 0.9970 - val_accuracy: 0.7316\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 10s 77ms/step - loss: 0.9499 - accuracy: 0.8932 - val_loss: 0.9084 - val_accuracy: 0.9228\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 10s 77ms/step - loss: 0.8771 - accuracy: 0.9190 - val_loss: 0.8519 - val_accuracy: 0.8897\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 10s 77ms/step - loss: 0.8051 - accuracy: 0.9316 - val_loss: 0.7824 - val_accuracy: 0.9265\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 10s 77ms/step - loss: 0.7404 - accuracy: 0.9394 - val_loss: 0.7122 - val_accuracy: 0.9412\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 10s 77ms/step - loss: 0.6777 - accuracy: 0.9444 - val_loss: 0.6571 - val_accuracy: 0.9375\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 10s 77ms/step - loss: 0.6149 - accuracy: 0.9513 - val_loss: 0.6108 - val_accuracy: 0.9301\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 10s 77ms/step - loss: 0.5579 - accuracy: 0.9560 - val_loss: 0.5563 - val_accuracy: 0.9412\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 10s 77ms/step - loss: 0.5040 - accuracy: 0.9606 - val_loss: 0.5067 - val_accuracy: 0.9412\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 10s 77ms/step - loss: 0.4547 - accuracy: 0.9641 - val_loss: 0.4947 - val_accuracy: 0.9154\n"
          ]
        }
      ],
      "source": [
        "#Entrenamos nuevamente el modelo para obtener las metricas\n",
        "\"\"\"CUANDO EXISTÁN DOS MODELOS ÓPTIMOS CON MISMO ACC: Antes de ejecutar el siguiente código verifique que la carpeta de guardado(Guardar_CNN) esté vacía de lo contrario el modelo\n",
        "y los resultados se mostrarán en funcion del último modelo guardado en lugar del siguiente.\n",
        "\"\"\"\n",
        "history = modelo_CNN.fit(train_dataset, epochs=100, validation_data=validation_dataset, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lWcWwtVUQSD",
        "outputId": "4f63fcfd-eafb-4c3b-f813-d35b1395f68c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27/27 [==============================] - 1s 13ms/step - loss: 0.3235 - accuracy: 0.9813\n",
            "Test ACC: 0.981\n"
          ]
        }
      ],
      "source": [
        "#EVALUACION FINAL DEL MODELO para determinar su ACC global\n",
        "\n",
        "test_model_cnn = keras.models.load_model(Guardar_CNN)\n",
        "test_loss, test_acc = test_model_cnn.evaluate(test_dataset)\n",
        "print(f\"Test ACC: {test_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tg8Wq7Ej4PCC"
      },
      "outputs": [],
      "source": [
        "#config = test_model_cnn.get_config()\n",
        "#print(config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmmJHnVYe70e"
      },
      "outputs": [],
      "source": [
        "#RESULTADOS FINALES PARA CNN ESTÁNDAR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "d6kt5Q60d2F2",
        "outputId": "11085979-4c29-41bb-c139-abce70a49ff4"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "graficar_curva_aprendizaje(history,plt=plt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "Onaz06RPWOS0",
        "outputId": "6a8d1b2e-2982-454a-b0e9-1e50ee40645b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27/27 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "actual, predicted = get_actual_predicted_labels(dataset=test_dataset,model=test_model_cnn)\n",
        "graficar_matriz_confusion(actual, predicted, test_dataset.class_names)\n",
        "#print(actual,predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cl6U2jt3WUnc"
      },
      "outputs": [],
      "source": [
        "precision, recall = calcular_precision_recall(actual, predicted, test_dataset.class_names)\n",
        "resultadosf1=calcular_f1_score(precision, recall)\n",
        "print(\"Resultado Precisión: {}\".format(precision))\n",
        "print(\"Resultado Recall: {}\".format( recall))\n",
        "print(\"Resultado F1_Score: {}\".format(resultadosf1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJj-ilRsWYPU"
      },
      "outputs": [],
      "source": [
        "valores = list(resultadosf1.values())\n",
        "promedio = statistics.mean(valores)\n",
        "print(\"F1macro:\", promedio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyM0HmEff7ZR"
      },
      "source": [
        "#ENTRENAMIENTO DEL MODELO CNN-VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4nJ5X41H-eb"
      },
      "outputs": [],
      "source": [
        "inicio=g.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDlpe9QOf_Hu",
        "outputId": "ff85b338-513e-4312-bca0-4a3b594380ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58889256/58889256 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#%% BASE COVOLUCIONAL VGG16\n",
        "\n",
        "conv_base = vgg.VGG16(\n",
        "weights=\"imagenet\",\n",
        "include_top=False,\n",
        "input_shape=(dst_size[0],dst_size[0],3))\n",
        "##bloquear capas de 1-4\n",
        "for layer in conv_base.layers:\n",
        "  if layer.name.startswith(\"block\") and not layer.name.startswith(\"block5\"):\n",
        "    layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixtgzZE5hJkr",
        "outputId": "f2015d31-54bc-4525-9467-cec4285d9924"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "block1_conv1 False\n",
            "block1_conv2 False\n",
            "block2_conv1 False\n",
            "block2_conv2 False\n",
            "block3_conv1 False\n",
            "block3_conv2 False\n",
            "block3_conv3 False\n",
            "block4_conv1 False\n",
            "block4_conv2 False\n",
            "block4_conv3 False\n",
            "block5_conv1 True\n",
            "block5_conv2 True\n",
            "block5_conv3 True\n"
          ]
        }
      ],
      "source": [
        "#verificar si las capas  finalesson entrenables\n",
        "for layer in conv_base.layers:\n",
        "  if isinstance(layer, keras.layers.Conv2D):\n",
        "    print(layer.name, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Bbo8ZrAHKTr",
        "outputId": "3d5159fd-fc2f-4a98-a7ec-d5264685fbd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6300 files belonging to 4 classes.\n",
            "Found 272 files belonging to 4 classes.\n",
            "Found 268 files belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=dst_size,\n",
        "    batch_size=50,\n",
        "    seed=5,\n",
        "    label_mode=\"categorical\",\n",
        ")\n",
        "\n",
        "\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    image_size=dst_size,\n",
        "    batch_size=10,\n",
        "    seed=5,\n",
        "    label_mode=\"categorical\",\n",
        ")\n",
        "\n",
        "\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    image_size=dst_size,\n",
        "    batch_size=10,\n",
        "    label_mode=\"categorical\",\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYhDdXuthLqN"
      },
      "outputs": [],
      "source": [
        "# #MODELO DE LA RED CON VGG16\n",
        "def VGG(dropout1=0.5,dropout2=0.6,activacion=\"softmax\",perdida=\"categorical_crossentropy\",metrica=\"accuracy\",neuronas=256,optimizador=\"Adamax\",vgg=conv_base,preproces=vgg):\n",
        "\n",
        "  inputs = Input(shape=(dst_size[0], dst_size[0], 3))\n",
        "  x = preproces.preprocess_input(inputs)\n",
        "  x = vgg(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dropout(dropout1)(x)\n",
        "  x = layers.Dense(neuronas,activation='relu')(x)\n",
        "  x = layers.Dense(neuronas,activation='relu')(x)\n",
        "  x = layers.Dropout(dropout2)(x)\n",
        "  outputs = layers.Dense(4, activation=activacion)(x)\n",
        "\n",
        "  model = models.Model(inputs, outputs)\n",
        "  model.compile(loss=perdida,\n",
        "                optimizer=optimizador,\n",
        "                metrics=[metrica])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwvgMNVth0y_"
      },
      "outputs": [],
      "source": [
        "#FASE DE ENTRENAMIENTO DEL MODELO\n",
        "\n",
        "callbacks2 = [\n",
        "keras.callbacks.ModelCheckpoint(\n",
        "filepath=Guardar_CNNVGG,\n",
        "save_best_only=True,\n",
        "monitor='val_accuracy'),\n",
        "tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=5,\n",
        "    verbose=0,\n",
        "    mode='auto',\n",
        "    start_from_epoch=5)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "efQcRDcaiHY8"
      },
      "outputs": [],
      "source": [
        "#ÁSTA FUNCION TAMBIEN LA USAMOS EN VGG16 y MOBILENETV2\n",
        "def obtener_mejores_metricas(rangos_drop, rangos_neu, rangos_opt,callbacks=callbacks2,mod=None):\n",
        "    mejores_metricas = np.zeros([4])\n",
        "\n",
        "    for drop in rangos_drop:\n",
        "        for neu in rangos_neu:\n",
        "            for opt in rangos_opt:\n",
        "              modelo=mod(dropout1=drop,dropout2=drop+0.1,neuronas=neu,optimizador=opt)\n",
        "              history = modelo.fit(\n",
        "                    train_dataset,\n",
        "                    epochs=100,\n",
        "                    validation_data=validation_dataset\n",
        "                    ,callbacks=callbacks2\n",
        "                    )\n",
        "              accuracy = history.history[\"val_accuracy\"][-1]\n",
        "\n",
        "              if accuracy >= 0.95:\n",
        "                  nueva_fila = np.array([drop, neu, opt, accuracy])\n",
        "                  mejores_metricas = np.vstack([mejores_metricas, nueva_fila])\n",
        "\n",
        "    return mejores_metricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkMwWvMrrKRF",
        "outputId": "b9a1a598-e7c1-46ea-debb-b24d342e07c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 1.2342 - accuracy: 0.4621"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 49s 310ms/step - loss: 1.2342 - accuracy: 0.4621 - val_loss: 0.9631 - val_accuracy: 0.5110\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 258ms/step - loss: 0.9430 - accuracy: 0.5048 - val_loss: 0.9069 - val_accuracy: 0.4926\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 258ms/step - loss: 0.9069 - accuracy: 0.4997 - val_loss: 0.8611 - val_accuracy: 0.5037\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.8515 - accuracy: 0.5127"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 36s 287ms/step - loss: 0.8515 - accuracy: 0.5127 - val_loss: 0.7671 - val_accuracy: 0.5956\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 259ms/step - loss: 0.8518 - accuracy: 0.5270 - val_loss: 0.8078 - val_accuracy: 0.5625\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.7598 - accuracy: 0.6010"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 37s 291ms/step - loss: 0.7598 - accuracy: 0.6010 - val_loss: 0.5845 - val_accuracy: 0.6985\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 258ms/step - loss: 0.5819 - accuracy: 0.6951 - val_loss: 0.5150 - val_accuracy: 0.6985\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.4982 - accuracy: 0.7341"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 36s 287ms/step - loss: 0.4982 - accuracy: 0.7341 - val_loss: 0.4083 - val_accuracy: 0.7463\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.4309 - accuracy: 0.7632"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 37s 289ms/step - loss: 0.4309 - accuracy: 0.7632 - val_loss: 0.3673 - val_accuracy: 0.8309\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3406 - accuracy: 0.8587"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 36s 286ms/step - loss: 0.3406 - accuracy: 0.8587 - val_loss: 0.2138 - val_accuracy: 0.9449\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2037 - accuracy: 0.9452"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 36s 285ms/step - loss: 0.2037 - accuracy: 0.9452 - val_loss: 0.0589 - val_accuracy: 0.9890\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.0546 - accuracy: 0.9884"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 37s 290ms/step - loss: 0.0546 - accuracy: 0.9884 - val_loss: 0.0233 - val_accuracy: 0.9963\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 33s 258ms/step - loss: 0.0303 - accuracy: 0.9935 - val_loss: 0.0384 - val_accuracy: 0.9890\n",
            "Epoch 14/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9965"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 13). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 36s 286ms/step - loss: 0.0153 - accuracy: 0.9965 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 15/100\n",
            "126/126 [==============================] - 33s 258ms/step - loss: 0.0080 - accuracy: 0.9986 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 16/100\n",
            "126/126 [==============================] - 33s 259ms/step - loss: 0.0051 - accuracy: 0.9994 - val_loss: 0.0065 - val_accuracy: 0.9963\n",
            "Epoch 17/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 0.0327 - accuracy: 0.9940 - val_loss: 0.0139 - val_accuracy: 0.9926\n",
            "Epoch 18/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.0064 - accuracy: 0.9979 - val_loss: 0.0129 - val_accuracy: 0.9926\n",
            "Epoch 19/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 0.9926\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 261ms/step - loss: 7.8855 - accuracy: 0.3651 - val_loss: 0.9673 - val_accuracy: 0.5515\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 259ms/step - loss: 1.2775 - accuracy: 0.4943 - val_loss: 0.8767 - val_accuracy: 0.5441\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 259ms/step - loss: 1.6367 - accuracy: 0.6310 - val_loss: 0.4090 - val_accuracy: 0.8162\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 259ms/step - loss: 0.8282 - accuracy: 0.8006 - val_loss: 0.2247 - val_accuracy: 0.9485\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 0.9570 - accuracy: 0.8368 - val_loss: 0.0668 - val_accuracy: 0.9816\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 2.2938 - accuracy: 0.8479 - val_loss: 0.0753 - val_accuracy: 0.9890\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 2.8123 - accuracy: 0.8473 - val_loss: 0.3194 - val_accuracy: 0.7390\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 259ms/step - loss: 2.1512 - accuracy: 0.8365 - val_loss: 0.1027 - val_accuracy: 0.9596\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 3.4264 - accuracy: 0.8414 - val_loss: 0.4310 - val_accuracy: 0.9044\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3849 - accuracy: 0.4678 - val_loss: 1.1868 - val_accuracy: 0.4081\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 259ms/step - loss: 3.1037 - accuracy: 0.3030 - val_loss: 1.0665 - val_accuracy: 0.4522\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 36s 262ms/step - loss: 2057.1257 - accuracy: 0.2757 - val_loss: 266.9272 - val_accuracy: 0.4559\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1483.6416 - accuracy: 0.3108 - val_loss: 169.5910 - val_accuracy: 0.6287\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1212.2563 - accuracy: 0.3635 - val_loss: 206.8161 - val_accuracy: 0.6066\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1034.2216 - accuracy: 0.4073 - val_loss: 174.9448 - val_accuracy: 0.6397\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 865.5981 - accuracy: 0.4625 - val_loss: 154.1709 - val_accuracy: 0.6801\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 782.9916 - accuracy: 0.4737 - val_loss: 137.9261 - val_accuracy: 0.7059\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 676.9854 - accuracy: 0.5217 - val_loss: 115.7345 - val_accuracy: 0.7243\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 576.5249 - accuracy: 0.5500 - val_loss: 86.4642 - val_accuracy: 0.7721\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 520.3176 - accuracy: 0.5795 - val_loss: 62.3065 - val_accuracy: 0.8419\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 461.5696 - accuracy: 0.6089 - val_loss: 51.5610 - val_accuracy: 0.8566\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 399.2212 - accuracy: 0.6371 - val_loss: 42.2006 - val_accuracy: 0.8676\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 329.4367 - accuracy: 0.6702 - val_loss: 27.7805 - val_accuracy: 0.8971\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 294.5804 - accuracy: 0.6889 - val_loss: 22.7705 - val_accuracy: 0.9118\n",
            "Epoch 14/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 245.2032 - accuracy: 0.7173 - val_loss: 18.8882 - val_accuracy: 0.9228\n",
            "Epoch 15/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 210.0544 - accuracy: 0.7473 - val_loss: 15.5116 - val_accuracy: 0.9375\n",
            "Epoch 16/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 189.0811 - accuracy: 0.7570 - val_loss: 13.0378 - val_accuracy: 0.9485\n",
            "Epoch 17/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 154.2811 - accuracy: 0.7927 - val_loss: 11.8976 - val_accuracy: 0.9632\n",
            "Epoch 18/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 132.5761 - accuracy: 0.8097 - val_loss: 12.3353 - val_accuracy: 0.9632\n",
            "Epoch 19/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 117.5635 - accuracy: 0.8257 - val_loss: 11.5335 - val_accuracy: 0.9632\n",
            "Epoch 20/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 104.6881 - accuracy: 0.8471 - val_loss: 10.1339 - val_accuracy: 0.9632\n",
            "Epoch 21/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 80.6651 - accuracy: 0.8656 - val_loss: 9.6022 - val_accuracy: 0.9632\n",
            "Epoch 22/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 75.4476 - accuracy: 0.8721 - val_loss: 8.4128 - val_accuracy: 0.9669\n",
            "Epoch 23/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 63.9557 - accuracy: 0.8865 - val_loss: 7.6912 - val_accuracy: 0.9669\n",
            "Epoch 24/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 55.6022 - accuracy: 0.8970 - val_loss: 7.2320 - val_accuracy: 0.9669\n",
            "Epoch 25/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 48.1873 - accuracy: 0.9106 - val_loss: 5.8823 - val_accuracy: 0.9706\n",
            "Epoch 26/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 45.8615 - accuracy: 0.9159 - val_loss: 5.9289 - val_accuracy: 0.9706\n",
            "Epoch 27/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 36.7406 - accuracy: 0.9227 - val_loss: 5.5260 - val_accuracy: 0.9743\n",
            "Epoch 28/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 38.5163 - accuracy: 0.9262 - val_loss: 5.1116 - val_accuracy: 0.9779\n",
            "Epoch 29/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 35.4095 - accuracy: 0.9319 - val_loss: 4.8054 - val_accuracy: 0.9779\n",
            "Epoch 30/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 30.8263 - accuracy: 0.9343 - val_loss: 4.8163 - val_accuracy: 0.9816\n",
            "Epoch 31/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 26.9713 - accuracy: 0.9429 - val_loss: 4.6218 - val_accuracy: 0.9816\n",
            "Epoch 32/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 26.6570 - accuracy: 0.9379 - val_loss: 4.2540 - val_accuracy: 0.9853\n",
            "Epoch 33/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 26.9158 - accuracy: 0.9448 - val_loss: 3.9800 - val_accuracy: 0.9853\n",
            "Epoch 34/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 25.5909 - accuracy: 0.9471 - val_loss: 3.7843 - val_accuracy: 0.9853\n",
            "Epoch 35/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 23.1080 - accuracy: 0.9535 - val_loss: 3.6352 - val_accuracy: 0.9816\n",
            "Epoch 36/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 18.4814 - accuracy: 0.9592 - val_loss: 3.3872 - val_accuracy: 0.9816\n",
            "Epoch 37/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 20.6839 - accuracy: 0.9568 - val_loss: 3.1488 - val_accuracy: 0.9853\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 262ms/step - loss: 31.0669 - accuracy: 0.9756 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.6901 - accuracy: 0.9944 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 0.7004 - accuracy: 0.9959 - val_loss: 3.4994e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.3846 - accuracy: 0.9970 - val_loss: 9.2496e-04 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.5229 - accuracy: 0.9970 - val_loss: 0.0689 - val_accuracy: 0.9963\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.2353 - accuracy: 0.9983 - val_loss: 1.2675 - val_accuracy: 0.9926\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.3058 - accuracy: 0.9975 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.0769 - accuracy: 0.9990 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 0.1433 - accuracy: 0.9986 - val_loss: 0.0803 - val_accuracy: 0.9963\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 0.0951 - accuracy: 0.9986 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 0.1553 - accuracy: 0.9984 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 0.1222 - accuracy: 0.9992 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 262ms/step - loss: 113.3241 - accuracy: 0.8378 - val_loss: 0.2618 - val_accuracy: 0.9228\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.5387 - accuracy: 0.5252 - val_loss: 0.8717 - val_accuracy: 0.5037\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 2.2758 - accuracy: 0.4983 - val_loss: 0.8357 - val_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 4.7354 - accuracy: 0.4892 - val_loss: 0.5649 - val_accuracy: 0.7022\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.0323 - accuracy: 0.5063 - val_loss: 0.8289 - val_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.7179 - accuracy: 0.4790 - val_loss: 0.8150 - val_accuracy: 0.4963\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.9094 - accuracy: 0.5078 - val_loss: 0.6931 - val_accuracy: 0.7169\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 2.1695 - accuracy: 0.5106 - val_loss: 0.7773 - val_accuracy: 0.5772\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 0.9624 - accuracy: 0.5341 - val_loss: 0.7573 - val_accuracy: 0.5588\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.4748 - accuracy: 0.7713 - val_loss: 0.6167 - val_accuracy: 0.8493\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 0.7769 - accuracy: 0.9241 - val_loss: 0.5980 - val_accuracy: 0.9743\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.6949 - accuracy: 0.8170 - val_loss: 0.4177 - val_accuracy: 0.8088\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 3.1097 - accuracy: 0.9330 - val_loss: 0.6323 - val_accuracy: 0.9265\n",
            "Epoch 14/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 0.7584 - accuracy: 0.9046 - val_loss: 0.5275 - val_accuracy: 0.7426\n",
            "Epoch 15/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.7240 - accuracy: 0.8951 - val_loss: 0.1050 - val_accuracy: 0.9816\n",
            "Epoch 16/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.5598 - accuracy: 0.9124 - val_loss: 1.0641 - val_accuracy: 0.9853\n",
            "Epoch 17/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.0357 - accuracy: 0.9660 - val_loss: 0.0134 - val_accuracy: 0.9963\n",
            "Epoch 18/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.9798 - accuracy: 0.9630 - val_loss: 0.0578 - val_accuracy: 0.9890\n",
            "Epoch 19/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.7070 - accuracy: 0.9779 - val_loss: 0.0532 - val_accuracy: 0.9853\n",
            "Epoch 20/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.4447 - accuracy: 0.9813 - val_loss: 0.0113 - val_accuracy: 0.9963\n",
            "Epoch 21/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.7920 - accuracy: 0.9741 - val_loss: 0.0256 - val_accuracy: 0.9926\n",
            "Epoch 22/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.3866 - accuracy: 0.9697 - val_loss: 0.1135 - val_accuracy: 0.9522\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 36s 263ms/step - loss: 193.3817 - accuracy: 0.4843 - val_loss: 4.1528 - val_accuracy: 0.9228\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 91.0947 - accuracy: 0.6681 - val_loss: 1.8665 - val_accuracy: 0.9669\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 56.8200 - accuracy: 0.7459 - val_loss: 1.4613 - val_accuracy: 0.9669\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 36.5977 - accuracy: 0.8070 - val_loss: 1.0120 - val_accuracy: 0.9669\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 258ms/step - loss: 27.4700 - accuracy: 0.8435 - val_loss: 0.6358 - val_accuracy: 0.9743\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 21.0577 - accuracy: 0.8765 - val_loss: 0.4964 - val_accuracy: 0.9816\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 16.2670 - accuracy: 0.8990 - val_loss: 0.3897 - val_accuracy: 0.9816\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 12.8924 - accuracy: 0.9138 - val_loss: 0.2815 - val_accuracy: 0.9963\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 11.7747 - accuracy: 0.9241 - val_loss: 0.2593 - val_accuracy: 0.9963\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 8.8634 - accuracy: 0.9381 - val_loss: 0.2440 - val_accuracy: 0.9963\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 7.4048 - accuracy: 0.9449 - val_loss: 0.2231 - val_accuracy: 0.9963\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 6.3102 - accuracy: 0.9497 - val_loss: 0.1992 - val_accuracy: 0.9963\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 7.1847 - accuracy: 0.9492 - val_loss: 0.1809 - val_accuracy: 0.9963\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 36s 264ms/step - loss: 4.7777 - accuracy: 0.9848 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 0.0560 - accuracy: 0.9987 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 0.0301 - accuracy: 0.9990 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 0.0459 - accuracy: 0.9990 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 0.0338 - accuracy: 0.9990 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 3.7787e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 0.0088 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 0.0243 - accuracy: 0.9995 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 0.0159 - accuracy: 0.9997 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 0.0147 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 5.4533e-04 - accuracy: 0.9998 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 264ms/step - loss: 6.6678 - accuracy: 0.9248 - val_loss: 0.0548 - val_accuracy: 0.9816\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.9225 - accuracy: 0.9598 - val_loss: 0.3597 - val_accuracy: 0.8346\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.8958 - accuracy: 0.8568 - val_loss: 0.5207 - val_accuracy: 0.7316\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 3.0653 - accuracy: 0.8871 - val_loss: 0.8316 - val_accuracy: 0.7574\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.6699 - accuracy: 0.6948 - val_loss: 0.6440 - val_accuracy: 0.6324\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.6099 - accuracy: 0.7140 - val_loss: 0.2392 - val_accuracy: 0.9485\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 0.9255 - accuracy: 0.8435 - val_loss: 0.5891 - val_accuracy: 0.6691\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.2210 - accuracy: 0.7217 - val_loss: 0.6775 - val_accuracy: 0.6985\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 2.2908 - accuracy: 0.7063 - val_loss: 0.5723 - val_accuracy: 0.6801\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.8869 - accuracy: 0.6475 - val_loss: 0.6830 - val_accuracy: 0.6213\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.7597 - accuracy: 0.6463 - val_loss: 0.4323 - val_accuracy: 0.7353\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 36s 264ms/step - loss: 140.6899 - accuracy: 0.3590 - val_loss: 20.6838 - val_accuracy: 0.6213\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 83.7311 - accuracy: 0.4767 - val_loss: 5.5428 - val_accuracy: 0.6838\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 50.8490 - accuracy: 0.5283 - val_loss: 1.8211 - val_accuracy: 0.7206\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 34.2115 - accuracy: 0.5729 - val_loss: 0.9753 - val_accuracy: 0.7243\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 24.0049 - accuracy: 0.5922 - val_loss: 0.7808 - val_accuracy: 0.7279\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 18.1890 - accuracy: 0.6176 - val_loss: 0.7174 - val_accuracy: 0.7316\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 14.4417 - accuracy: 0.6222 - val_loss: 0.7172 - val_accuracy: 0.7316\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 11.7605 - accuracy: 0.6286 - val_loss: 0.7169 - val_accuracy: 0.7316\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 11.1423 - accuracy: 0.6416 - val_loss: 0.7166 - val_accuracy: 0.7316\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 8.6032 - accuracy: 0.6486 - val_loss: 0.7164 - val_accuracy: 0.7316\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 7.5080 - accuracy: 0.6554 - val_loss: 0.7161 - val_accuracy: 0.7316\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 261ms/step - loss: 2.5557 - accuracy: 0.3794 - val_loss: 1.0043 - val_accuracy: 0.4963\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.0544 - accuracy: 0.4640 - val_loss: 0.9207 - val_accuracy: 0.5110\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.9869 - accuracy: 0.4732 - val_loss: 0.8964 - val_accuracy: 0.5074\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.9559 - accuracy: 0.4846 - val_loss: 0.8671 - val_accuracy: 0.5110\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.9774 - accuracy: 0.4722 - val_loss: 0.8643 - val_accuracy: 0.5074\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 0.8960 - accuracy: 0.4941 - val_loss: 0.8483 - val_accuracy: 0.5110\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 0.8825 - accuracy: 0.4983 - val_loss: 0.8402 - val_accuracy: 0.5110\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 0.8826 - accuracy: 0.4976 - val_loss: 0.8399 - val_accuracy: 0.5074\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.8748 - accuracy: 0.4995 - val_loss: 0.8314 - val_accuracy: 0.5110\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 0.8879 - accuracy: 0.4851 - val_loss: 0.8293 - val_accuracy: 0.5110\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.8704 - accuracy: 0.4890 - val_loss: 0.8289 - val_accuracy: 0.5110\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 36s 261ms/step - loss: 2.3583 - accuracy: 0.3105 - val_loss: 1.0160 - val_accuracy: 0.4926\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.2777 - accuracy: 0.3824 - val_loss: 0.9010 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.1448 - accuracy: 0.4497 - val_loss: 0.8727 - val_accuracy: 0.4963\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3237 - accuracy: 0.4821 - val_loss: 0.8389 - val_accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.0475 - accuracy: 0.4805 - val_loss: 0.8348 - val_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.0522 - accuracy: 0.4890 - val_loss: 0.8525 - val_accuracy: 0.4963\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 0.9561 - accuracy: 0.4800 - val_loss: 0.8551 - val_accuracy: 0.4963\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.2744 - accuracy: 0.4797 - val_loss: 0.8713 - val_accuracy: 0.4926\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 0.9970 - accuracy: 0.4775 - val_loss: 0.8675 - val_accuracy: 0.4926\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 2.2171 - accuracy: 0.4900 - val_loss: 0.8380 - val_accuracy: 0.5000\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.1073 - accuracy: 0.4854 - val_loss: 0.9116 - val_accuracy: 0.4816\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.4401 - accuracy: 0.4703 - val_loss: 0.8500 - val_accuracy: 0.4963\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 3.6638 - accuracy: 0.4762 - val_loss: 0.8353 - val_accuracy: 0.5000\n",
            "Epoch 14/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 0.8888 - accuracy: 0.4911 - val_loss: 0.8332 - val_accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.6292 - accuracy: 0.4837 - val_loss: 0.9791 - val_accuracy: 0.5000\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 262ms/step - loss: 296.5722 - accuracy: 0.2463 - val_loss: 94.2419 - val_accuracy: 0.2574\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 223.9130 - accuracy: 0.2690 - val_loss: 39.6293 - val_accuracy: 0.3382\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 165.7133 - accuracy: 0.2868 - val_loss: 15.1894 - val_accuracy: 0.3897\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 127.9790 - accuracy: 0.3079 - val_loss: 4.9215 - val_accuracy: 0.4485\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 101.1928 - accuracy: 0.3214 - val_loss: 2.4088 - val_accuracy: 0.4779\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 77.7284 - accuracy: 0.3438 - val_loss: 1.7162 - val_accuracy: 0.4890\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 61.0116 - accuracy: 0.3560 - val_loss: 1.3278 - val_accuracy: 0.4926\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 49.3061 - accuracy: 0.3754 - val_loss: 1.2466 - val_accuracy: 0.4926\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 39.7280 - accuracy: 0.3863 - val_loss: 1.1762 - val_accuracy: 0.4926\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 32.5273 - accuracy: 0.3975 - val_loss: 1.1279 - val_accuracy: 0.4963\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 27.4951 - accuracy: 0.4097 - val_loss: 1.1027 - val_accuracy: 0.4963\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 23.7396 - accuracy: 0.4208 - val_loss: 1.0818 - val_accuracy: 0.4963\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 20.3183 - accuracy: 0.4263 - val_loss: 1.0650 - val_accuracy: 0.4963\n",
            "Epoch 14/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 17.2263 - accuracy: 0.4346 - val_loss: 1.0578 - val_accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 15.1965 - accuracy: 0.4427 - val_loss: 1.0581 - val_accuracy: 0.5000\n",
            "Epoch 16/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 13.1535 - accuracy: 0.4456 - val_loss: 1.0584 - val_accuracy: 0.5000\n",
            "Epoch 17/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 10.0892 - accuracy: 0.4500 - val_loss: 1.0591 - val_accuracy: 0.5000\n",
            "Epoch 18/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 8.7848 - accuracy: 0.4565 - val_loss: 1.0593 - val_accuracy: 0.5000\n",
            "Epoch 19/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 9.1754 - accuracy: 0.4549 - val_loss: 1.0602 - val_accuracy: 0.5000\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 262ms/step - loss: 2.0928 - accuracy: 0.4773 - val_loss: 0.9388 - val_accuracy: 0.5000\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 0.9237 - accuracy: 0.4946 - val_loss: 0.8653 - val_accuracy: 0.5000\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 0.8794 - accuracy: 0.4835 - val_loss: 0.8464 - val_accuracy: 0.5000\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 0.8643 - accuracy: 0.4884 - val_loss: 0.8391 - val_accuracy: 0.5000\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 0.8489 - accuracy: 0.5054 - val_loss: 0.8347 - val_accuracy: 0.5000\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.8536 - accuracy: 0.4981 - val_loss: 0.8330 - val_accuracy: 0.5000\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 0.8509 - accuracy: 0.5014 - val_loss: 0.8319 - val_accuracy: 0.5000\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 0.8494 - accuracy: 0.4997 - val_loss: 0.8306 - val_accuracy: 0.5000\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 0.8552 - accuracy: 0.4983 - val_loss: 0.8305 - val_accuracy: 0.5000\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 0.8774 - accuracy: 0.4903 - val_loss: 0.8300 - val_accuracy: 0.5000\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 0.8509 - accuracy: 0.4990 - val_loss: 0.8296 - val_accuracy: 0.5000\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 261ms/step - loss: 5.4180 - accuracy: 0.2944 - val_loss: 1.3933 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3921 - accuracy: 0.2422 - val_loss: 1.3865 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3866 - accuracy: 0.2435 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3867 - accuracy: 0.2444 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2524 - val_loss: 1.3864 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3867 - accuracy: 0.2427 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3867 - accuracy: 0.2378 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3865 - accuracy: 0.2492 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3865 - accuracy: 0.2402 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3865 - accuracy: 0.2465 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 259ms/step - loss: 1.3865 - accuracy: 0.2484 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 36s 264ms/step - loss: 1.3863 - accuracy: 0.2403 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2398 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2452 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2451 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2449 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2424 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2427 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2483 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2421 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2421 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2481 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 36s 264ms/step - loss: 1.3864 - accuracy: 0.2441 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 264ms/step - loss: 1.3863 - accuracy: 0.2446 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2500 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2463 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2430 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 916s 7s/step - loss: 1.3863 - accuracy: 0.2419 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2430 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2430 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 34s 264ms/step - loss: 1.3863 - accuracy: 0.2419 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2397 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2411 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 264ms/step - loss: 1.3864 - accuracy: 0.2465 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2397 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2422 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2462 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2424 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2424 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2398 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2411 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2346 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2314 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2341 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 36s 264ms/step - loss: 1.3863 - accuracy: 0.2417 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2408 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2375 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2410 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2433 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2408 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2406 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2367 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2406 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2384 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2402 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 262ms/step - loss: 1.3863 - accuracy: 0.2440 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2438 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2462 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3863 - accuracy: 0.2443 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2451 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3863 - accuracy: 0.2465 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3863 - accuracy: 0.2446 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3863 - accuracy: 0.2460 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2441 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2400 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2348 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 261ms/step - loss: 1.3864 - accuracy: 0.2427 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2432 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3864 - accuracy: 0.2406 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3864 - accuracy: 0.2448 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3864 - accuracy: 0.2406 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3864 - accuracy: 0.2362 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3864 - accuracy: 0.2419 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3864 - accuracy: 0.2397 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2292 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3864 - accuracy: 0.2373 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 259ms/step - loss: 1.3864 - accuracy: 0.2392 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 36s 269ms/step - loss: 1.3863 - accuracy: 0.2408 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2370 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2411 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2437 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2452 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2419 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2392 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2449 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2424 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2467 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2381 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 36s 263ms/step - loss: 1.3863 - accuracy: 0.2438 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2435 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2425 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2462 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2441 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2500 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2465 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2430 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2422 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2416 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2389 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 263ms/step - loss: 1.3864 - accuracy: 0.2446 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2451 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2433 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2449 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3864 - accuracy: 0.2433 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2422 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2398 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3864 - accuracy: 0.2324 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2410 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2437 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2422 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 36s 264ms/step - loss: 1.3863 - accuracy: 0.2410 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2429 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2452 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2417 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2411 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2327 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2397 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2383 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2419 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2465 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2411 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 36s 264ms/step - loss: 1.3863 - accuracy: 0.2354 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 264ms/step - loss: 1.3863 - accuracy: 0.2429 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2400 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2417 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 264ms/step - loss: 1.3863 - accuracy: 0.2432 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2444 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2440 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2398 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2392 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2449 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2359 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 264ms/step - loss: 1.3864 - accuracy: 0.2398 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3864 - accuracy: 0.2430 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2437 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2410 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3864 - accuracy: 0.2422 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3864 - accuracy: 0.2424 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3864 - accuracy: 0.2329 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2395 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2406 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3864 - accuracy: 0.2387 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2421 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 36s 265ms/step - loss: 1.3863 - accuracy: 0.2456 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 264ms/step - loss: 1.3863 - accuracy: 0.2451 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3863 - accuracy: 0.2411 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2400 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2456 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2473 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2386 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 264ms/step - loss: 1.3863 - accuracy: 0.2411 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2443 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2478 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2459 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 262ms/step - loss: 1.3863 - accuracy: 0.2379 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2444 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2452 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2413 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2417 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2433 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2443 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2398 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2433 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2444 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2403 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 261ms/step - loss: 1.3864 - accuracy: 0.2413 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3864 - accuracy: 0.2478 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2414 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 259ms/step - loss: 1.3864 - accuracy: 0.2386 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2405 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3864 - accuracy: 0.2478 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3864 - accuracy: 0.2383 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2357 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2433 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3864 - accuracy: 0.2395 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3864 - accuracy: 0.2362 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 263ms/step - loss: 1.3863 - accuracy: 0.2424 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2435 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2402 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2444 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2473 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2392 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2430 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2449 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2402 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2429 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2408 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 264ms/step - loss: 1.3864 - accuracy: 0.2413 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2392 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2411 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2414 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2425 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2452 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2378 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2419 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2427 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2405 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2392 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 36s 264ms/step - loss: 1.3864 - accuracy: 0.2457 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 34s 264ms/step - loss: 1.3864 - accuracy: 0.2457 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3864 - accuracy: 0.2416 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2440 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3864 - accuracy: 0.2422 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2337 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2468 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2395 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3864 - accuracy: 0.2413 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2427 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2356 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 36s 265ms/step - loss: 1.3863 - accuracy: 0.2398 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 264ms/step - loss: 1.3863 - accuracy: 0.2406 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2422 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2433 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2479 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2398 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3863 - accuracy: 0.2387 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2462 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2408 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2441 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 259ms/step - loss: 1.3863 - accuracy: 0.2416 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 36s 264ms/step - loss: 1.3863 - accuracy: 0.2489 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2444 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2468 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2449 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2438 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2435 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 264ms/step - loss: 1.3863 - accuracy: 0.2448 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 258ms/step - loss: 1.3863 - accuracy: 0.2430 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 259ms/step - loss: 1.3863 - accuracy: 0.2386 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2451 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2432 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 265ms/step - loss: 1.3864 - accuracy: 0.2408 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3864 - accuracy: 0.2432 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3864 - accuracy: 0.2424 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3864 - accuracy: 0.2429 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3864 - accuracy: 0.2352 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3864 - accuracy: 0.2390 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3864 - accuracy: 0.2421 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3864 - accuracy: 0.2397 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3864 - accuracy: 0.2373 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2422 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2402 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 36s 266ms/step - loss: 1.3863 - accuracy: 0.2400 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 264ms/step - loss: 1.3863 - accuracy: 0.2419 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2425 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 34s 264ms/step - loss: 1.3863 - accuracy: 0.2443 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 264ms/step - loss: 1.3863 - accuracy: 0.2443 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2424 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 34s 264ms/step - loss: 1.3863 - accuracy: 0.2359 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2441 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2402 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 264ms/step - loss: 1.3863 - accuracy: 0.2411 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 34s 264ms/step - loss: 1.3863 - accuracy: 0.2454 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 36s 264ms/step - loss: 1.3863 - accuracy: 0.2454 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2435 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2435 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2471 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2419 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2437 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2421 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2406 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2425 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2433 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2367 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 262ms/step - loss: 1.3864 - accuracy: 0.2356 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2435 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2351 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2403 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2383 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2395 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2402 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2433 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2414 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3864 - accuracy: 0.2449 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2383 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 262ms/step - loss: 1.3863 - accuracy: 0.2449 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 259ms/step - loss: 1.3863 - accuracy: 0.2448 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 258ms/step - loss: 1.3863 - accuracy: 0.2387 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2395 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2405 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2414 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2422 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2414 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2383 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2375 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2443 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 36s 265ms/step - loss: 1.3864 - accuracy: 0.2444 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2446 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2438 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2413 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2465 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2429 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2462 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2406 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2413 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2417 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2408 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 262ms/step - loss: 1.3864 - accuracy: 0.2429 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2444 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2402 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2362 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2419 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2405 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2416 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2422 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3864 - accuracy: 0.2360 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 258ms/step - loss: 1.3864 - accuracy: 0.2379 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3864 - accuracy: 0.2422 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 262ms/step - loss: 1.3863 - accuracy: 0.2390 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2427 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2400 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2486 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2475 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2489 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2500 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2500 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2500 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2492 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2495 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 36s 264ms/step - loss: 1.3863 - accuracy: 0.2441 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2432 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3863 - accuracy: 0.2440 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2456 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2475 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 259ms/step - loss: 1.3863 - accuracy: 0.2449 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2484 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2459 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2462 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2440 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2346 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 264ms/step - loss: 1.3864 - accuracy: 0.2446 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2384 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3864 - accuracy: 0.2422 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3864 - accuracy: 0.2395 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 161s 1s/step - loss: 1.3864 - accuracy: 0.2448 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 32s 253ms/step - loss: 1.3864 - accuracy: 0.2419 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 32s 255ms/step - loss: 1.3864 - accuracy: 0.2381 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 32s 255ms/step - loss: 1.3864 - accuracy: 0.2368 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 32s 256ms/step - loss: 1.3864 - accuracy: 0.2389 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 258ms/step - loss: 1.3864 - accuracy: 0.2457 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 259ms/step - loss: 1.3864 - accuracy: 0.2425 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 35s 262ms/step - loss: 1.3863 - accuracy: 0.2371 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 33s 261ms/step - loss: 1.3863 - accuracy: 0.2410 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2433 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2467 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 33s 260ms/step - loss: 1.3863 - accuracy: 0.2483 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2451 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2424 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 33s 262ms/step - loss: 1.3863 - accuracy: 0.2457 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2422 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2438 - val_loss: 1.3863 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 33s 263ms/step - loss: 1.3863 - accuracy: 0.2476 - val_loss: 1.3863 - val_accuracy: 0.2500\n"
          ]
        }
      ],
      "source": [
        "mejores_metricas = obtener_mejores_metricas(rangos_drop=[0.3,0.4,0.5,0.6,0.7], rangos_neu=[300,400,600], rangos_opt=[\"Adamax\",\"RMSprop\",\"adadelta\"],,callbacks=callbacks2,mod=VGG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9f_mpff23Vkd",
        "outputId": "f8523da1-13ad-4cc6-d3e6-679e72c2111f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([['0.0', '0.0', '0.0', '0.0'],\n",
              "       ['0.3', '300', 'Adamax', '0.9926470518112183'],\n",
              "       ['0.3', '300', 'adadelta', '0.9852941036224365'],\n",
              "       ['0.3', '400', 'Adamax', '1.0'],\n",
              "       ['0.3', '400', 'RMSprop', '0.9522058963775635'],\n",
              "       ['0.3', '400', 'adadelta', '0.9963235259056091'],\n",
              "       ['0.3', '600', 'Adamax', '1.0']], dtype='<U32')"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "mejores_metricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yUnnWKrSICTA",
        "outputId": "62d112a2-bd01-45b2-b734-97a9956cd926"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tiempo total de  busqueda por rejilla VGG16: 19703.78045153618 Seg\n"
          ]
        }
      ],
      "source": [
        "final=g.time()\n",
        "print(f\"Tiempo total de  busqueda por rejilla VGG16: {final-inicio} Seg\",)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AuTKXQPWjF9N"
      },
      "outputs": [],
      "source": [
        "#guardar los resultados al archivo de txt\n",
        "file = open(Guardar_CNNVGG+\"/resultados_de_busqueda_por_rejilla.txt\", \"w+\")\n",
        "content = str(mejores_metricas)\n",
        "file.write(content)\n",
        "file.close()\n",
        "\n",
        "# Obtener el índice de la fila con el máximo valor de accuracy\n",
        "max_index = np.argmax(mejores_metricas[:, -1])\n",
        "\n",
        "# Obtener los parámetros correspondientes a la fila con el máximo valor de accuracy\n",
        "dropout_max = float(mejores_metricas[max_index, 0])\n",
        "neuronas_max = int(mejores_metricas[max_index, 1])\n",
        "optimizador_max = str(mejores_metricas[max_index, 2])\n",
        "\n",
        "# Recuperamos un modelo CNN estandar con la función VGG() con los parámetros correspondientes al máximo valor de accuracy\n",
        "modelo_VGG = VGG(dropout1=dropout_max,dropout2=dropout_max+0.1,neuronas=neuronas_max,optimizador=optimizador_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1ms05oy6mI65"
      },
      "outputs": [],
      "source": [
        "#Entrenamos nuevamente el modelo para obtener las metricas\n",
        "\"\"\"CUANDO EXISTÁN DOS MODELOS ÓPTIMOS CON MISMO ACC: Antes de ejecutar el siguiente código verifique que la carpeta de guardado(Guardar_CNNVGG) esté vacía de lo contrario el modelo\n",
        "y los resultados se mostrarán en funcion del último modelo guardado en lugar del siguiente.\n",
        "\"\"\"\n",
        "historyvgg16 = modelo_VGG.fit(train_dataset, epochs=100, validation_data=validation_dataset, callbacks=callbacks2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "luKIYE_rmSfq",
        "outputId": "6af8f6a3-d1f7-436b-9380-7485d789d65a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27/27 [==============================] - 3s 109ms/step - loss: 0.0256 - accuracy: 0.9888\n",
            "Test ACC : 0.989\n"
          ]
        }
      ],
      "source": [
        "#EVALUACION FINAL DEL MODELO VGG para determinar su ACC global\n",
        "\n",
        "test_model_vgg = keras.models.load_model(Guardar_CNNVGG)\n",
        "test_loss, test_acc = test_model_vgg.evaluate(test_dataset)\n",
        "print(f\"Test ACC : {test_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bbPJNUXHmgFO"
      },
      "outputs": [],
      "source": [
        "graficar_curva_aprendizaje(historyvgg16,plt=plt)\n",
        "#la grafica salió rara porque no se entrenó correctamente, pero el modelo entrenado se cargó desde el archivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4DnyaQkamgFO",
        "outputId": "457f1833-fff4-445f-a0d0-cb31d3c0225f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27/27 [==============================] - 2s 51ms/step\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAuoAAAMDCAYAAAD0WzBYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABtzklEQVR4nO3deVxU9f7H8fewKSCSooK4oKiIQpbZpqYmWmQuqZS2/LQsNW2x0rott2vmrTRtu2nazZtbZWW55K6FpmamuQdq5gqiqIhLsg/M7w9ykgRjFpgz8Hrexzwe4znfOedD90QfP/M5n2OyWCwWAQAAADAUD1cHAAAAAOByJOoAAACAAZGoAwAAAAZEog4AAAAYEIk6AAAAYEAk6gAAAIABkagDAAAABkSiDgAAABgQiToAAABgQF6uDsBo8tIOujoEuBHf0A6uDgEAUImZc1NcHYKVkXIo71rhrg7BKaioAwAAAAZERR0AAACOK8h3dQQVDhV1AAAAwIBI1AEAAAADovUFAAAAjrMUuDqCCoeKOgAAAGBAJOoAAACAAdH6AgAAAMcV0PribFTUAQAAAAMiUQcAAAAMiNYXAAAAOMzC1Beno6IOAAAAGBAVdQAAADiOm0mdjoo6AAAAYEAk6gAAAIAB0foCAAAAx3EzqdNRUQcAAAAMiEQdAAAAMCBaXwAAAOC4gnxXR1DhUFEHAAAADIiKOgAAABzHzaROR0UdAAAAMCASdQAAAMCAaH0BAACA4wpofXE2KuoAAACAAZGoAwAAAAZE6wsAAAAcZmHqi9NRUQcAAAAMiEQdAAAAMCBaXwAAAOA4pr44HRV1AAAAwICoqAMAAMBx3EzqdFTUAQAAAAMiUQcAAAAMiNYXAAAAOK4g39URVDhU1AEAAAADIlEHAAAADIjWFwAAADiOqS9OR0UdAAAAMCAq6gAAAHAcTyZ1OirqAAAAgAGRqAMAAAAGROsLAAAAHMfNpE5HRR0AAAAwIBJ1AAAAwIBofQEAAIDjmPridFTUAQAAAAOiog4AAACHWSz5rg6hwqGiDgAAABgQiToAAABgQLS+AAAAwHHMUXc6KuoAAACAAZGoAwAAAAZE6wsAAAAcxxx1p6OiDgAAABgQiToAAABgQLS+AAAAwHFMfXE6KuoAAACAAVFRBwAAgOMK8l0dQYVDRR0AAAAwIBJ1AAAAwIBofQEAAIDjuJnU6aioAwAAAAZERR0AAAD4i99//13Tp0/Xd999p6NHj0qSgoOD1aZNG40YMULBwcFF1iclJWnSpEnauHGjzp07p5CQEMXGxmr48OHy9/e3KwYq6gAAAHBcQYFxXg7av3+/7rzzTk2ZMkU5OTnq0KGDbr75Znl6eurrr79WcnJykfWJiYnq3bu3Fi1apDp16qhLly7Kz8/XtGnTdO+99+r333+3Kw4q6gAAAMAfzp8/r4cfflhnz57VW2+9pZ49exbZn5SUpGrVqln/nJ+fr5EjRyojI0OjRo3S0KFDJUm5ubkaMWKE1qxZo4kTJ2rs2LE2x0JFHQAAAI6zFBjn5YDJkyfrxIkTGjVq1GVJuiQ1bNhQNWvWtP45Pj5ehw8fVkREhIYMGWLd7uPjo7Fjx8rLy0vz5s3TmTNnbI6FRB0AAACQlJOTo/nz58vX11f9+/cv1WfWrFkjSYqNjZXJZCqyr06dOmrTpo3MZrPWrl1rczy0vgAAAACSEhIS9Pvvv6tNmzby9fXVxo0btX79el24cEH169dX165dFR4eXuQze/bskSRFR0cXe8yoqCht2rRJe/futTkeEnUAAAA4zgk3cbra/v37JUlBQUEaMWKEVq5cWWT/u+++q2HDhumpp56ybjt27JgkKSQkpNhjXpwOc3GdLUjUAQAAUKF06dLlivvj4+OL3X7u3DlJf7azPPfcc+rZs6c8PT21fPlyTZgwQVOmTFFoaKjuueceSVJmZqYkydfXt9hjXhzNmJGRYfPPQY86AAAAIKngj28F8vLyNGzYMA0ePFjBwcGqVauWBgwYoJEjR0qSpkyZUi7xUFEHAACA4wzU+lJSxfzv+Pn5Wd9frJhfql+/fho/fryOHTum5ORkNWjQQH5+fjp37pyysrKKPebFSro9Dz2iog4AAABIqlevnqTC0Yp/ffKoVJhsXxzNeOrUKUlSaGioJCk1NbXYY544caLIOluQqAMAAACSWrZsKanwYUXF9ZTn5+dbnzJ6sfreokULSYUTY4qTmJgoSYqMjLQ5HlpfoM1bd+qrRcu1bVei0s+clb+fn+oG11aba6I1eEA/1Qoq/Jvj5m279PCTz5fqmDe0bqUZk98sy7BhMDff1EYjRz6q9u1uVGBggI4fP6kVK9do3Pj3dexY8VUGVE5cK7AF14v7sFjyXR2Cw+rWrauoqCglJiZq06ZNiomJKbJ/y5YtysvLk6+vr3VMY+fOnTV//nytXLlSjz/+eJFZ6idPntTWrVvl5eWljh072hyP21bU09LSFBUVpebNm+vxxx93dThuqaCgQK9OeF8Pj3hBy79bq4L8AjVvGq6rqgfo0JGj+vSrb5R09M9RQgHV/NS6VcsSX61aNreuva5VlCt+JLjIw4Pu09rvF6hvn+7y8PBQQuKvqlnzKg0f9qB2bPtOrVq1dHWIMAiuFdiC6wWuMHToUEnShAkTdPToUev2EydO6PXXX5ck3X333fLx8ZEkxcTEqFGjRtq3b5+mTZtmXZ+bm6vRo0fLbDYrLi6uyNNMS8tksVgsjvwwrjJjxgyNHz9ekuTt7a1169bZ9Q/gr/LSDjp8DHfxxjtTNGfeYjVvGq5X/vGkWkX9+ZVMntms7TsT1ahhfdWpHVSq4323doOefuk1mUwmLfvyYzWoV7esQjcM39AOrg7B5aKjI7Vl80p5eXlpwsTJGv3KRJnNZvn6VtWHUyfogfvjdPDgEUW3ulW5ubmuDhcuxLUCW3C9lI45N8XVIVhlfT/d1SFY+d76sEOfHzNmjD7//HP5+fnpuuuuk4eHh7Zv367ff/9d1157rWbOnFlkHGNCQoIGDBigzMxMRUVFKSwsTDt37lRKSooiIiI0Z84cBQQE2ByH21bUFyxYIKnw0ax5eXlaunSpiyNyL1t2/KI58xYruE4tzZj8ZpEkXZK8vbx0Y5trSp2kS9KCpaskFba9VIYkHYX+9fJIeXl5acOGzXrpn+NkNpslSVlZ2Roy9FkdPHhE4eFheujB0j2KGRUX1wpswfUCVxozZozeeustNW/eXNu3b9emTZsUGhqqUaNGafbs2ZfNTI+OjtbChQvVs2dPnThxQt9++608PDw0ePBgffHFF3Yl6ZKbJup79uzRr7/+qqCgIL388suS/kzcUTqzPp8vSXrovjhVD6jm8PHSTqdrw09bJUl9e9zu8PHgHvz8fHVnt8L+vf9O++Sy/bm5uZr9yVxJUv9+vco1NhgL1wpswfUCI+jZs6e++OILbdu2Tbt27dKiRYs0dOhQValSpdj1YWFheuutt7RhwwYlJCTou+++03PPPWfXWMaL3PJm0otJeffu3RUTE6MaNWooMTFR+/btU0REhIujM77c3Fz9sGmLJKndDa11JDlFXy9aoX0HDsnDZFJ444bqeXuMIiOalPqY3yz/Tub8fAVU81fXW9uXVegwmNbXRlurCuvX/1TsmnXrCrffeGNrmUwmuWm3HRzEtQJbcL24KYtx5qhXFG5XUTebzVqyZIkkqXfv3vL29lb37t0lUVUvrb2/HVReXuFXiDsT96rvwMc0Y87X2rBpq9b/tEWzPp+vex5+Uu9/NKvUx1y49FtJ0p233aqqJfxNExVPs2aFd7zn5OQoOflYsWsOHDwiqfDRymFh9cstNhgL1wpswfUCFHK7RH3dunU6ffq0IiIiFBVVOFmkd+/ekqTFixcrP9/9RwOVtVOn063vx06crCaNG+rT/76jbWu+0ap5M9W/T3dZLBZ9NOsLfb1oxd8eb9vOBB1KKrwruk932l4qk5o1r5IknTlzrsQ16elnrO9rXBVY1iHBoLhWYAuuF6CQ2yXqCxculCTddddd1m1XX321mjZtqlOnTumHH35wUWTuIzMr2/rex9tbH779b10b3UI+Pj4KDQnWv559Qh3b3ShJmvLxp3/7l5/5f9xEGtG0saJb0HpUmVz8ajo3N6/ENdnZOdb3fn6+Ja5Dxca1AltwvbipggLjvCoIt0rUz549q9WrV8vT01M9e/Yssu9i4k77y9+r+sfcT0nq1a2Lata46rI1g+6PkySdTDutvb+VPLIyMzNLq1YX/uWIanrlk5WVJUny8fEucU3Vqn+2QmVmZpV5TDAmrhXYgusFKORWifrSpUuVl5entm3bKjg4uMi+Xr16ycPDQ6tXr9b58+ddFKF7CKz+54ig8LAGxa5p0qih9X3K8ZKf/LZi9TplZmXJ29tLPWNjSlyHiuni19I1apT8tXPNmjX+XH+25K+xUbFxrcAWXC9uylJgnFcF4VZTXy62vRw8eFD33XffZfu9vLyUk5OjZcuW6d577y3n6NxH40uS85KqFZduz88v+YK/ODs9pkM7XRVY3UkRwl3s23dAklSlShU1bFhPSUmXP3ijSXiYpMIK2ZEjRy/bj8qBawW24HoBCrlNRf3AgQPatWuXJOnYsWPatm3bZa+LTyaj/eXKateqqfqhIZKk5JTiq+XJKcet74Pr1Cp2zaEjR7V9125JzE6vrLbvSLB+Rd2hw83FrunYsXD7zz/vYHxaJca1AltwvQCF3CZRv/Qm0l9//bXY144dO+Tn56cdO3bo0KFDrg3Y4O687VZJ0tJv1xT76OV5i1dKkqoHVFN0ZLNij7FgaeGakODaantD67IJFIaWmZml5StWS5KGDv6/y/b7+Pho4IB+kqS5Xy0u19hgLFwrsAXXi5ty9Q2k3EzqGgUFBVq0aJEkXXYT6aV8fX3VtWtXSX8m9ijeg/f21VWB1ZV64pTGTpysrOw/J8EsXbXGOpbxofvi5HPJzacX5efna/Efv0R7d+sqDw+3uJRQBl57/T2ZzWa1b3+j3nj9RXl5FXbU+fpW1Uf/fUvh4WE6fDhZ02d87uJI4WpcK7AF1wsgmSxu8H3Rhg0b9PDDD6tWrVpat26dPD09S1y7bt06DRkyRHXr1tXq1attTiDz0kqecFLRbNuZoGGjRiszK0v+fr5qHNZAp9PP6viJk5Kkbl076c1X/lHsP8Pvf/hJTzz/qkwmk5bPnW5tpalsfEM7uDoEQxgy+P80edIb8vT01KlTp3Uk6aiaNW2swMDqOnPmrG6L7acdOxJdHSYMgGsFtuB6+Xvm3Mv7910la9UUV4dg5Xv7Y64OwSncogx6see8W7duV0zSJaldu3YKCgrS8ePH9dNPxT92GIWuuyZa33z6ofr1vlNXBVbXr/sPKiMzUzded40mjHleE8Y8X+JfdC7OTr/xulaVNknHn6b971Pd2rmvFn6zXBaLRVdHR+rs2fP68L+zde11XSv9f0jxJ64V2ILrxc24etJLBZz64hYV9fJUmSrqcBwVdQCAKxmqor5ysqtDsPKNfcLVITiFW41nBAAAgEFVoJs4jcItWl8AAACAyoZEHQAAADAgWl8AAADgOFpfnI6KOgAAAGBAJOoAAACAAdH6AgAAAMdVoPnlRkFFHQAAADAgEnUAAADAgGh9AQAAgOOY+uJ0VNQBAAAAA6KiDgAAAMdxM6nTUVEHAAAADIhEHQAAADAgWl8AAADgOG4mdToq6gAAAIABkagDAAAABkTrCwAAABzH1Beno6IOAAAAGBAVdQAAADiOm0mdjoo6AAAAYEAk6gAAAIAB0foCAAAAx9H64nRU1AEAAAADIlEHAAAADIjWFwAAADjOYnF1BBUOFXUAAADAgEjUAQAAAAOi9QUAAACOY+qL01FRBwAAAAyIijoAAAAcR0Xd6aioAwAAAAZEog4AAAAYEK0vAAAAcJyF1hdno6IOAAAAGBCJOgAAAGBAtL4AAADAcUx9cToq6gAAAIABUVEHAACA4ywWV0dQ4VBRBwAAAAyIRB0AAAAwIFpfAAAA4DhuJnU6KuoAAACAAZGoAwAAAAZE6wsAAAAcR+uL01FRBwAAAAyIRB0AAAAwIFpfAAAA4DgLrS/ORkUdAAAAMCAq6gAAAHCYpcDi6hAqHCrqAAAAgAGRqAMAAAAGROsLAAAAHMccdaejog4AAAAYEIk6AAAAYEC0vgAAAMBxzFF3OirqAAAAgAFRUQcAAIDjmKPudFTUAQAAAAMiUQcAAAAMiNYXAAAAOI456k5HRR0AAAAwIBJ1AAAAwIBofQEAAIDjaH1xOirqAAAAgAFRUQcAAIDjLMxRdzYq6gAAAIABkagDAAAABkTrCwAAABzHzaROR0UdAAAAMCASdQAAAMCAaH0BAACA4wqY+uJsVNQBAAAAAyJRBwAAAAyI1hcAAAA4zlJxpr688MILWrBgQYn7+/fvr7Fjx162PSkpSZMmTdLGjRt17tw5hYSEKDY2VsOHD5e/v7/NcZCoAwAAAMW45ZZbVLt27cu2t27d+rJtiYmJGjBggDIyMhQVFaXrr79eu3bt0rRp07R27VrNmTNHAQEBNp2fRB0AAACOq4A3kw4dOlQ33XTT367Lz8/XyJEjlZGRoVGjRmno0KGSpNzcXI0YMUJr1qzRxIkTi63CXwk96gAAAIAD4uPjdfjwYUVERGjIkCHW7T4+Pho7dqy8vLw0b948nTlzxqbjkqgDAAAADlizZo0kKTY2ViaTqci+OnXqqE2bNjKbzVq7dq1Nx6X15S98Qzu4OgS4kaxj610dAtwEv1sAVHSWgopzM+lF3377rb799lvl5uaqbt26at++vVq1anXZuj179kiSoqOjiz1OVFSUNm3apL1799p0fhJ1AAAAoBiffPJJkT+/99576tSpkyZMmKCrrrrKuv3YsWOSpJCQkGKPExwcXGRdaZGoAwAAoELp0qXLFffHx8dfcX9kZKReeeUV3Xzzzapbt67S09O1efNmvfPOO1q7dq2GDRumOXPmyMOjsIs8MzNTkuTr61vs8S6OZszIyLDp5yBRBwAAgOMq0NSXhx56qMif69Wrpz59+qhdu3bq1auXtm/frpUrV6pbt25lGgeJOgAAACqUv6uY2ys4OFh9+/bV9OnTtW7dOmui7ufnp3PnzikrK6vYz12spNv60COmvgAAAMBxlgLjvMpQo0aNJEknT560bgsNDZUkpaamFvuZEydOFFlXWiTqAAAAQCmdO3dOUtF+9BYtWkiSEhISiv1MYmKipMLed1uQqAMAAAClYLFYtGrVKklFRzF27txZkrRy5UpZLEV79U+ePKmtW7fKy8tLHTt2tOl8JOoAAABwXIHFOC8H7N69W4sXL1Zubm6R7RcuXNDLL7+sX375RX5+foqLi7Pui4mJUaNGjbRv3z5NmzbNuj03N1ejR4+W2WxWXFycatasaVMsJstf0/5KzsunnqtDgBvhgUcoLR54BKAsmHNTXB2CVcbYB1wdgpX/6M/s/ux3332nxx9/XIGBgYqOjlaNGjWUlpamPXv26Ny5c/Lz87POU79UQkKCBgwYoMzMTEVFRSksLEw7d+5USkqKIiIiNGfOHAUEBNgUC1NfAAAAgD80b95cAwYM0C+//KJ9+/bp7Nmz8vb2Vr169dS7d28NHDhQ9evXv+xz0dHRWrhwoSZNmqSNGzdq3759CgkJ0eDBg/XYY4/ZPPFFoqJ+GSrqsAUVdZQWFXUAZcFQFfUx97k6BCv/MZ+7OgSnoEcdAAAAMCASdQAAAMCA6FEHAACA4xyctoLLUVEHAAAADIiKOgAAABxnKXB1BBUOFXUAAADAgEjUAQAAAAOi9QUAAACO42ZSp6OiDgAAABgQiToAAABgQLS+AAAAwGGWAqa+OBsVdQAAAMCAqKgDAADAcdxM6nRU1AEAAAADIlEHAAAADIjWFwAAADiO1heno6IOAAAAGBCJOgAAAGBAtL4AAADAcRbmqDsbFXUAAADAgKioAwAAwHHcTOp0VNQBAAAAAyJRBwAAAAyI1hcAAAA4zELri9NRUQcAAAAMiEQdAAAAMCBaXwAAAOA4Wl+cjoo6AAAAYEAk6gAAAIAB0foCAAAAxxUUuDqCCoeKOgAAAGBAVNQBAADgOG4mdToq6gAAAIABkagDAAAABkTrCwAAABxH64vTUVEHAAAADIhEHQAAADAgWl8AAADgMIuF1hdno6IOAAAAGBAVdQAAADiOm0mdjoo6AAAAYEAk6gAAAIAB0foCAAAAx9H64nRU1AEAAAADIlEHAAAADIjWFwAAADjMQuuL01FRBwAAAAyIRB0AAAAwIFpfAAAA4DhaX5yOijoAAABgQFTUAQAA4LgCVwdQ8VBRBwAAAAyIRB0AAAAwIFpfAAAA4DDmqDsfFXUAAADAgEjUAQAAAAOi9QUAAACOo/XF6aioAwAAAAZERR0AAACOY46601FRBwAAAAyIRB0AAAAwIFpfAAAA4DDmqDsfFXUAAADAgEjUAQAAAAOi9QUluvmmNho58lG1b3ejAgMDdPz4Sa1YuUbjxr+vY8dSXR0eXGDz1p36atFybduVqPQzZ+Xv56e6wbXV5ppoDR7QT7WCahau27ZLDz/5fKmOeUPrVpox+c2yDBsGw+8W2ILrxY0w9cXpTBaLxS0aimJiYpSSklJkm8lkUmBgoJo3b65+/fqpR48eDp/Hy6eew8eoCB4edJ+mTnlTnp6eOnXqtI4kHVWzpo0VGFhd6eln1PX2ftq1a7erw3S5rGPrXR1CuSgoKNC/35qsr75ZLkmqHVRTwXVq6cKFDKWeTFN2To5mT5mo666JliTt2bdfb7w7tcTj5ZvztWv3r5KkRx+8T08OHVj2P4SL+YZ2cHUIhsDvFtiC6+XvmXNT/n5ROTkTd6urQ7CqMe97V4fgFG6XqN9yyy2qXbu2JCk3N1dJSUn65ZdfJEn333+/XnnlFYfOQ6IuRUdHasvmlfLy8tKEiZM1+pWJMpvN8vWtqg+nTtAD98fp4MEjim51q3Jzc10drktVlkT9jXemaM68xWreNFyv/ONJtYqKtO7LM5u1fWeiGjWsrzq1g0p1vO/WbtDTL70mk8mkZV9+rAb16pZV6IZBos7vFtiG66V0SNSLV1ESdbfrUR86dKjGjx+v8ePH65133tHXX3+tDz/8UCaTSXPmzNHu3ZX7b9bO8K+XR8rLy0sbNmzWS/8cJ7PZLEnKysrWkKHP6uDBIwoPD9NDD/Z3caQoD1t2/KI58xYruE4tzZj8ZpEkXZK8vbx0Y5trSp2kS9KCpaskFba9VIYkHYX43QJbcL24H0uBxTCvisLtEvXidO7cWW3atJEkbd682cXRuDc/P1/d2S1GkvTfaZ9ctj83N1ezP5krSerfr1e5xgbXmPX5fEnSQ/fFqXpANYePl3Y6XRt+2ipJ6tvjdoePB/fA7xbYgusFKFRhbiYNCiqs5uXn57s4EvfW+tpo+fr6SpLWr/+p2DXr1hVuv/HG1jKZTHKT7inYITc3Vz9s2iJJandDax1JTtHXi1Zo34FD8jCZFN64oXreHqPIiCalPuY3y7+TOT9fAdX81fXW9mUVOgyG3y2wBdeLm+JmUqerEIm62WzWnj17JElNmpQ+YcDlmjULlyTl5OQoOflYsWsOHDwiSfL19VVYWH0dPpxcbvGhfO397aDy8gq/bt6ZuFevvz1FOZf0gq7/aYtmf7FAQwb214ihD5bqmAuXfitJuvO2W1W1ShXnBw1D4ncLbMH1AhRy69aX3NxcHThwQC+88IKSkpLUsmVLdejADVuOqFnzKknSmTPnSlyTnn7G+r7GVYFlHRJc6NTpdOv7sRMnq0njhvr0v+9o25pvtGreTPXv010Wi0UfzfpCXy9a8bfH27YzQYeSjkqS+nSn7aUy4XcLbMH1AhRyu4r6wIGXj3EzmUx64IEH9Mwzz8jT09MFUVUcF79qzM3NK3FNdnaO9b2fn2+ZxwTXyczKtr738fbWh2//WzVrXCVJCg0J1r+efULHT5zSuh83a8rHn6pP99uu+O/g/D9uIo1o2ljRLSLKNHYYC79bYAuuF/dkofXF6dwuUb90PKPFYtGpU6f0yy+/aO7cwptKXnjhBfn4+LgyRLeWlZUlSfLx8S5xTdWqf7YrZGZmlXlMcJ2ql/y71KtbF2uSfqlB98dp3Y+bdTLttPb+dlBRkc2KPVZmZpZWrf5BEtX0yojfLbAF1wtQyO0S9aFDh+qmm24qsu3ChQt6+umn9dlnn6mgoEBjxoxxTXAVwMWvGWvUKPlrxJo1a/y5/mzJX0vC/QVWD7C+Dw9rUOyaJo0aWt+nHE8tMVFfsXqdMrOy5O3tpZ6xMc4NFIbH7xbYgusFKOTWPeoXVatWTf/4xz8kSXPnztX58+ddHJH72rfvgCSpSpUqatiw+Ic/NQkPk1RY8Thy5Gi5xYby1/iS5Lykytal2/PzS/7e8+Ls9JgO7XRVYHUnRQh3we8W2ILrxU0VGOhVQVSIRF2SGjQoTCjy8/N15MgRF0fjvrbvSLB+5dihw83FrunYsXD7zz/vYBxWBVe7Vk3VDw2RJCWnpBa7JjnluPV9cJ1axa45dOSotv/xmG9mp1dO/G6BLbhegEIVJlFPSkqyvvfz83NhJO4tMzNLy1esliQNHfx/l+338fHRwAH9JElzv1pcrrHBNe687VZJ0tJv1xT7mO55i1dKkqoHVFN0CW0vC5YWrgkJrq22N7Qum0BhaPxugS24XtyTpcA4r4qiQiTqFy5c0IQJEyRJYWFhCg8Pd3FE7u2119+T2WxW+/Y36o3XX5SXV+GtDL6+VfXRf99SeHiYDh9O1vQZn7s4UpSHB+/tq6sCqyv1xCmNnThZWdl/ToJZumqNdSzjQ/fFFXsjd35+vhb/8R/c3t26ysOjQvzagR343QJbcL0AksniJt8XxcTEKCUl5bKpL2lpafrll1907tw5+fv763//+5+uu+46u8/j5VN8L1xlM2Tw/2nypDfk6empU6dO60jSUTVr2liBgdV15sxZ3RbbTzt2JLo6TJfLOrbe1SGUi207EzRs1GhlZmXJ389XjcMa6HT6WR0/cVKS1K1rJ735yj+KTcK//+EnPfH8qzKZTFo+d7q1laay8Q3lGQ8Sv1tgG66Xv2fOTXF1CFZp3Tq5OgSrWsvXujoEp3C7RP2vfH19Va9ePbVr104PP/yw6tat69B5SNT/1Pbm6zVq1DC1a3uDAgMDlJp6SstXrNa48e8r5ZK+5MqssiTqknQ89aSmffKlNmzaqpNpp+VbtaoimzXR3b3uULeunWQymYr93IgXx2r1uo26qc01+vj98eUctXGQqP+J3y2wBdfLlRkqUY81UKK+kkS9QiJRhy0qU6IOx5CoAygLJOrFqyiJOs2iAAAAgAG53QOPAAAAYDwVadqKUVBRBwAAAAyIijoAAAAcRkXd+aioAwAAACWwWCwaOHCgmjdvrubNm+vAgQPFrktKStJzzz2nW265RVdffbVuu+02vfXWW8rIyLD73CTqAAAAQAm+/PJLbdq0qcQxxJKUmJio3r17a9GiRapTp466dOmi/Px8TZs2Tffee69+//13u85Nog4AAACHWQqM83KW1NRUTZw4UR06dFBoaGixa/Lz8zVy5EhlZGRo1KhRmj9/vt577z2tWLFCnTt31r59+zRx4kS7zk+iDgAAABRj9OjRKigo0Kuvvlrimvj4eB0+fFgREREaMmSIdbuPj4/Gjh0rLy8vzZs3T2fOnLH5/CTqAAAAwF8sXLhQa9eu1VNPPaV69Up+IOaaNWskSbGxsZe1x9SpU0dt2rSR2WzW2rW2P4SJRB0AAACOs5iM83JQWlqaxo0bp6uvvloDBw684to9e/ZIkqKjo4vdHxUVJUnau3evzXGQqAMAAACXGDt2rC5cuKDXXntNHh5XTpePHTsmSQoJCSl2f3BwcJF1tmCOOgAAACqULl26XHF/fHx8iftWrlyplStXaujQoYqMjPzbc2VmZkqSfH19i93v7+8vSXaNaSRRBwAAgMMM9cAjT/s+dvbsWY0dO1ZhYWF64oknnBuTHUjUAQAAUKFcqWJ+JePGjVNaWpreeustValSpVSf8fPz07lz55SVlVXs/ouV9IuVdVuQqAMAAMBhlgLHb+J0tfj4eFWpUkVTpkzRlClTiuw7deqUJOn555+Xr6+vHnjgAd1xxx0KDQ3VuXPnlJqaWmyrzIkTJySpxDnsV0KiDgAAAPwhJydHmzdvLnH/L7/8IunPPvgWLVpoz549SkhI0K233nrZ+sTEREkqVb/7X5GoAwAAAJK2bNlS4r6YmBilpKRo2bJlatKkiXV7586dNX/+fK1cuVKPP/54kVnqJ0+e1NatW+Xl5aWOHTvaHA/jGQEAAOAwS4FxXuUpJiZGjRo10r59+zRt2jTr9tzcXI0ePVpms1lxcXGqWbOmzcemog4AAADYycvLS2+//bYGDBigt99+WytWrFBYWJh27typlJQURURE6LnnnrPr2FTUAQAAAAdER0dr4cKF6tmzp06cOKFvv/1WHh4eGjx4sL744gsFBATYdVyTxWKxODlWt+blU8/VIcCNZB1b7+oQ4CZ8Qzu4OgQAFZA5N8XVIViltI1xdQhW9TaudnUITkFFHQAAADAgp/Wom81mpaSkKCMjQ/7+/qpXr568vGiBBwAAqAwM9WTSCsLhTHrXrl2aOnWqNm7cqJycHOv2KlWqqH379ho2bJiuvvpqR08DAAAAVCoOtb7MnTtX999/v77//ntlZ2fLYrFYX9nZ2YqPj9d9992nr776ylnxAgAAAJWC3RX13bt369VXX1V+fr6uv/56Pfzww4qIiFCdOnV08uRJ7du3T9OnT9eWLVs0ZswYRUVFqWXLls6MHQAAAAZhKTD9/SLYxO6K+scff6z8/HwNGjRIn376qWJiYlS/fn35+Piofv36iomJ0aeffqqHH35Y+fn5mjFjhjPjBgAAACo0uxP1LVu2qHr16ho5cuQV1z3zzDMKCAjQ5s2b7T0VAAAAUOnYnaifPn1aYWFh8vb2vuI6b29vNWrUSOnp6faeCgAAAAZnsRjnVVHYnaj7+/srLS2tVGvT0tLk5+dn76kAAACASsfuRL1ly5ZKTU1VfHz8Fdd99913On78ODeSAgAAADawO1GPi4uTxWLRs88+qxkzZigrK6vI/qysLE2fPl3PPfecTCaT7r77boeDBQAAgDFZCkyGeVUUJovF/k6eESNGaNWqVTKZTKpSpYrq1aunWrVqKS0tTSkpKcrJyZHFYlFsbKz+85//ODPuMuPlU8/VIcCNZB1b7+oQ4CZ8Qzu4OgQAFZA5N8XVIVgdua6rq0OwCtv2natDcAqHnkz67rvvaurUqZo5c6YuXLigAwcO6MCBA9b91apV00MPPaThw4c7HCgAAACMqyJVso3CoYr6RVlZWdqyZYsOHTqkjIwM+fv7Kzw8XG3atJGvr68z4iw3VNRhCyrqKC0q6gDKgpEq6oevvc3VIVg12vGtq0NwCrsr6i+++KI8PDz0yiuvyNfXVx06dFCHDvyHCAAAAHAGuxP1xYsXKzw8XD4+Ps6MBwAAAG6oIs0vNwq7p74EBQXJy8uhFncAAAAAJbA7Ub/55pt14MABXbhwwZnxAAAAAJADifqwYcPk4eGhsWPHqqCgwJkxAQAAwM24enZ6RZyjbnfvSlpamoYPH67//Oc/2rNnj3r37q2mTZvKz8+vxM/ccMMN9p4OAAAAqFTsHs8YGRkpk6n0f2MxmUzavXu3PacqV4xnhC0Yz4jSYjwjgLJgpPGMB6JjXR2CVZOEla4OwSnsrqiHhoY6Mw4AAAAAl7A7UV+9erUz4wAAAABwCeYrAgAAwGEWZos4nd1TXwAAAACUHYcr6gUFBVq1apU2btyo1NRUZWdna9asWdb9CQkJysrKUps2beThwd8LAAAAgNJwKFHfv3+/RowYoUOHDuni8Ji/ToJZtGiRPvnkE02fPl1t27Z15HQAAAAwqAJLxZlfbhR2l7jT09M1aNAgHTx4UC1atNATTzyhsLCwy9b16NFDFotF8fHxDgUKAAAAVCZ2V9SnTZumU6dOqU+fPnrjjTdkMpn0448/Kikpqci6Vq1aydfXV1u2bHE4WAAAABiThYq609ldUV+zZo18fHz0z3/+828ffNSgQQMdPXrU3lMBAAAAlY7difqxY8fUqFEjVatW7W/X+vr6Kjs7295TAQAAAJWO3a0vPj4+ysnJKdXa9PT0UiX0AAAAcE+WAlpfnM3uinrDhg2VkpKiM2fOXHFdcnKykpOT1axZM3tPBQAAAFQ6difqMTExMpvNeu+990pcY7FYNH78eJlMJt122232ngoAAACodOxufXnwwQc1d+5czZ07V+np6erfv79yc3MlFfav7927VzNmzNDPP/+sBg0aqF+/fk4LGgAAAMbyxyN14EQmi8X+f6x79+7Vo48+qhMnThQ7+cVisahOnTr6+OOP3ab1xcunnqtDgBvJOrbe1SHATfiGdnB1CAAqIHNuiqtDsNrT7E5Xh2DV4rdlrg7BKexufZGkyMhILVq0SI8++qgaNmwoi8VifYWEhGjQoEFauHCh2yTpAAAAgFE4VFH/q6ysLJ0/f17+/v5uO+WFijpsQUUdpUVFHUBZMFJFfXeT7q4OwarlgaWuDsEp7O5RL46vr698fX2deUgAAACgUnJqog4AAIDKqcDCHHVnK1WiPnnyZKec7IknnnDKcQAAAICKrtSJenFTXUrLYrHIZDKRqAMAAAClVKpEvXfv3sUm6rm5uVq5cqXMZrNq1aql8PBw1apVS2lpaTp06JBOnTolb29v3X777fLx8XF68AAAADAGC60vTleqRH38+PGXbcvJydHAgQNVvXp1vfTSS7rzzjvl4fHntMeCggItW7ZM48aNU0pKimbPnu28qAEAAIAKzu456lOnTtWuXbs0depU9ejRo0iSLkkeHh7q0aOHPvjgA+3YsUNTp051OFgAAACgsrA7UV++fLkaNWqka6655orrrr32WjVu3FjLllWMJ0QBAADgchaLcV4Vhd2J+vHjx0s9M93X11epqan2ngoAAACodOyeo169enX99ttvSk9PV82aNUtcl56ert9++03Vq1e391QAAAAwOOaoO5/dFfV27dopLy9PzzzzjNLT04tdk56ermeeeUZms1nt27e3O0gAAACgsrG7oj5ixAitWbNGmzdvVkxMjLp166amTZsqKChIp0+f1v79+7V8+XJlZ2crICBAI0aMcGbcAAAAQIVmd6Jev359zZw5U88884ySkpK0cOHCy9ZYLBY1aNBA77zzjurXr+9InAAAADAw5qg7n92JuiRFRUVpyZIlWr58udatW6eDBw8qIyND/v7+Cg8PV4cOHXTnnXfysCMAAADARg4l6pLk4+Oju+66S3fddZcz4gEAAAAgJyTqAAAAQEWaX24Udk99AQAAAFB2HK6onzhxQosXL9aePXt09uxZ5eXlFbvOZDJp1qxZjp4OAAAAqBQcStS//PJLvfbaazKbzdZtlku+9zCZTNZtF98DAACg4uGBR85nd6K+ZcsWjRkzRlWrVtUjjzyi5cuXKykpSa+//rrOnj2rnTt3avXq1fLy8tJjjz2m2rVrOzNuAAAAoEKzO1GfPXu2JGncuHG64447tHnzZiUlJSkuLs665sCBAxo+fLi++OILLViwwPFoy0FVL0ZJovR8Qzu4OgS4iYzEr1wdAtxI9av7uzoEwGbMUXc+u28m3bFjh6pXr67Y2NgS1zRp0kTvv/++jh07pilTpth7KgAAAKDSsTtRP3PmjEJDQ629556enpKk7OzsIusiIyPVuHFjrVmzxoEwAQAAgMrF7taXatWqFblxtHr16pKkY8eOKTw8vMhaHx8fHT582N5TAQAAwOC4mdT57K6oh4SE6NSpU9Y/N2nSRJK0YcOGIutOnTqlQ4cOqWrVqvaeCgAAAKh07E7UW7durTNnzliT9a5du8pisejtt9/W559/rt9++00//vijhg8frry8PN1www1OCxoAAACo6OxO1Dt16qSCggJ9//33kqRWrVqpV69eys7O1tixY9WrVy898sgjSkhIkK+vr5566ilnxQwAAACDsRjoVVHY3aPeqVMnbdu2Td7e3tZt48aNU9OmTbVgwQIdPXpUvr6+uuGGG/TUU0+pWbNmTgkYAAAAqAwcejKpn59fkT97enpq6NChGjp0qENBAQAAwL1wM6nz2d36AgAAAKDskKgDAAAABlSq1pfJkyc75WRPPPGEU44DAAAAY7HQ+uJ0pU7ULz6B1B4Wi0Umk4lEHQAAACilUiXqvXv3LjZRz83N1cqVK2U2m1WrVi2Fh4erVq1aSktL06FDh3Tq1Cl5e3vr9ttvl4+Pj9ODBwAAACqqUiXq48ePv2xbTk6OBg4cqOrVq+ull17SnXfeKQ+PP1veCwoKtGzZMo0bN04pKSmaPXu286IGAACAoRS4OoAKyO6bSadOnapdu3Zp6tSp6tGjR5EkXZI8PDzUo0cPffDBB9qxY4emTp3qcLAAAABAZWF3or58+XI1atRI11xzzRXXXXvttWrcuLGWLVtm76kAAABgcBaZDPOqKOxO1I8fPy5fX99SrfX19VVqaqq9pwIAAAAqHbsT9erVq+u3335Tenr6Fdelp6frt99+U7Vq1ew9FQAAAFDp2J2ot2vXTnl5eXrmmWdKTNbT09P1zDPPyGw2q3379nYHCQAAAGMrsBjnVVGUaupLcUaMGKE1a9Zo8+bNiomJUbdu3dS0aVMFBQXp9OnT2r9/v5YvX67s7GwFBARoxIgRzowbAAAAqNDsTtTr16+vmTNn6plnnlFSUpIWLlx42RqLxaIGDRronXfeUf369R2JEwAAAKhU7E7UJSkqKkpLlizR8uXLtW7dOh08eFAZGRny9/dXeHi4OnTooDvvvJOHHQEAAFRwBRVo2opR2J2oHzt2TJIUEhKiu+66S3fddZfTggIAAAAqO7sT9ZiYGAUFBWn9+vXOjAcAAACAHEjUq1Wrpnr16l32RFIAAABUPhXpQUNGYXeW3bhxY6WlpTkzFgAAAAB/sDtR7927t44dO6aNGzc6Mx4AAAC4oQIDvSoKuxP1+++/X7fffruefvppLVu2TAUFFekfCwAAAOBadveoP/jgg7JYLLpw4YJGjRql0aNHq3HjxvL19S12vclk0qxZs+wOFAAAACgPX375pTZu3Khff/1Vp0+fVkZGhgIDA3X11Vfr3nvvVefOnYv9XFJSkiZNmqSNGzfq3LlzCgkJUWxsrIYPHy5/f3+b4zBZLBa7HrQaGRlp24lMJu3Zs8eeU5Wran6NXR0C3Ei2OdfVIcBNZCR+5eoQ4EaqX93f1SHATeRkJ7s6BKtVwfe6OgSr20984dDn77jjDiUnJysiIkLBwcGqWrWqkpOTlZCQIEl6+OGH9fzzzxf5TGJiogYMGKCMjAxFRUWpYcOG2rVrl1JSUhQREaE5c+YoICDApjjsrqiPGzfO3o8CAAAAhjVu3DhFRERcVgXfsmWLhgwZounTp+uOO+7QNddcI0nKz8/XyJEjlZGRoVGjRmno0KGSpNzcXI0YMUJr1qzRxIkTNXbsWJvisDtR79Onj70fBQAAAAyrdevWxW6//vrr1a1bN82bN08bN260Jurx8fE6fPiwIiIiNGTIEOt6Hx8fjR07Vp07d9a8efP0zDPPqEaNGqWOgyHoAAAAcJirJ72U19QXL6/COrePj49125o1ayRJsbGxMpmKzpOvU6eO2rRpI7PZrLVr19p0Lqcl6mlpafrll1/0888/O+uQAAAAgGHs2bNHy5cvl6enpzp06FBkuyRFR0cX+7moqChJ0t69e206n92tLxctWrRIH330kQ4cOCCp8KbR3bt3W/dPmDBBCQkJmjhxooKDgx09HQAAAAzISIO6u3TpcsX98fHxpTrOvHnz9PPPPysvL08pKSnasWOHvLy8NGbMGDVr1sy67tixY5KkkJCQYo9zMQe+uK60HErUX3vtNX322WeyWCzy8vKSyWSS2WwusiYiIkLTp09XfHy87r//fkdOBwAAAJSbbdu2acGCBdY/+/r66qWXXlJcXFyRdZmZmdb9xbl4U2pGRoZN57c7UY+Pj9enn36qoKAgvfrqq7r11ls1cOBAbd++vci6zp07y2Qy6fvvvydRBwAAQJkrbcX877z++ut6/fXXlZmZqSNHjuiTTz7Rv/71L61atUqTJ09W1apVnXKektjdoz5nzhyZTCZNmDBBXbt2tTbW/1VgYKDq1q2rX3/91e4gAQAAYGwWmQzzcjY/Pz+1aNFCb7zxhu6++26tX79eM2bMKLJfkrKysor9/MVKuq0PPbI7UU9ISFBQUJDat2//t2tr1aql9PR0e08FAAAAGELv3r0lFa3ah4aGSpJSU1OL/cyJEyeKrCstuxP1jIwM1alTp1RrzWazPD097T0VAAAAYAg1a9aUpCJF6BYtWkiS9cmlf5WYmChJioyMtOlcdifqNWvWVEpKyt+uy8/P1+HDh5n4AgAAUIEVmIzzKkubNm2SJIWFhVm3de7cWZK0cuVKWSyWIutPnjyprVu3ysvLSx07drTpXHYn6tdee63Onz//t4PbFy9erMzMTF1//fX2ngoAAAAoFwkJCfr2228vm2QoFT7Y6L333pMk3XPPPdbtMTExatSokfbt26dp06ZZt+fm5mr06NEym82Ki4uzVuNLy+6pL/fff79WrVqlMWPG6IMPPlDLli0vW7Nx40a9/vrrMplMuu++++w9FQAAAFAuUlNT9cQTT6h69eqKiopSUFCQfv/9dx06dEhJSUmSpIcfflh33nmn9TNeXl56++23NWDAAL399ttasWKFwsLCtHPnTqWkpCgiIkLPPfeczbGYLH+tz9vgtdde06effiovLy9FR0crOTlZ6enp6t27t3799Vft2bNHFotFgwcP1rPPPmvvacpVNb/Grg4BbiTbnOvqEOAmMhK/cnUIcCPVr+7v6hDgJnKyk10dgtU3IcYZw31X6hy7P3vixAnNnTtXmzdvVlJSktLT0+Xh4aE6deqodevW6tevX4mdIkeOHNGkSZO0ceNGnTt3TiEhIYqNjdVjjz1m88QXyYZEffTo0br77rvVqlWrItunTZumqVOnWge9X6pq1aoaPny4Hn30UZsDcxUSddiCRB2lRaIOW5Coo7RI1IvnSKJuJKVO1CMjI2UymdSkSRPFxcXprrvusvbZXOxV37t3r86fPy8/Pz9FRESoc+fONvfiuBqJOmxBoo7SIlGHLUjUUVpGStQXGihR713ZEvV+/fpp165dhR8ymeTp6albb71VcXFx6tSpkzw87L4v1VBI1GELEnWUFok6bEGijtIiUS9eRUnUS30z6dy5c3XgwAHNmzdPixYtUlpamr777jvFx8crKChIvXv3Vp8+fdSkSZOyjBcAAACoFOy6mbSgoEDr1q3TvHnztGbNGpnNZplMhUMrr7nmGsXFxenOO++0q2ne1aiowxZU1FFaVNRhCyrqKC0jVdTnG6ii3reCVNQdmvoiSWfOnNGiRYu0YMEC7d27t/CgJpOqVq2qO+64Q3379tUNN9zglGDLA4k6bEGijtIiUYctSNRRWiTqxSNRL8aePXs0b948LVmyRGfPni08gcmkhg0bqm/fvm4x/YVEHbYgUUdpkajDFiTqKC0S9eKRqF9BXl6eVq9erfnz5+uHH35Qfn6+TCaT9uzZ4+xTOR2JOmxBoo7SIlGHLUjUUVpGStS/rvuAq0Owuvv4Z64OwSnKZFSLp6enqlSpoipVqsjT07MsTgEAAABUaKWe+lIal06FOX36tCTJYrEoNDRUffr0ceapAAAAYCBOb9GA44n677//riVLlmj+/PlKSEiQVJicV6lSRV27dlVcXJzatm1rnQoDAAAA4O/ZlahbLBb98MMPmj9/vlavXq3c3FxdbHVv2bKl4uLi1LNnT1WvXt2pwQIAAACVhU2J+qFDh7RgwQJ98803OnnypKTCpL1GjRrq2bOn+vbtq8jIyDIJFAAAAMZV4OoAKqBSJ+r33nuvdu7cKakwOff09FT79u0VFxenmJgYeXt7l1mQAAAAQGVT6kR9x44dkqSwsDD17dtXvXv3VnBwcFnFBQAAAFRqpU7U+/Tpo7i4OF1//fVlGQ8AAADcUAFzQ5yu1In6uHHjyjIOAAAAAJcokwceAQAAAHCMUx94BAAAgMqpQPS+OBsVdQAAAMCAqKgDAADAYRZXB1ABUVEHAAAADIhEHQAAADAgWl8AAADgMOaoOx8VdQAAAMCASNQBAAAAA6L1BQAAAA4rcHUAFRAVdQAAAMCAqKgDAADAYcxRdz4q6gAAAIABkagDAAAABkTrCwAAABzGHHXnc7tEvaCgQMuWLdPKlSv1yy+/6PTp0/L09FRwcLCuvfZa9ejRQx06dHB1mG4tKqq5uve4Te3b36io6OaqWfMqZWVla//+Q1q+LF4fTp2ls2fPuzpMGMzNN7XRyJGPqn27GxUYGKDjx09qxco1Gjf+fR07lurq8OACm3ft0dcr1mr77n1KP/u7/P2qKqR2TbWJaq5H7umuWjUCr/j5xN8O6f9Gvab8gsJZEruWzCiPsGEQwcG1FRNzi9pc10rXtWmla6+Jlr+/nw4fSVbz5u1cHR5QLtwqUT969KieeOIJ7dmzRyaTSS1atFCrVq0kSYcPH9bChQu1cOFCxcbG6v3333dxtO6pceOG2vTzCuufjx1L1S+/7FFISB21aXON2rS5Ro8MfkC9ez2oxMRfXRgpjOThQfdp6pQ35enpqVOnTish8Vc1a9pYw4c9qP79eqnr7f20a9duV4eJclJQUKDXpszW1yvWSpJq17xKzRs30O+ZWTp8NFV7DyTptvbXXzFRzzObNfo/061JOiqffvf00ltvjXF1GIBLuU2inpaWpvvuu08nT55U+/btNWbMGDVs2LDImqSkJL3//vvav3+/i6J0fyaTSadOpumjjz7R53MW6PDhZOu+m29uo49nvKewsPr6/Mv/6vrrbldubq4Lo4URREdHasoH4+Xp6akJEydr9CsTZTab5etbVR9OnaAH7o/T13P/p+hWt3K9VBJvfjRHX69Yq+aNG+hfTzyoVs2bWPflmc3avvs31Q+pfcVjfPTlYv12+Ki6tL1O8Ru3lXXIMKDzv1/Q6tXrtXXrLm3dtksNG9TThAmjXR0WroC/Vjuf2yTqY8aM0cmTJ3XTTTfpo48+kpfX5aE3bNhQb731lrZs2eKCCCuGlJTjimrZUZmZWZft++mnrXpk0NP6bvXXCg8PU9fbOmrZ0u9cECWM5F8vj5SXl5c2bNisl/45zro9KytbQ4Y+q7Y3X6/w8DA99GB/fTTtExdGivKwJeFXfb4kXsG1aujjcS+oejW/Ivu9vbx0Y6sWVzzGvkPJ+virpWrVvInu7dGFRL2SmjXrS82a9aX1z/fc08uF0QCu4RZTXw4ePKjvvitMCEePHl1skn6p66+/vjzCqpBycnKLTdIv+umnrdb+9OaXVMlQOfn5+erObjGSpP8Wk4Tn5uZq9idzJUn9+/Ef2cpg9oLC1rkH+9xxWZJeGub8fI3+z3RJ0itPPiQPk1v8ZwqACivqRnlVFG5RUV+7dq0sFotatGihpk2bujqcSs3T01Pe3oWXzZUSelQOra+Nlq+vryRp/fqfil2zbl3h9htvbC2TySSLhUdiVFS5eXnasDVBktS2dZSOpKRq3sp12nc4WR4mk8IbhqpH53aKDG9Y4jFmzluu3fsPa2j/nmrWqL5+3rW3vMIHAMNxi0R99+7Cm9CioqJcHAl69rxd/v6FVbIf1m9ycTRwtWbNwiVJOTk5Sk4+VuyaAwePSJJ8fX0VFla/yH0PqFj2HkxSntksSdq194De+PBT5eTmWff/sPUXfbJwlQb3664nB8Rd9vlDycf14effqHH9uhp6b89yixsAjMotEvUzZ85IkmrWrOniSCq3wMAAvTH+n5KkpUu/Y+oLVLPmVZKkM2fOlbgmPf2M9X2NqwJ1WCTqFVVa+p/Xwb+nzFazsPp6adj/qUXTMKWdOafpXy/T3GVrNO3LJQqtU0txsZ2s6wsKCjT6Px8rz5yv0U88JB9vb1f8CAAcYGGOutPR/IdS8fT01MzZk9SwYT2dOpmmp0b809UhwQAutr3kXlI1/avs7Bzrez8/3zKPCa6TmZ1tfe/j7a2pY0fqmhZN5ePtrdA6tfTyYwPV8YZrJElTP1uo/Pw/O0k/W/Stdu49oLtjO6lNdES5xw4ARuQWiXqNGjUkSenp6S6OpHIymUz6aNpbuu22Tjp//nfdc88QpR4/6eqwYABZWYX3Kfj4lFz9rFq1ivU99zVUbFV8fKzve8a0U83A6peteajvHZKkk+ln9euhJElS8vGTmvTJfNWpeZWeHnRP+QQLAG7ALRL1li1bSpISExNdHEnlNOXDN9X/3t66cCFDd/d9RFt+3uHqkGAQF1tealzhwTU1a9b4c/3Zkltk4P4CA/yt78Pr1y12TXjDUOv7o6mnJEljJ89Sdk6uXho+QAH+tk+KAWAMrp70wtQXF+nUqZPefPNN7dmzR/v372fySzma9ME4DRhwjzIyMnVP3CP68cefXR0SDGTfvgOSpCpVqqhhw3pKSkq5bE2T8DBJhdX3I0eOlmt8KF+NL0nOvUvoMb+097zgj6eO7t5/SJL07w9m6d8fzCqyPs+cb33f+f+ekiQ92PcOPdS3m3OCBgADc4uKenh4uLp06SJJGjt2rMx/TBUoydatW8sjrArv3ffGatCge5WZmaX+9wzReqa84C+270iwtr906HBzsWs6dizc/vPPOxjNWMHVrnmV9YmjKanFt8clX9I2F1yr6ICA02fPX/Y6fyHjsv2ZWTkCgMrALSrqkvTqq69q165d2rRpkx599FGNGTNGDRo0KLImJSVF77//vn799VctXLjQNYFWEBPfekVDhg5QVla2+vcbqu+//9HVIcGAMjOztHzFavXt011DB/+fPvtsXpH9Pj4+GjignyRp7leLXREiylm3Tjdp2pdLtHTtTxr+QO/LprfMX7VOkhTg76eoZo0kSRu+nFLi8X7etVePvPSmJGnXkhllEzQAp6hILSdG4RYVdUmqVauW5syZo8jISP3www+67bbb1LdvXz311FMaMWKEevfurS5dumjhwoVq3Lixq8N1a/9+7QUNf+wha5K+ZvUPrg4JBvba6+/JbDarffsb9cbrL1qfHOzrW1Uf/fcthYeH6fDhZE2f8bmLI0V5GNg7VldVr6bUU+n69wezlXXJ1J+l32/UvJVrJUkPxXVjBCMA/A2Txc2+iy4oKNDSpUu1YsUKJSQkKD09XR4eHgoJCVHr1q3Vq1cvtWvXzu7jV/Or3En+jTe21urv50uSTp5I0/4Dh0pcu2rl93prYsmVsMog25zr6hAMYcjg/9PkSW/I09NTp06d1pGko2rWtLECA6vrzJmzui22n3bsqNw3g2ckfuXqEMrNtsR9emzMu8rMypa/b1U1rl9Xp8+e1/FTpyVJd3S8SeOfHSoPj7+vFVXWinr1q/u7OgSXq1+/rjb9tML6Zx8fb1WvHqD8/Pwiz27YuHGL7r7nEVeEaAg52cZ5NsWkBv/n6hCsnkz+1NUhOIXbtL5c5OHhoZ49e6pnT55aVxaqVPlzvFqd4FqqE1yrxLUHDxwpj5DgBqb971MlJOzVqFHD1K7tDbo6OlKpqaf0+RcLNW78+0pJOe7qEFGOrouK0IIPXtP/vlqqDdt+0a+HklW1io9uaBWpuNhO6tbxJplMPBkFV+bp6alatS5/0OFft1cPDCjPsIBy5XYV9bJW2SvqsA0VdZRWZaqow3FU1FFaVNSLR0UdAAAA+EMBX5Q5ndvcTAoAAABUJiTqAAAAgAHR+gIAAACHMUfd+aioAwAAAAZERR0AAAAOo6LufFTUAQAAAAMiUQcAAAAMiNYXAAAAOIwnaDofFXUAAADAgEjUAQAAAAOi9QUAAAAOKzC5OoKKh4o6AAAAYEAk6gAAAIAB0foCAAAAh/HAI+ejog4AAAAYEBV1AAAAOIw56s5HRR0AAAAwIBJ1AAAAwIBofQEAAIDDCmh+cToq6gAAAIABkagDAAAABkTrCwAAABzGHHXno6IOAAAAGBAVdQAAADiMW0mdj4o6AAAAYEAk6gAAAIAB0foCAAAAh3EzqfNRUQcAAAAMiEQdAAAAMCBaXwAAAOCwApOrI6h4qKgDAAAABkRFHQAAAA4rYJK601FRBwAAAAyIRB0AAAAwIFpfAAAA4DAaX5yPijoAAABgQFTUAQAAgD/k5eVp06ZN+v7777Vp0yYlJycrPz9fISEhuuWWWzR48GDVq1ev2M8mJSVp0qRJ2rhxo86dO6eQkBDFxsZq+PDh8vf3tzkWKuoAAABwWIGBXo74+eef9cgjj+iTTz7R77//rvbt26tjx47Kzs7WnDlz1KtXL23fvv2yzyUmJqp3795atGiR6tSpoy5duig/P1/Tpk3Tvffeq99//93mWKioAwAAAH8wmUyKjY3VoEGD1Lp1a+v2nJwcjRkzRvPnz9eoUaO0cuVKeXt7S5Ly8/M1cuRIZWRkaNSoURo6dKgkKTc3VyNGjNCaNWs0ceJEjR071qZYqKgDAAAAf2jbtq3ef//9Ikm6JFWpUkWvvPKKAgIClJKSUqSqHh8fr8OHDysiIkJDhgyxbvfx8dHYsWPl5eWlefPm6cyZMzbFQqIOAAAAhxXIYphXWalataoaNWokSTp58qR1+5o1ayRJsbGxMplMRT5Tp04dtWnTRmazWWvXrrXpfCTqAAAAQCnk5+crJSVFklSrVi3r9j179kiSoqOji/1cVFSUJGnv3r02nY8edQAAADisMsxR/+abb5Senq6aNWvquuuus24/duyYJCkkJKTYzwUHBxdZV1ok6gAAAKhQunTpcsX98fHxNh/z6NGjevPNNyVJzzzzjHx8fKz7MjMzJUm+vr7FfvbiaMaMjAybzknrCwAAAHAFFy5c0GOPPaazZ8/qjjvuUL9+/crlvFTUAQAA4DBH55c7kz0V85Lk5ORo+PDh+vXXX9W2bVtNnDjxsjV+fn46d+6csrKyij3GxUq6rQ89oqIOAAAAFCMvL09PPvmkNm/erGuvvVZTpkwp0vJyUWhoqCQpNTW12OOcOHGiyLrSIlEHAAAA/qKgoEDPPfec1q5dq8jISH300Ufy8/Mrdm2LFi0kSQkJCcXuT0xMlCRFRkbaFAOJOgAAABzm6tnpzpyjbrFY9PLLL2v58uVq3Lixpk+frsDAwBLXd+7cWZK0cuVKWSxFz3/y5Elt3bpVXl5e6tixo01xkKgDAAAAlxg/frzmzZun+vXra9asWQoKCrri+piYGDVq1Ej79u3TtGnTrNtzc3M1evRomc1mxcXFqWbNmjbFwc2kAAAAcFhFmaP+3XffaebMmZKkevXq6d133y12XdeuXdW1a1dJkpeXl95++20NGDBAb7/9tlasWKGwsDDt3LlTKSkpioiI0HPPPWdzLCTqAAAAwB/Onz9vfb9p06YS19WrV8+aqEuFTyVduHChJk2apI0bN2rfvn0KCQnR4MGD9dhjj9k88UWSTJa/NtJUctX8Grs6BLiRbHOuq0OAm8hI/MrVIcCNVL+6v6tDgJvIyU52dQhWzzS619UhWL17+AtXh+AUVNQBAADgMCPNUa8ouJkUAAAAMCASdQAAAMCAaH0BAACAwywVZu6LcVBRBwAAAAyIRB0AAAAwIFpfAAAA4DCmvjgfFXUAAADAgKioAwAAwGEF3EzqdFTUAQAAAAMiUQcAAAAMiNYXAAAAOIzGF+ejog4AAAAYEIk6AAAAYEC0vgAAAMBhTH1xPirqAAAAgAFRUQcAAIDDeDKp81FRBwAAAAyIRB0AAAAwIFpfAAAA4DALN5M6HRV1AAAAwIBI1AEAAAADovUFAAAADmPqi/NRUQcAAAAMiEQdAAAAMCBaX/4i25zr6hAAVED+Ufe4OgS4kaxj610dAmAzpr44HxV1AAAAwICoqAMAAMBh3EzqfFTUAQAAAAMiUQcAAAAMiNYXAAAAOKzAws2kzkZFHQAAADAgEnUAAADAgGh9AQAAgMNofHE+KuoAAACAAVFRBwAAgMMKqKk7HRV1AAAAwIBI1AEAAAADovUFAAAADrPQ+uJ0VNQBAAAAAyJRBwAAAAyI1hcAAAA4rMDVAVRAVNQBAAAAA6KiDgAAAIcxR935qKgDAAAABkSiDgAAABgQrS8AAABwGHPUnY+KOgAAAGBAJOoAAACAAdH6AgAAAIcxR935qKgDAAAABkSiDgAAABgQrS8AAABwmMXC1Bdno6IOAAAAGBAVdQAAADisgDnqTkdFHQAAADAgEnUAAADAgGh9AQAAgMOYo+58VNQBAAAAAyJRBwAAAAyI1hcAAAA4zMLUF6ejog4AAAAYEBV1AAAAOIw56s5HRR0AAAAwIBJ1AAAAwIBofQEAAIDDLBZaX5yNijoAAABgQCTqAAAAgAHR+gIAAACHFbg6gAqIijoAAABgQCTqAAAAgAHR+gIAAACHWXjgkdNRUQcAAAAMiIo6AAAAHFZARd3pqKgDAAAABkSiDgAAABgQrS8AAABwmMVC64uzUVEHAAAADIhEHQAAADAgWl8AAADgMKa+OB8VdQAAAMCAqKgDAADAYTyZ1PmoqAMAAAAGRKIOAAAAGBCtLwAAAHBYAXPUnY6KOgAAAGBAJOoAAACAAdH6AgAAAIdVlMaXxMRE/fjjj/rll1+UkJCglJQUSVJ8fLzq169f4ueSkpI0adIkbdy4UefOnVNISIhiY2M1fPhw+fv72xULiToAAADwhw8++EDx8fE2fSYxMVEDBgxQRkaGoqKidP3112vXrl2aNm2a1q5dqzlz5iggIMDmWEjUAQAA4LCK8mTSa6+9VhEREYqOjtbVV1+tvn37Ki0trcT1+fn5GjlypDIyMjRq1CgNHTpUkpSbm6sRI0ZozZo1mjhxosaOHWtzLCTqAAAAwB8uJtqlFR8fr8OHDysiIkJDhgyxbvfx8dHYsWPVuXNnzZs3T88884xq1Khh07G5mRQAAACw05o1ayRJsbGxMplMRfbVqVNHbdq0kdls1tq1a20+Nok6AAAAHFYgi2Fe5WnPnj2SpOjo6GL3R0VFSZL27t1r87FpfQEAAECF0qVLlyvut/Vm0Ss5duyYJCkkJKTY/cHBwUXW2YKKOgAAAGCnzMxMSZKvr2+x+y+OZszIyLD52FTUAQAA4DCLxThTX5xZMXclKuoAAACAnfz8/CRJWVlZxe6/WEm356FHJOoAAACAnUJDQyVJqampxe4/ceJEkXW2IFEHAACAw1w96cVVU19atGghSUpISCh2f2JioiQpMjLS5mOTqAMAAAB26ty5syRp5cqVl/Xpnzx5Ulu3bpWXl5c6duxo87FJ1AEAAOAwi4H+V55iYmLUqFEj7du3T9OmTbNuz83N1ejRo2U2mxUXF6eaNWvafGyTxUi36JYgJiZGKSkp1j97eHjI399fgYGBioiIUJs2bdS7d2/VqlXL4XN5+dRz+BgVxc03tdHIkY+qfbsbFRgYoOPHT2rFyjUaN/59HTtWfB8WKi+uF5QW18rfyzq23tUhlKvNW3fqq0XLtW1XotLPnJW/n5/qBtdWm2uiNXhAP9UKKkxwNm/bpYeffL5Ux7yhdSvNmPxmWYZtCN61wl0dgtUNobZXjMvKz8fW2f3Z77//XlOmTLH+effu3crLy1OLFi3k4+MjSerUqZMef/xx65qEhAQNGDBAmZmZioqKUlhYmHbu3KmUlBRFRERozpw5CggIsDkWt0rUb7nlFtWuXVtS4czKkydPavfu3crJyZG3t7eGDRum4cOHy9PT0+5zkagXenjQfZo65U15enrq1KnTOpJ0VM2aNlZgYHWlp59R19v7adeu3a4OEwbB9YLS4lopncqSqBcUFOjfb03WV98slyTVDqqp4Dq1dOFChlJPpik7J0ezp0zUddcUPvFxz779euPdqSUeL9+cr127f5UkPfrgfXpy6MCy/yFcjES9eI4k6vPnz9eLL754xTV9+vTR+PHji2w7cuSIJk2apI0bN+rcuXMKCQlRbGysHnvsMbsmvkhulqjPnj1bN910U5F9mZmZmjt3rt59911lZ2erf//+Gjt2rN3nIlGXoqMjtWXzSnl5eWnCxMka/cpEmc1m+fpW1YdTJ+iB++N08OARRbe6Vbm5ua4OFy7G9YLS4lopvcqSqL/xzhTNmbdYzZuG65V/PKlWUX/ebJdnNmv7zkQ1alhfdWoHlep4363doKdfek0mk0nLvvxYDerVLavQDcNIifr1dTu4OgSrLccrxr9Dbt+j7ufnp4ceekgffvihPDw89OWXX2r9+orxf46r/OvlkfLy8tKGDZv10j/HyWw2S5KysrI1ZOizOnjwiMLDw/TQg/1dHCmMgOsFpcW1gktt2fGL5sxbrOA6tTRj8ptFknRJ8vby0o1tril1ki5JC5auklTY9lIZknRUfG6fqF/Utm1bde/eXZI0c+ZM1wbjxvz8fHVntxhJ0n+nfXLZ/tzcXM3+ZK4kqX+/XuUaG4yH6wWlxbWCv5r1+XxJ0kP3xal6QDWHj5d2Ol0bftoqSerb43aHjwcYgZerA3CmHj16aPHixdq6davy8vLk7e3t6pDcTutro+Xr6ytJWr/+p2LXrFtXuP3GG1vLZDIZ6pHBKF9cLygtrhVcKjc3Vz9s2iJJandDax1JTtHXi1Zo34FD8jCZFN64oXreHqPIiCalPuY3y7+TOT9fAdX81fXW9mUVOq6gvOeXVwYVpqIu/TlwPisrq8iUGJRes2aFvW45OTlKTj5W7JoDB49Iknx9fRUWVr/cYoPxcL2gtLhWcKm9vx1UXl5h69POxL3qO/AxzZjztTZs2qr1P23RrM/n656Hn9T7H80q9TEXLv1WknTnbbeqapUqZRI3UN4qVKJeo0YN6/tz5865MBL3VbPmVZKkM2dK/ueXnn7G+r7GVYFlHRIMjOsFpcW1gkudOp1ufT924mQ1adxQn/73HW1b841WzZup/n26y2Kx6KNZX+jrRSv+9njbdiboUNJRSVKf7rS9uIrFYjHMq6KoUIn6pf/HmEwmF0bivi5+NZ2bm1fimuzsHOt7Pz/fMo8JxsX1gtLiWsGlMrOyre99vL314dv/1rXRhTOqQ0OC9a9nn1DHdjdKkqZ8/Kny8/OveLz5f9xEGtG0saJbRJRd4EA5q1CJ+pkzf1ZjAgOpxtgjKytLkuTjU3J/f9Wqf36lmJmZVeYxwbi4XlBaXCu4VNU/HhojSb26dVHNGlddtmbQ/XGSpJNpp7X3t4MlHiszM0urVv8giWo6Kp4Klajv3l34kAw/Pz/Vq8c8dHtc/Fq6Ro2S/6JTs+afLUZnztJiVJlxvaC0uFZwqcDqfz6hMTysQbFrmjRqaH2fcrzkJ9auWL1OmVlZ8vb2Us/YGOcFCZsVyGKYV0VRoRL1pUuXSpJuuOEGeXlVqIE25WbfvgOSpCpVqqhhw+L/stMkPExSYYXsyJGj5RYbjIfrBaXFtYJLNb4kOS/pW5ZLt+fnF5R4rIuz02M6tNNVgdWdFCFgDBUmUd+4caOWLVsmSRo0aJCLo3Ff23ckWL+i7tDh5mLXdOxYuP3nn3dUqBs2YDuuF5QW1wouVbtWTdUPDZEkJacUXy1PTjlufR9cp1axaw4dOartuwq/TWd2Oioit0/Us7KyNHPmTA0bNkwFBQW6//771bZtW1eH5bYyM7O0fMVqSdLQwf932X4fHx8NHNBPkjT3q8XlGhuMh+sFpcW1gr+687ZbJUlLv12j3Nzcy/bPW7xSklQ9oJqiI5sVe4wFSwvXhATXVtsbWpdNoCg1i4H+V1G4VaL+0Ucf6YUXXtALL7ygESNG6N5779VNN92kcePGKT8/XyNGjNDLL7/s6jDd3muvvyez2az27W/UG6+/aG0j8vWtqo/++5bCw8N0+HCyps/43MWRwgi4XlBaXCu41IP39tVVgdWVeuKUxk6crKzsPyfBLF21xjqW8aH74uRzyc2nF+Xn52vxH3/5692tqzw83CqlAUrFZHGD7xdjYmKKPMDIZDLJ399fgYGBioiI0A033KC77rpLtWoV/9WYLbx8uAlVkoYM/j9NnvSGPD09derUaR1JOqpmTRsrMLC6zpw5q9ti+2nHjkRXhwmD4HpBaXGtlE7WsfWuDqFcbNuZoGGjRiszK0v+fr5qHNZAp9PP6viJk5Kkbl076c1X/lFsEv79Dz/piedflclk0vK5062tNJWNd61wV4dg1SrEOB0Nu1I3ujoEp3CLRL08kaj/qe3N12vUqGFq1/YGBQYGKDX1lJavWK1x499XyiW9g4DE9YLS41r5e5UlUZek46knNe2TL7Vh01adTDst36pVFdmsie7udYe6de1U4nNRRrw4VqvXbdRNba7Rx++PL+eojcNIiXp0cPH3n7hCwomfXB2CU5Co/wWJOgDA1SpTog7HkKgXr6Ik6swwBAAAgMMq0k2cRsGdFwAAAIABkagDAAAABkTrCwAAABxWwG2PTkdFHQAAADAgEnUAAADAgGh9AQAAgMOY+uJ8VNQBAAAAA6KiDgAAAIdxM6nzUVEHAAAADIhEHQAAADAgWl8AAADgMG4mdT4q6gAAAIABkagDAAAABkTrCwAAABzG1Bfno6IOAAAAGBAVdQAAADiMm0mdj4o6AAAAYEAk6gAAAIAB0foCAAAAh1ksBa4OocKhog4AAAAYEIk6AAAAYEC0vgAAAMBhBUx9cToq6gAAAIABkagDAAAABkTrCwAAABxmsdD64mxU1AEAAAADoqIOAAAAh3EzqfNRUQcAAAAMiEQdAAAAMCBaXwAAAOAwbiZ1PirqAAAAgAGRqAMAAAAGROsLAAAAHFZA64vTUVEHAAAADIiKOgAAABxmYY6601FRBwAAAAyIRB0AAAAwIFpfAAAA4DDmqDsfFXUAAADAgEjUAQAAAAOi9QUAAAAOK2Dqi9NRUQcAAAAMiEQdAAAAMCBaXwAAAOAwpr44HxV1AAAAwICoqAMAAMBhBVTUnY6KOgAAAGBAJOoAAACAAdH6AgAAAIdxM6nzUVEHAAAADIhEHQAAADAgWl8AAADgsALR+uJsVNQBAAAAA6KiDgAAAIdxM6nzUVEHAAAADIhEHQAAADAgWl8AAADgsAJaX5yOijoAAABgQCTqAAAAgAHR+gIAAACHWZij7nRU1AEAAAADIlEHAAAADIjWFwAAADiMqS/OR0UdAAAAMCAq6gAAAHCYhYq601FRBwAAAAyIRB0AAAAwIFpfAAAA4DDmqDsfFXUAAADAgEjUAQAAAAOi9QUAAAAOq0hTX3JzczVjxgwtWrRIycnJ8vPz0/XXX6/hw4crKiqq3OKgog4AAAD8ITc3V4888ojeeecdnTlzRp07d1Z4eLi+/fZb9e/fX+vXry+3WKioAwAAwGEVpaI+bdo0bd68WVdffbVmzpypatWqSZKWLFmiUaNG6bnnntN3331n3V6WqKgDAAAAksxms2bPni1JeuWVV4ok4z169FCnTp105swZzZs3r1ziIVEHAAAAJG3btk1nz55V/fr1dfXVV1+2/84775QkxcfHl0s8tL4AAADAYRWh8WXPnj2SVOINoy1btpQk/frrr+USDxV1AAAAQNKxY8ckSSEhIcXuv7j97NmzysjIKPN4qKgDAACgQunSpcsV95fUupKZmSlJ8vX1LXa/n5+f9X1GRob8/f3tjLB0SNT/wpyb4uoQAAAA3I6Rcqi/S9TdBYk6AAAAKhR7b/a8WDHPysoqdv/FirukMq+mS/SoAwAAAJKk0NBQSVJqamqx+y9uv+qqq0jUAQAAgPLSokULSVJiYmKx+3fv3i1Jat68ebnEQ6IOAAAASLruuut01VVX6ejRo/rll18u279s2TJJ5dcDT6IOAAAASPLy8tLAgQMlSa+++qouXLhg3bdkyRKtXbtWNWrUUFxcXLnEY7JYLBVhPj0AAADgsNzcXD3yyCPavHmzgoKCdMMNNygtLU1btmyRt7e3pkyZoo4dO5ZLLCTqAAAAwCVyc3M1ffp0LVq0SMnJyfLz81ObNm30+OOPl/jU0rJAog4AAAAYED3qAAAAgAGRqAMAAAAGRKIOAAAAGBCJOgAAAGBAJOoAAACAAZGowy4bN250dQgAAAAVmperA4D7OHLkiBYsWKBFixYpNTVVu3fvdnVIAAAAFRaJOq7owoULWrZsmebPn6+dO3dKkiwWi4KCglwcGQCje+qpp5ScnKyXX35Z11133RXXbtu2Ta+99poaN26st99+u5wiBABjI1HHZSwWi9avX6+FCxdq9erVysnJkcVikZ+fn7p27aqePXuqXbt2rg4TBnfhwgUdOXJEvr6+Cg8Pd3U4KGc//PCDVq5cqV69ev1tki5J1113nZo1a6ZFixbpnnvu0c0331wOUcLo8vPzlZKSorNnz8pkMumqq65SvXr15OFB5y4qBxJ1WO3fv18LFizQ4sWLderUKVksFnl4eMjb21t5eXnauHGjqlSp4uowYRB79+7V5s2blZ+fr/DwcHXs2FEmk0l5eXkaN26c5s6dq/z8fElSWFiY3nzzTV1zzTUujhrlZcmSJTKZTHryySdL/ZkRI0Zo0aJFWrRoEYl6JbdhwwbNnDlTW7ZsUXZ2dpF9vr6+uvHGGzVo0CDddNNNLooQKB8mi8VicXUQcJ2zZ89q6dKlmj9/vrXn3GKxqGnTpurVq5fuuusuPfPMM9q+fbv27Nnj4mhhFP/+9781Z86cIttatmypWbNm6d1339Vnn3122WcCAgK0ZMkSBQcHl1eYcKHY2Fj5+vpq4cKFNn2uT58+ys7O1vLly8smMBhaQUGBXn31Vc2dO1d/l56YTCY98MAD+uc//ymTyVROEQLli4p6Jfbkk0/q+++/l9lslsViUY0aNdS9e3f17t1b0dHRrg4PBrV06VJ99tlnMplMatOmjWrWrKk9e/Zo9+7deu+99/Tll1+qQ4cO+sc//qEGDRooKSlJb775pjZs2KAZM2bohRdecPWPgHJw8uRJdezY0ebPNWzYUOvWrSuDiOAOpkyZoi+//FIeHh7q0aOHevToocjISNWoUUOSdObMGe3evVtLlizR8uXL9dlnn6lWrVoaNmyYiyMHygaJeiX27bffymQyqU6dOnr55ZfVuXNneXlxSeDK5s6dK5PJpA8//FCdOnWSVNhH+vzzz+uzzz5T9erV9d5778nf31+SFBERof/85z/q0qWLNmzY4MrQUY7y8/PtqnKaTCYVFBSUQUQwutOnT+vDDz+Ur6+vpk6dWmz7U3BwsIKDg9W5c2fdfffdGj58uD744AP169dPNWvWdEHUQNniboxKzNPTUxaLRSdPntSrr76qt956S3v37nV1WDC4vXv36uqrr7Ym6VLhtTR8+HBZLBZFR0dbk/SLqlWrpujoaB09erS8w4WLBAUFKSkpyebPJScnk3BVUgsXLpTZbNbTTz9dqnsU2rZtq6efflp5eXlatGhROUQIlD8S9Ups3bp1ev755xUREaG0tDTNnDlTffr0Ua9evTRjxgydOnXK1SHCgM6fP68GDRpctr1hw4aSpDp16hT7udq1a192UxgqrujoaO3du9emv5wlJydr9+7dtN5VUlu3blXVqlXVv3//Un/m3nvvVZUqVbR58+YyjAxwHRL1SiwoKEiDBg3SN998o4ULF2rgwIGqWbOm9u3bpwkTJqhz584aPHiwUlNTXR0qDMRiscjHx+ey7d7e3lf8HDd7VS6xsbEqKCjQmDFjStXKcnGtJN1xxx1lHB2MaN++fWrRooWqVq1a6s9UrVpVLVu21L59+8owMsB1SNQhSYqMjNRLL72kdevWaerUqbrttttkMpn0ww8/6NixY5KkF198URs2bPjbO/EBoHv37oqMjNSGDRv0yCOP6ODBgyWuPXDggB5++GH9+OOPioyMVPfu3csxUhjFuXPnSvxG7krq1Kmjc+fOlUFEgOtx5yCK8PT0VOfOndW5c2edO3dOS5Ys0TfffKNdu3ZpwYIFWrhwoYKCgtS9e3e9+OKLrg4XLpKWlqaff/7Zpn20UlUuJpNJkydP1n333aeNGzeqe/fuatGihaKioqw96Onp6UpMTNSePXtksVhUp04dTZ482cWRw1UyMjLk5+dn8+f8/PyUkZFRBhEBrsccdZTKwYMHrQ9DSk1NlclkYq56JRUZGelQGwvXTeVy+vRpvfLKK4qPj5fFYrns2rm4rUuXLnr11VcVFBTkokjhapGRkerTp4/GjRtn0+defPFFLVy4kN8tqJCoqKNUwsPDNWrUKI0cOVI//vijzQ8xQcURGhrq6hDgRoKCgjR58mQdOnRIa9eu1e7du3XmzBlJUo0aNdSyZUt16tRJjRs3dnGkMIIrfVtXEr6tQ0VGRR0AALgc39YBl6OiDgAAXI5v64DLUVEHAAAADIjxjAAAAIABkagDAAAABkSiDgAAABgQiToAlIFNmzapefPmiomJuWzfgAED1Lx5c82fP9/h88yfP1/NmzfXgAEDHD4WAMBYmPoCwC0MGDBAmzdvLrLNw8NDAQEBCg8PV5cuXfTAAw/Y9WRDAACMiEQdgFupW7eu6tatK0kym81KTk7W9u3btX37dn399deaPXu2goODXRzlldWtW1eNGzdWQECAq0MBABgYiToAtxIXF6cnn3yyyLaVK1fqhRde0OHDhzVmzBhNnTrVRdGVzoQJE1wdAgDADdCjDsDtxcbGavjw4ZKk77//XufOnXNxRAAAOI6KOoAKoW3btpKkgoICHTlyRFlZWRo4cKDq1aun1atXa8mSJfriiy+0b98+nTt3TrNnz9ZNN90kScrPz9fChQu1aNEi7d27VxkZGapRo4ZuvPFGDRkyRJGRkcWeMy8vTzNnztTChQuVlJSkgIAAXX/99Xr88cevGOvFfvtx48apb9++l+0/f/68Pv30U61Zs0aHDx9Wdna2ateurebNmys2Nla9e/cu8djz58/X559/rv3798tkMikqKkrDhg1T+/btS/zMunXrNGfOHO3atUvnz59XYGCgrrnmGg0YMMD6zxUAUP5I1AFUCFd6yPIbb7yhWbNmqVatWmrYsKFOnDhh3Xfu3Dk99thj2rJliySpTp06Cg0N1ZEjR7RkyRKtXLlSb775prp3717kmLm5uXr00Uf1448/SpLq16+vwMBAff/991q7du3fJuslSUhI0LBhw3Tq1ClJUlhYmAICAnT8+HGtXr1aq1evLjFRf+mllzRv3jxrD/yhQ4e0efNmbdmyRZMmTVLXrl0v+8zrr7+u2bNnS5KCgoIUGRmpo0ePKj4+XvHx8Ro+fLiefvppu34WAIBjSNQBVAg//fSTpMJJMGFhYdq7d68kKTU1VZ9//rkmTpyonj17ymQyyWKxKC8vT5L07LPPasuWLWrTpo3GjBmjiIgISYWV+dmzZ+vNN9/Uiy++qJYtW6px48bW802ZMkU//vij/P399f777+uWW26RVJj4P//883r//fdt/hnS0tL06KOPKi0tTTfeeKP+/e9/q1GjRtb9KSkp+vrrr4v97Pbt27Vv3z5Nnz7dWj3PzMzUP/7xD3377bd644031KVLF5lMJutnFixYoNmzZ8vT01P/+te/1L9/f3l4eCg/P9/6s0+dOlWRkZG64447bP55AACOoUcdgNtbuXKl9QbSW2+9VYGBgdZ9+fn5evzxx9WrVy9rkmoymeTj46Mff/xR69atU2hoqD788ENrki4VJvwPPfSQHnjgAeXk5GjWrFnWfZmZmfrkk08kSU899ZQ1SZekwMBAvf3223aNifzf//6ntLQ0NW7cWNOmTSuSpEtSvXr19NRTTxX72by8PL300ktFWlz8/Pz0yiuvyNvbWykpKfr111+LfGbKlCmSpP79++u+++6Th0fhfxI8PT01aNAg9ezZU5L0wQcf2PyzAAAcR6IOwK3MmzdP9913n+677z7dc889uvnmmzVixAhlZmaqUaNGGjNmzGWfueeee4o91rJlyyRJ3bt3V/Xq1Ytdc/vtt0uSNm7caN22detWXbhwQVWrVi322P7+/rr77rtt/dG0atUqSdKgQYNUtWpVmz4bEBCgXr16Xba9du3aqlevniQpKSnJuv3AgQPWPw8aNKjYYz7yyCOSpH379unYsWM2xQMAcBytLwDcyvHjx3X8+HFJhVXvatWqqXXr1iU+8KhGjRoKCgoq9lgX22O+/fZbbd26tdg1OTk5kgpbaC46ePCgpMIKd0mV82bNmtnwU0kXLlxQSkqKJKl169Y2fVYq7GW/tK3lUrVq1dLhw4eVkZFh3Xbo0CFJUtWqVdWwYcNiP9e0aVN5enoqPz9fBw8eVGhoqM1xAQDsR6IOwK088cQTl81Rv5IrtaCcP39eknT48GEdPnz4isfJzs62vr+Y8Jb0F4C/21ecS5Pokqr7V3Kln/NiS8ulN9yW5mfw8vJSjRo1lJaWViQ+AED5IFEHUGldTG7feOMNxcXFlfpz/v7+kqTTp0+XuOZK+650TKnwLxAhISE2fd5WpfkZzGazzpw5c1l8AIDyQY86gErr4s2jf73J8u+Eh4dLKpzCkpWVVeya3377zaZjVqtWzdpLvn37dps+a4+LP0N2dnaR3vVL7d+/X/n5+ZKkJk2alHlMAICiSNQBVFrdunWTJH3zzTdKS0sr9efatGkjf39/ZWdnFzsuMSMjQ/PmzbM5ntjYWEnSzJkzrb3xZSU8PFxhYWGSpBkzZhS75uL2iIgI1a1bt0zjAQBcjkQdQKXVuXNn3XLLLTp79qwGDhxofejRpZKTkzVt2jR99dVX1m1+fn4aMGCAJOk///mP9aFHUmHbynPPPWdXT/fgwYNVq1YtHTx4UEOHDtWRI0eK7E9JSbFrPntJhg8fLkn68ssv9cUXX1h72AsKCjRr1ix98803kmT3w5sAAI6hRx1Apfbuu+/qqaee0o8//qgHHnhAQUFBCg0NVUFBgY4fP6709HRJhTexXuqxxx7T9u3btWnTJg0aNEgNGjRQYGCg9u/fL0kaMWKE3n77bZtiCQoK0ocffqjhw4frp59+0u23365GjRqpWrVqSk1NtVb9R4wY4YSfXOrTp492796t2bNn65VXXtGkSZNUt25dpaSkWH/uYcOG8bAjAHAREnUAlVr16tX18ccfa9WqVVq0aJF27dqlvXv3ytPTU3Xq1FG7du0UExOjTp06FflclSpV9L///U8zZ87UggULdPToUWVkZKhjx4564okndPbsWbviufrqq7VkyRJ98sknWr16tQ4fPqzjx4+rdu3a6tq1q7U9xln++c9/6pZbbtHnn3+unTt3as+ePQoMDFSXLl00YMAAtW3b1qnnAwCUnsly6bwuAAAAAIZAjzoAAABgQCTqAAAAgAGRqAMAAAAGRKIOAAAAGBCJOgAAAGBAJOoAAACAAZGoAwAAAAZEog4AAAAYEIk6AAAAYEAk6gAAAIABkagDAAAABkSiDgAAABgQiToAAABgQCTqAAAAgAH9P6arQul6LXoHAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 900x900 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "actual, predicted = get_actual_predicted_labels(dataset=test_dataset,model=test_model_vgg)\n",
        "graficar_matriz_confusion(actual, predicted, test_dataset.class_names)\n",
        "#print(actual,predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ryOH7Na3mgFO",
        "outputId": "db20acb8-f75a-41ef-b35c-3b434021226d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultado F1_Score: {'angular_leafspot': 0.9852941176470589, 'hojas_sanas': 1.0, 'leaf_spot': 0.9770992366412213, 'powdery_mildew': 0.9925925925925926}\n"
          ]
        }
      ],
      "source": [
        "precision, recall = calcular_precision_recall(actual, predicted, test_dataset.class_names)\n",
        "resultadosf1=calcular_f1_score(precision, recall)\n",
        "print(\"Resultado Precisión: {}\".format(precision))\n",
        "print(\"Resultado Recall: {}\".format( recall))\n",
        "print(\"Resultado F1_Score: {}\".format(resultadosf1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nLyprAYsmgFO",
        "outputId": "6b81c116-f26c-4105-926a-d4bbfac49166"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Promedio: 0.9887464867202183\n"
          ]
        }
      ],
      "source": [
        "valores = list(resultadosf1.values())\n",
        "promedio = statistics.mean(valores)\n",
        "print(\"F1macro:\", promedio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3rDA1TAp_jn"
      },
      "source": [
        "#ENTRENAMIENTO DEL MODELO CNN-MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DUWvaBHIa3v"
      },
      "outputs": [],
      "source": [
        "incio=g.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDFTpI-6qCoa",
        "outputId": "6111336d-2953-45e9-f7b4-16159e67c4ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"mobilenetv2_1.00_224\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_3[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']                  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']             \n",
            " wiseConv2D)                    )                                                                 \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']\n",
            " tchNormalization)              )                                                                 \n",
            "                                                                                                  \n",
            " expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
            " ReLU)                          )                                ]']                              \n",
            "                                                                                                  \n",
            " expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]\n",
            "                                )                                [0]']                            \n",
            "                                                                                                  \n",
            " expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']  \n",
            " hNormalization)                )                                                                 \n",
            "                                                                                                  \n",
            " block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
            "                                )                                ]                                \n",
            "                                                                                                  \n",
            " block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']         \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']      \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',     \n",
            "                                                                  'block_2_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',     \n",
            "                                                                  'block_4_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',            \n",
            "                                                                  'block_5_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']    \n",
            "                                                                                                  \n",
            " block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']            \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',     \n",
            "                                                                  'block_7_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',            \n",
            "                                                                  'block_8_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']         \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']      \n",
            "                                                                                                  \n",
            " block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
            " nv2D)                                                                                            \n",
            "                                                                                                  \n",
            " block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']      \n",
            " malization)                                                                                      \n",
            "                                                                                                  \n",
            " block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
            "                                                                                                  \n",
            " block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
            "                                                                                                  \n",
            " block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',            \n",
            "                                                                  'block_9_project_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']            \n",
            "                                                                                                  \n",
            " block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',    \n",
            "                                                                  'block_11_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',           \n",
            "                                                                  'block_12_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']   \n",
            "                                                                                                  \n",
            " block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']           \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',    \n",
            "                                                                  'block_14_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',           \n",
            "                                                                  'block_15_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']           \n",
            "                                                                                                  \n",
            " block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']        \n",
            " lization)                                                                                        \n",
            "                                                                                                  \n",
            " block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']     \n",
            "                                                                                                  \n",
            " block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
            "                                                                                                  \n",
            " block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
            "                                                                                                  \n",
            " block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']       \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
            "                                                                                                  \n",
            " Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']                 \n",
            "                                                                                                  \n",
            " out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,257,984\n",
            "Trainable params: 2,223,872\n",
            "Non-trainable params: 34,112\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#%% BASE COVOLUCIONAL MobileNet\n",
        "\n",
        "conv_base2 = tf.keras.applications.MobileNetV2(\n",
        "weights=\"imagenet\",\n",
        "include_top=False,\n",
        "input_shape=(dst_size[0],dst_size[0], 3))\n",
        "conv_base2.trainable=True\n",
        "conv_base2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoJ9Y4v_qUdU",
        "outputId": "bc8ced6e-5cc8-497f-92e1-5c2833a68135"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Conv1 True\n",
            "expanded_conv_project True\n",
            "block_1_expand True\n",
            "block_1_project True\n",
            "block_2_expand True\n",
            "block_2_project True\n",
            "block_3_expand True\n",
            "block_3_project True\n",
            "block_4_expand True\n",
            "block_4_project True\n",
            "block_5_expand True\n",
            "block_5_project True\n",
            "block_6_expand True\n",
            "block_6_project True\n",
            "block_7_expand True\n",
            "block_7_project True\n",
            "block_8_expand True\n",
            "block_8_project True\n",
            "block_9_expand True\n",
            "block_9_project True\n",
            "block_10_expand True\n",
            "block_10_project True\n",
            "block_11_expand True\n",
            "block_11_project True\n",
            "block_12_expand True\n",
            "block_12_project True\n",
            "block_13_expand True\n",
            "block_13_project True\n",
            "block_14_expand True\n",
            "block_14_project True\n",
            "block_15_expand True\n",
            "block_15_project True\n",
            "block_16_expand True\n",
            "block_16_project True\n",
            "Conv_1 True\n"
          ]
        }
      ],
      "source": [
        "#verificar si las capas  finalesson entrenables\n",
        "\n",
        "for layer in conv_base2.layers:\n",
        "  if isinstance(layer, keras.layers.Conv2D):\n",
        "    print(layer.name, layer.trainable)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pocPDAMuqhTB",
        "outputId": "de2f4130-2a96-460b-ee47-38210ae91c22"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6300 files belonging to 4 classes.\n",
            "Found 272 files belonging to 4 classes.\n",
            "Found 268 files belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "train_dataset = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    image_size=dst_size,\n",
        "    batch_size=50,\n",
        "    seed=5,\n",
        "    label_mode=\"categorical\",\n",
        ")\n",
        "\n",
        "\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    image_size=dst_size,\n",
        "    batch_size=10,\n",
        "    seed=5,\n",
        "    label_mode=\"categorical\",\n",
        ")\n",
        "\n",
        "\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    image_size=dst_size,\n",
        "    batch_size=10,\n",
        "    label_mode=\"categorical\",\n",
        "    shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xY2cT7H7qZOy"
      },
      "outputs": [],
      "source": [
        "#MODELO DE LA RED CON MobileNetv2\n",
        "def MobileNet(dropout1=0.5,dropout2=0.6,activacion=\"softmax\",perdida=\"categorical_crossentropy\",metrica=\"accuracy\",neuronas=256,optimizador=\"Adamax\",mobile=conv_base2):\n",
        "\n",
        "  inputs = Input(shape=(dst_size[0], dst_size[0], 3))\n",
        "  x = mobile(inputs)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dropout(dropout1)(x)\n",
        "  x = layers.Dense(neuronas,activation='relu')(x)\n",
        "  x = layers.Dense(neuronas,activation='relu')(x)\n",
        "  x = layers.Dropout(dropout2)(x)\n",
        "  outputs = layers.Dense(4, activation=activacion)(x)\n",
        "\n",
        "  model = models.Model(inputs, outputs)\n",
        "  model.compile(loss=perdida,\n",
        "                optimizer=optimizador,\n",
        "                metrics=[metrica])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRP0-v4oqwi_"
      },
      "outputs": [],
      "source": [
        "#FASE DE ENTRENAMIENTO DEL MODELO\n",
        "\n",
        "callbacks3 = [\n",
        "keras.callbacks.ModelCheckpoint(\n",
        "filepath=Guardar_CNNMobilNetV2,\n",
        "save_best_only=True,\n",
        "monitor='val_accuracy'),\n",
        "tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=5,\n",
        "    verbose=0,\n",
        "    mode='auto',\n",
        "    start_from_epoch=3)\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWYwmt4wsi9B",
        "outputId": "7ecf5344-61ad-484c-8d36-81d5ee309c9f"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.3225 - accuracy: 0.9452"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 574s 4s/step - loss: 0.3225 - accuracy: 0.9452 - val_loss: 22.5147 - val_accuracy: 0.4485\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9944"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 49s 392ms/step - loss: 0.0179 - accuracy: 0.9944 - val_loss: 10.0928 - val_accuracy: 0.6581\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.0144 - accuracy: 0.9976"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 49s 390ms/step - loss: 0.0144 - accuracy: 0.9976 - val_loss: 4.2679 - val_accuracy: 0.8272\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9987"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 49s 391ms/step - loss: 0.0031 - accuracy: 0.9987 - val_loss: 2.6046 - val_accuracy: 0.8676\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 0.9989"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 49s 389ms/step - loss: 0.0031 - accuracy: 0.9989 - val_loss: 1.4299 - val_accuracy: 0.9007\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9987"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 49s 390ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.6455 - val_accuracy: 0.9559\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.0018 - accuracy: 0.9990"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 49s 392ms/step - loss: 0.0018 - accuracy: 0.9990 - val_loss: 0.3959 - val_accuracy: 0.9816\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0058 - accuracy: 0.9979 - val_loss: 0.3865 - val_accuracy: 0.9816\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0069 - accuracy: 0.9986 - val_loss: 0.3872 - val_accuracy: 0.9743\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0057 - accuracy: 0.9989 - val_loss: 0.4706 - val_accuracy: 0.9596\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.0045 - accuracy: 0.9989 - val_loss: 0.0912 - val_accuracy: 0.9743\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9986"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 49s 387ms/step - loss: 0.0051 - accuracy: 0.9986 - val_loss: 0.0062 - val_accuracy: 0.9926\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9989"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 49s 392ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0290 - val_accuracy: 0.9963\n",
            "Epoch 14/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.0745 - val_accuracy: 0.9926\n",
            "Epoch 15/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0597 - val_accuracy: 0.9963\n",
            "Epoch 16/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0058 - accuracy: 0.9986 - val_loss: 0.1181 - val_accuracy: 0.9779\n",
            "Epoch 17/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.0069 - accuracy: 0.9987 - val_loss: 0.0203 - val_accuracy: 0.9963\n",
            "Epoch 18/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0196 - val_accuracy: 0.9963\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 47s 207ms/step - loss: 0.5217 - accuracy: 0.9527 - val_loss: 749.4818 - val_accuracy: 0.2500\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.2213 - accuracy: 0.9614 - val_loss: 694.1509 - val_accuracy: 0.2500\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 0.1173 - accuracy: 0.9827 - val_loss: 490.9417 - val_accuracy: 0.2500\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0783 - accuracy: 0.9852 - val_loss: 94.8549 - val_accuracy: 0.4926\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0667 - accuracy: 0.9862 - val_loss: 132.4654 - val_accuracy: 0.4485\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0512 - accuracy: 0.9892 - val_loss: 246.4249 - val_accuracy: 0.4632\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 0.1461 - accuracy: 0.9895 - val_loss: 46.6416 - val_accuracy: 0.4926\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0601 - accuracy: 0.9911 - val_loss: 62.6540 - val_accuracy: 0.4963\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 0.0291 - accuracy: 0.9937 - val_loss: 8.7597 - val_accuracy: 0.8015\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.1244 - accuracy: 0.9895 - val_loss: 805.0067 - val_accuracy: 0.2500\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0547 - accuracy: 0.9911 - val_loss: 532.7515 - val_accuracy: 0.3051\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0446 - accuracy: 0.9927 - val_loss: 179.5975 - val_accuracy: 0.3346\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 0.0136 - accuracy: 0.9978 - val_loss: 112.9583 - val_accuracy: 0.4669\n",
            "Epoch 14/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0299 - accuracy: 0.9951 - val_loss: 104.0097 - val_accuracy: 0.5147\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 51s 209ms/step - loss: 1.0455 - accuracy: 0.5787 - val_loss: 1.5539 - val_accuracy: 0.5882\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.6473 - accuracy: 0.8373 - val_loss: 1.0146 - val_accuracy: 0.7574\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.5100 - accuracy: 0.9086 - val_loss: 0.5238 - val_accuracy: 0.8713\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.4256 - accuracy: 0.9403 - val_loss: 0.2777 - val_accuracy: 0.9301\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.3594 - accuracy: 0.9633 - val_loss: 0.1252 - val_accuracy: 0.9559\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.3138 - accuracy: 0.9803 - val_loss: 0.0655 - val_accuracy: 0.9816\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.2782 - accuracy: 0.9862 - val_loss: 0.0434 - val_accuracy: 0.9853\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.2553 - accuracy: 0.9908 - val_loss: 0.0365 - val_accuracy: 0.9890\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.2326 - accuracy: 0.9922 - val_loss: 0.0356 - val_accuracy: 0.9890\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.2063 - accuracy: 0.9954 - val_loss: 0.0371 - val_accuracy: 0.9890\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.2009 - accuracy: 0.9956 - val_loss: 0.0397 - val_accuracy: 0.9890\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.1770 - accuracy: 0.9963 - val_loss: 0.0428 - val_accuracy: 0.9926\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.1643 - accuracy: 0.9968 - val_loss: 0.0459 - val_accuracy: 0.9926\n",
            "Epoch 14/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.1558 - accuracy: 0.9981 - val_loss: 0.0486 - val_accuracy: 0.9963\n",
            "Epoch 15/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.1459 - accuracy: 0.9975 - val_loss: 0.0513 - val_accuracy: 0.9963\n",
            "Epoch 16/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.1308 - accuracy: 0.9983 - val_loss: 0.0540 - val_accuracy: 0.9963\n",
            "Epoch 17/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.1296 - accuracy: 0.9990"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "126/126 [==============================] - 50s 398ms/step - loss: 0.1296 - accuracy: 0.9990 - val_loss: 0.0562 - val_accuracy: 1.0000\n",
            "Epoch 18/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.1202 - accuracy: 0.9984 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
            "Epoch 19/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.1181 - accuracy: 0.9983 - val_loss: 0.0597 - val_accuracy: 1.0000\n",
            "Epoch 20/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.1025 - accuracy: 0.9989 - val_loss: 0.0609 - val_accuracy: 1.0000\n",
            "Epoch 21/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.1047 - accuracy: 0.9979 - val_loss: 0.0619 - val_accuracy: 1.0000\n",
            "Epoch 22/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.0938 - accuracy: 0.9990 - val_loss: 0.0627 - val_accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 52s 210ms/step - loss: 0.0196 - accuracy: 0.9922 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.0026 - accuracy: 0.9994 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 5.0144e-04 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.0597 - accuracy: 0.9992 - val_loss: 0.0143 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0038 - accuracy: 0.9995 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 7.2847e-04 - accuracy: 0.9997 - val_loss: 0.0064 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 3.6368e-04 - accuracy: 1.0000 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 8.4332e-04 - accuracy: 0.9997 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 6.6695e-04 - accuracy: 0.9998 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 5.0989e-04 - accuracy: 0.9998 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 47s 209ms/step - loss: 0.0240 - accuracy: 0.9917 - val_loss: 0.5859 - val_accuracy: 0.9485\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0301 - accuracy: 0.9941 - val_loss: 17.0753 - val_accuracy: 0.7059\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 0.0099 - accuracy: 0.9970 - val_loss: 1.3156 - val_accuracy: 0.9559\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0182 - accuracy: 0.9971 - val_loss: 0.6977 - val_accuracy: 0.9890\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0273 - accuracy: 0.9978 - val_loss: 0.0493 - val_accuracy: 0.9963\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0118 - accuracy: 0.9987 - val_loss: 0.0659 - val_accuracy: 0.9926\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0204 - accuracy: 0.9975 - val_loss: 1.7969e-08 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0127 - accuracy: 0.9981 - val_loss: 8.1553 - val_accuracy: 0.9118\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0173 - accuracy: 0.9970 - val_loss: 0.1056 - val_accuracy: 0.9963\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0042 - accuracy: 0.9995 - val_loss: 5.4509 - val_accuracy: 0.9338\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0083 - accuracy: 0.9978 - val_loss: 1.6338 - val_accuracy: 0.9669\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0269 - accuracy: 0.9978 - val_loss: 4.5420 - val_accuracy: 0.9449\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 51s 211ms/step - loss: 1.0088 - accuracy: 0.6417 - val_loss: 0.2951 - val_accuracy: 0.9596\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.5907 - accuracy: 0.9183 - val_loss: 0.1820 - val_accuracy: 0.9632\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.4371 - accuracy: 0.9602 - val_loss: 0.1474 - val_accuracy: 0.9669\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.3443 - accuracy: 0.9787 - val_loss: 0.1294 - val_accuracy: 0.9669\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.2889 - accuracy: 0.9838 - val_loss: 0.1187 - val_accuracy: 0.9669\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.2484 - accuracy: 0.9902 - val_loss: 0.1123 - val_accuracy: 0.9779\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.2163 - accuracy: 0.9906 - val_loss: 0.1084 - val_accuracy: 0.9779\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.1906 - accuracy: 0.9952 - val_loss: 0.1057 - val_accuracy: 0.9853\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.1606 - accuracy: 0.9952 - val_loss: 0.1033 - val_accuracy: 0.9926\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.1456 - accuracy: 0.9975 - val_loss: 0.1006 - val_accuracy: 0.9963\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.1286 - accuracy: 0.9971 - val_loss: 0.0977 - val_accuracy: 0.9963\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.1108 - accuracy: 0.9990 - val_loss: 0.0944 - val_accuracy: 0.9963\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0998 - accuracy: 0.9990 - val_loss: 0.0908 - val_accuracy: 0.9963\n",
            "Epoch 14/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0918 - accuracy: 0.9984 - val_loss: 0.0868 - val_accuracy: 0.9963\n",
            "Epoch 15/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0866 - accuracy: 0.9990 - val_loss: 0.0827 - val_accuracy: 0.9963\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 50s 212ms/step - loss: 0.0185 - accuracy: 0.9941 - val_loss: 0.0450 - val_accuracy: 0.9926\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 207ms/step - loss: 1.7208e-04 - accuracy: 1.0000 - val_loss: 0.0239 - val_accuracy: 0.9926\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 3.7463e-05 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 3.4752e-04 - accuracy: 0.9998 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0013 - accuracy: 0.9994 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 4.0056e-04 - accuracy: 0.9998 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 9.3511e-05 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 2.9804e-05 - accuracy: 1.0000 - val_loss: 7.8989e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 3.5498e-04 - accuracy: 0.9998 - val_loss: 5.4946e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0051 - accuracy: 0.9998 - val_loss: 5.9935e-04 - val_accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 48s 212ms/step - loss: 0.0229 - accuracy: 0.9921 - val_loss: 0.0141 - val_accuracy: 0.9963\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0122 - accuracy: 0.9984 - val_loss: 0.0214 - val_accuracy: 0.9963\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.0120 - accuracy: 0.9994 - val_loss: 0.0672 - val_accuracy: 0.9890\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0468 - accuracy: 0.9970 - val_loss: 64.5789 - val_accuracy: 0.7684\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.0142 - accuracy: 0.9981 - val_loss: 0.4833 - val_accuracy: 0.9779\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0132 - accuracy: 0.9983 - val_loss: 0.2261 - val_accuracy: 0.9779\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0296 - accuracy: 0.9965 - val_loss: 0.5089 - val_accuracy: 0.9853\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.0363 - val_accuracy: 0.9926\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 0.3624 - val_accuracy: 0.9816\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 7.5658e-05 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.9669\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.4358 - val_accuracy: 0.9706\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0081 - accuracy: 0.9989 - val_loss: 0.2333 - val_accuracy: 0.9816\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.1655 - val_accuracy: 0.9816\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 50s 214ms/step - loss: 0.9160 - accuracy: 0.6892 - val_loss: 0.2467 - val_accuracy: 0.9816\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 207ms/step - loss: 0.4958 - accuracy: 0.9549 - val_loss: 0.1615 - val_accuracy: 0.9890\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.3384 - accuracy: 0.9905 - val_loss: 0.1329 - val_accuracy: 0.9890\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.2558 - accuracy: 0.9960 - val_loss: 0.1167 - val_accuracy: 0.9963\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.2068 - accuracy: 0.9979 - val_loss: 0.1060 - val_accuracy: 0.9963\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.1561 - accuracy: 0.9992 - val_loss: 0.0978 - val_accuracy: 0.9963\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.1327 - accuracy: 0.9997 - val_loss: 0.0909 - val_accuracy: 0.9963\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.1079 - accuracy: 0.9997 - val_loss: 0.0851 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0934 - accuracy: 0.9994 - val_loss: 0.0801 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0794 - accuracy: 0.9997 - val_loss: 0.0754 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0650 - accuracy: 1.0000 - val_loss: 0.0712 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0596 - accuracy: 0.9997 - val_loss: 0.0672 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0496 - accuracy: 1.0000 - val_loss: 0.0637 - val_accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 50s 210ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 2.8475e-04 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 6.0530e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 1.1079e-04 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.0021 - accuracy: 0.9997 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0073 - accuracy: 0.9998 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 4.3511e-04 - accuracy: 0.9998 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 7.2740e-05 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 2.1369e-05 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 1.5744e-04 - accuracy: 1.0000 - val_loss: 8.3975e-04 - val_accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 46s 208ms/step - loss: 0.0172 - accuracy: 0.9929 - val_loss: 0.0515 - val_accuracy: 0.9926\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.2872 - val_accuracy: 0.9779\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 0.0195 - accuracy: 0.9981 - val_loss: 0.0453 - val_accuracy: 0.9926\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 8.7786e-04 - accuracy: 0.9998 - val_loss: 0.1076 - val_accuracy: 0.9926\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.2875 - val_accuracy: 0.9890\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0095 - accuracy: 0.9987 - val_loss: 0.3848 - val_accuracy: 0.9706\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 0.0136 - accuracy: 0.9983 - val_loss: 0.0768 - val_accuracy: 0.9890\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 7.9329e-04 - accuracy: 0.9995 - val_loss: 0.1610 - val_accuracy: 0.9890\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.1842 - val_accuracy: 0.9816\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0082 - accuracy: 0.9989 - val_loss: 0.1227 - val_accuracy: 0.9926\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 8.4745e-04 - accuracy: 0.9998 - val_loss: 0.2925 - val_accuracy: 0.9926\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0022 - accuracy: 0.9995 - val_loss: 0.0786 - val_accuracy: 0.9890\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 4.1377e-05 - accuracy: 1.0000 - val_loss: 0.0366 - val_accuracy: 0.9926\n",
            "Epoch 14/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 1.5068e-05 - accuracy: 1.0000 - val_loss: 0.0292 - val_accuracy: 0.9926\n",
            "Epoch 15/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.2420 - val_accuracy: 0.9890\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 49s 210ms/step - loss: 1.0242 - accuracy: 0.5941 - val_loss: 0.4841 - val_accuracy: 0.9890\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.4878 - accuracy: 0.8986 - val_loss: 0.2885 - val_accuracy: 0.9890\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.3134 - accuracy: 0.9675 - val_loss: 0.2011 - val_accuracy: 0.9926\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.2234 - accuracy: 0.9846 - val_loss: 0.1497 - val_accuracy: 0.9926\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.1717 - accuracy: 0.9924 - val_loss: 0.1164 - val_accuracy: 0.9926\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.1370 - accuracy: 0.9941 - val_loss: 0.0952 - val_accuracy: 0.9926\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.1127 - accuracy: 0.9970 - val_loss: 0.0809 - val_accuracy: 0.9926\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.0962 - accuracy: 0.9990 - val_loss: 0.0707 - val_accuracy: 0.9926\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0800 - accuracy: 0.9983 - val_loss: 0.0633 - val_accuracy: 0.9926\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0675 - accuracy: 0.9987 - val_loss: 0.0582 - val_accuracy: 0.9926\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0620 - accuracy: 0.9990 - val_loss: 0.0542 - val_accuracy: 0.9890\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 51s 212ms/step - loss: 0.0135 - accuracy: 0.9941 - val_loss: 0.0418 - val_accuracy: 0.9926\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 6.4753e-06 - accuracy: 1.0000 - val_loss: 0.0399 - val_accuracy: 0.9926\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 2.5708e-04 - accuracy: 0.9998 - val_loss: 0.0180 - val_accuracy: 0.9926\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 2.0449e-04 - accuracy: 0.9998 - val_loss: 0.0297 - val_accuracy: 0.9926\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 1.0888e-05 - accuracy: 1.0000 - val_loss: 0.0369 - val_accuracy: 0.9926\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 5.8051e-06 - accuracy: 1.0000 - val_loss: 0.0393 - val_accuracy: 0.9926\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 5.5311e-06 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9926\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 3.2789e-05 - accuracy: 1.0000 - val_loss: 0.0498 - val_accuracy: 0.9926\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 7.7078e-05 - accuracy: 1.0000 - val_loss: 0.0417 - val_accuracy: 0.9926\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 7.8073e-07 - accuracy: 1.0000 - val_loss: 0.0437 - val_accuracy: 0.9926\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 2.5987e-05 - accuracy: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9926\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 46s 210ms/step - loss: 0.0336 - accuracy: 0.9914 - val_loss: 0.0844 - val_accuracy: 0.9890\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0032 - accuracy: 0.9990 - val_loss: 0.0174 - val_accuracy: 0.9963\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0038 - accuracy: 0.9990 - val_loss: 0.0558 - val_accuracy: 0.9963\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 1.9598e-05 - accuracy: 1.0000 - val_loss: 0.0487 - val_accuracy: 0.9963\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 4.7587e-07 - accuracy: 1.0000 - val_loss: 0.0451 - val_accuracy: 0.9963\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0091 - val_accuracy: 0.9963\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 2.8675e-05 - accuracy: 1.0000 - val_loss: 0.0423 - val_accuracy: 0.9890\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 2.8382e-04 - accuracy: 0.9998 - val_loss: 0.2959 - val_accuracy: 0.9779\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 4.5491e-04 - accuracy: 0.9998 - val_loss: 0.0770 - val_accuracy: 0.9926\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.0522 - val_accuracy: 0.9926\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0105 - accuracy: 0.9992 - val_loss: 0.0389 - val_accuracy: 0.9926\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 51s 211ms/step - loss: 1.0483 - accuracy: 0.5943 - val_loss: 0.3262 - val_accuracy: 0.9853\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.4255 - accuracy: 0.9181 - val_loss: 0.1689 - val_accuracy: 0.9963\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.2593 - accuracy: 0.9743 - val_loss: 0.1114 - val_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.1768 - accuracy: 0.9903 - val_loss: 0.0829 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.1305 - accuracy: 0.9965 - val_loss: 0.0664 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0993 - accuracy: 0.9979 - val_loss: 0.0559 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0800 - accuracy: 0.9984 - val_loss: 0.0488 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0671 - accuracy: 0.9990 - val_loss: 0.0437 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.0541 - accuracy: 0.9989 - val_loss: 0.0400 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0487 - accuracy: 0.9990 - val_loss: 0.0369 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0423 - accuracy: 0.9987 - val_loss: 0.0345 - val_accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 51s 213ms/step - loss: 0.0160 - accuracy: 0.9937 - val_loss: 0.0083 - val_accuracy: 0.9963\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 208ms/step - loss: 7.1594e-06 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9963\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 9.0739e-05 - accuracy: 1.0000 - val_loss: 0.0276 - val_accuracy: 0.9926\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 4.0887e-06 - accuracy: 1.0000 - val_loss: 0.0272 - val_accuracy: 0.9926\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 1.1705e-05 - accuracy: 1.0000 - val_loss: 0.0126 - val_accuracy: 0.9926\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 2.8781e-05 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 0.9963\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 1.1358e-05 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9963\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 207ms/step - loss: 8.7815e-06 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9963\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 1.8868e-06 - accuracy: 1.0000 - val_loss: 0.0106 - val_accuracy: 0.9963\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 2.5698e-05 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 0.9963\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 3.0362e-07 - accuracy: 1.0000 - val_loss: 0.0134 - val_accuracy: 0.9963\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 46s 212ms/step - loss: 0.6249 - accuracy: 0.9895 - val_loss: 0.0177 - val_accuracy: 0.9963\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.0066 - accuracy: 0.9990 - val_loss: 0.4962 - val_accuracy: 0.9816\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 8.6094e-04 - accuracy: 0.9997 - val_loss: 0.0108 - val_accuracy: 0.9963\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0120 - accuracy: 0.9990 - val_loss: 0.1042 - val_accuracy: 0.9963\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.0067 - accuracy: 0.9994 - val_loss: 0.5035 - val_accuracy: 0.9816\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0067 - val_accuracy: 0.9963\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0063 - accuracy: 0.9995 - val_loss: 0.2838 - val_accuracy: 0.9926\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.0579 - val_accuracy: 0.9926\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 0.4012 - val_accuracy: 0.9926\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.1217 - val_accuracy: 0.9926\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0118 - accuracy: 0.9994 - val_loss: 0.0244 - val_accuracy: 0.9963\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 52s 214ms/step - loss: 0.8950 - accuracy: 0.6367 - val_loss: 0.1619 - val_accuracy: 0.9890\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 208ms/step - loss: 0.4351 - accuracy: 0.8830 - val_loss: 0.0862 - val_accuracy: 0.9963\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.2844 - accuracy: 0.9589 - val_loss: 0.0630 - val_accuracy: 0.9963\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.2110 - accuracy: 0.9787 - val_loss: 0.0518 - val_accuracy: 0.9963\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.1598 - accuracy: 0.9903 - val_loss: 0.0456 - val_accuracy: 0.9963\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.1290 - accuracy: 0.9937 - val_loss: 0.0413 - val_accuracy: 0.9963\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.1048 - accuracy: 0.9973 - val_loss: 0.0386 - val_accuracy: 0.9963\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0890 - accuracy: 0.9976 - val_loss: 0.0364 - val_accuracy: 0.9963\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0735 - accuracy: 0.9986 - val_loss: 0.0347 - val_accuracy: 0.9963\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0642 - accuracy: 0.9986 - val_loss: 0.0333 - val_accuracy: 0.9963\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0572 - accuracy: 0.9995 - val_loss: 0.0322 - val_accuracy: 0.9963\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 49s 210ms/step - loss: 0.0221 - accuracy: 0.9935 - val_loss: 0.0185 - val_accuracy: 0.9890\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 7.7844e-05 - accuracy: 1.0000 - val_loss: 0.0196 - val_accuracy: 0.9890\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 1.0185e-04 - accuracy: 1.0000 - val_loss: 0.0209 - val_accuracy: 0.9890\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.0040 - accuracy: 0.9998 - val_loss: 0.0134 - val_accuracy: 0.9963\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 6.0011e-05 - accuracy: 1.0000 - val_loss: 0.0116 - val_accuracy: 0.9963\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 3.5303e-04 - accuracy: 0.9998 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 5.0428e-05 - accuracy: 1.0000 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 4.0389e-05 - accuracy: 1.0000 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 1.5055e-05 - accuracy: 1.0000 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 3.2843e-06 - accuracy: 1.0000 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 1.4792e-05 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 47s 209ms/step - loss: 0.0267 - accuracy: 0.9937 - val_loss: 0.0240 - val_accuracy: 0.9926\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 9.9160e-06 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9963\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 6.2007e-05 - accuracy: 1.0000 - val_loss: 0.0511 - val_accuracy: 0.9853\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 3.7933e-06 - accuracy: 1.0000 - val_loss: 0.0350 - val_accuracy: 0.9926\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0027 - accuracy: 0.9997 - val_loss: 0.0151 - val_accuracy: 0.9926\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0113 - val_accuracy: 0.9963\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 200ms/step - loss: 0.0013 - accuracy: 0.9995 - val_loss: 0.0107 - val_accuracy: 0.9963\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 4.9036e-05 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9963\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 9.6487e-06 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 2.0914e-06 - accuracy: 1.0000 - val_loss: 9.8000e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 4.8610e-07 - accuracy: 1.0000 - val_loss: 3.0713e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0041 - accuracy: 0.9995 - val_loss: 1.4684e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0153 - accuracy: 0.9990 - val_loss: 0.0592 - val_accuracy: 0.9853\n",
            "Epoch 14/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 9.8495e-04 - accuracy: 0.9997 - val_loss: 0.0289 - val_accuracy: 0.9926\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 51s 210ms/step - loss: 1.2465 - accuracy: 0.5011 - val_loss: 0.4707 - val_accuracy: 0.9706\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.6148 - accuracy: 0.7983 - val_loss: 0.2619 - val_accuracy: 0.9890\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.3912 - accuracy: 0.9025 - val_loss: 0.1735 - val_accuracy: 0.9926\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.2681 - accuracy: 0.9475 - val_loss: 0.1260 - val_accuracy: 0.9926\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.2023 - accuracy: 0.9694 - val_loss: 0.0967 - val_accuracy: 0.9890\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.1539 - accuracy: 0.9817 - val_loss: 0.0780 - val_accuracy: 0.9926\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.1164 - accuracy: 0.9865 - val_loss: 0.0652 - val_accuracy: 0.9926\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0915 - accuracy: 0.9932 - val_loss: 0.0560 - val_accuracy: 0.9926\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.0761 - accuracy: 0.9941 - val_loss: 0.0493 - val_accuracy: 0.9926\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0667 - accuracy: 0.9959 - val_loss: 0.0445 - val_accuracy: 0.9926\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0532 - accuracy: 0.9968 - val_loss: 0.0406 - val_accuracy: 0.9926\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 50s 211ms/step - loss: 0.0194 - accuracy: 0.9933 - val_loss: 0.1072 - val_accuracy: 0.9926\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 4.3241e-05 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9926\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 1.8551e-04 - accuracy: 1.0000 - val_loss: 0.1163 - val_accuracy: 0.9926\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 1.8482e-05 - accuracy: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9926\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 7.2552e-06 - accuracy: 1.0000 - val_loss: 0.1086 - val_accuracy: 0.9926\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 1.7154e-05 - accuracy: 1.0000 - val_loss: 0.1061 - val_accuracy: 0.9926\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 7.2438e-06 - accuracy: 1.0000 - val_loss: 0.1064 - val_accuracy: 0.9926\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 1.6218e-06 - accuracy: 1.0000 - val_loss: 0.1074 - val_accuracy: 0.9926\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 1.2629e-06 - accuracy: 1.0000 - val_loss: 0.1073 - val_accuracy: 0.9926\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 3.2682e-06 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9926\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 1.7512e-06 - accuracy: 1.0000 - val_loss: 0.1078 - val_accuracy: 0.9926\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 48s 211ms/step - loss: 0.0226 - accuracy: 0.9921 - val_loss: 0.0665 - val_accuracy: 0.9926\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.0614 - val_accuracy: 0.9926\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0092 - accuracy: 0.9984 - val_loss: 3.4140e-07 - val_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 1.3203e-05 - accuracy: 1.0000 - val_loss: 2.9005e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0975 - val_accuracy: 0.9926\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0023 - accuracy: 0.9997 - val_loss: 0.0938 - val_accuracy: 0.9926\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 8.7462e-06 - accuracy: 1.0000 - val_loss: 0.0656 - val_accuracy: 0.9926\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 3.2544e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 3.1426e-05 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9926\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 1.3840e-06 - accuracy: 1.0000 - val_loss: 0.0281 - val_accuracy: 0.9926\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 5.9473e-06 - accuracy: 1.0000 - val_loss: 0.0254 - val_accuracy: 0.9890\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 4.9327e-07 - accuracy: 1.0000 - val_loss: 0.0246 - val_accuracy: 0.9926\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 3.8637e-06 - accuracy: 1.0000 - val_loss: 0.0143 - val_accuracy: 0.9963\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 50s 211ms/step - loss: 1.4514 - accuracy: 0.4783 - val_loss: 0.3783 - val_accuracy: 0.9743\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.5666 - accuracy: 0.8049 - val_loss: 0.2085 - val_accuracy: 0.9890\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.3306 - accuracy: 0.9186 - val_loss: 0.1395 - val_accuracy: 0.9926\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.2218 - accuracy: 0.9568 - val_loss: 0.1025 - val_accuracy: 0.9926\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.1606 - accuracy: 0.9735 - val_loss: 0.0796 - val_accuracy: 0.9926\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.1152 - accuracy: 0.9852 - val_loss: 0.0648 - val_accuracy: 0.9926\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0901 - accuracy: 0.9903 - val_loss: 0.0541 - val_accuracy: 0.9926\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0720 - accuracy: 0.9944 - val_loss: 0.0463 - val_accuracy: 0.9926\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0553 - accuracy: 0.9959 - val_loss: 0.0402 - val_accuracy: 0.9926\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0443 - accuracy: 0.9983 - val_loss: 0.0355 - val_accuracy: 0.9926\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0400 - accuracy: 0.9987 - val_loss: 0.0320 - val_accuracy: 0.9926\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 51s 214ms/step - loss: 0.0209 - accuracy: 0.9925 - val_loss: 0.0131 - val_accuracy: 0.9926\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 208ms/step - loss: 8.2023e-05 - accuracy: 1.0000 - val_loss: 0.0117 - val_accuracy: 0.9926\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 3.5836e-04 - accuracy: 0.9998 - val_loss: 0.0081 - val_accuracy: 0.9963\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 207ms/step - loss: 4.9907e-05 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 0.9963\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 207ms/step - loss: 1.4719e-05 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 0.9963\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 1.2553e-05 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 0.9926\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 3.9634e-06 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9963\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 1.8050e-05 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 0.9963\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 207ms/step - loss: 3.3412e-04 - accuracy: 0.9998 - val_loss: 0.0165 - val_accuracy: 0.9926\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 208ms/step - loss: 2.1533e-05 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 0.9963\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 4.4067e-05 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 0.9963\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 2.6017e-05 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 0.9963\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 46s 212ms/step - loss: 0.0194 - accuracy: 0.9940 - val_loss: 0.0603 - val_accuracy: 0.9926\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 3.3543e-05 - accuracy: 1.0000 - val_loss: 0.1120 - val_accuracy: 0.9890\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 1.2503e-04 - accuracy: 1.0000 - val_loss: 0.0586 - val_accuracy: 0.9926\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 1.8716e-04 - accuracy: 0.9998 - val_loss: 0.2160 - val_accuracy: 0.9853\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 4.6929e-05 - accuracy: 1.0000 - val_loss: 0.0839 - val_accuracy: 0.9890\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 2.4692e-05 - accuracy: 1.0000 - val_loss: 0.0742 - val_accuracy: 0.9926\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 2.7842e-06 - accuracy: 1.0000 - val_loss: 0.0447 - val_accuracy: 0.9926\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 6.2510e-07 - accuracy: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9926\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 2.9119e-07 - accuracy: 1.0000 - val_loss: 0.0455 - val_accuracy: 0.9926\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 3.7741e-06 - accuracy: 1.0000 - val_loss: 0.0463 - val_accuracy: 0.9926\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 1.9591e-05 - accuracy: 1.0000 - val_loss: 0.1227 - val_accuracy: 0.9890\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 51s 215ms/step - loss: 1.0345 - accuracy: 0.5841 - val_loss: 0.3244 - val_accuracy: 0.9890\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 207ms/step - loss: 0.4022 - accuracy: 0.8914 - val_loss: 0.1527 - val_accuracy: 0.9890\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.2179 - accuracy: 0.9644 - val_loss: 0.0919 - val_accuracy: 0.9890\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.1295 - accuracy: 0.9860 - val_loss: 0.0627 - val_accuracy: 0.9890\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 207ms/step - loss: 0.0848 - accuracy: 0.9935 - val_loss: 0.0473 - val_accuracy: 0.9890\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0572 - accuracy: 0.9981 - val_loss: 0.0384 - val_accuracy: 0.9890\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0425 - accuracy: 0.9987 - val_loss: 0.0330 - val_accuracy: 0.9890\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0326 - accuracy: 0.9986 - val_loss: 0.0295 - val_accuracy: 0.9890\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0252 - accuracy: 0.9992 - val_loss: 0.0273 - val_accuracy: 0.9890\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0204 - accuracy: 0.9995 - val_loss: 0.0257 - val_accuracy: 0.9890\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0169 - accuracy: 0.9995 - val_loss: 0.0247 - val_accuracy: 0.9890\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 49s 209ms/step - loss: 0.0342 - accuracy: 0.9925 - val_loss: 0.0376 - val_accuracy: 0.9963\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 5.7063e-04 - accuracy: 0.9998 - val_loss: 0.0384 - val_accuracy: 0.9963\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 7.3469e-05 - accuracy: 1.0000 - val_loss: 0.0379 - val_accuracy: 0.9963\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 1.0175e-04 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9963\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 9.6774e-05 - accuracy: 1.0000 - val_loss: 0.0373 - val_accuracy: 0.9963\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 5.1632e-04 - accuracy: 0.9998 - val_loss: 0.0215 - val_accuracy: 0.9963\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.0219 - val_accuracy: 0.9963\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 6.5847e-05 - accuracy: 1.0000 - val_loss: 0.0189 - val_accuracy: 0.9963\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 3.5882e-05 - accuracy: 1.0000 - val_loss: 0.0158 - val_accuracy: 0.9963\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 9.1194e-06 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 0.9963\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 1.6908e-05 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9963\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 46s 207ms/step - loss: 0.0266 - accuracy: 0.9935 - val_loss: 7.7604e-06 - val_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.5163 - val_accuracy: 0.9743\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 25s 199ms/step - loss: 0.0075 - accuracy: 0.9994 - val_loss: 0.2729 - val_accuracy: 0.9926\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 0.0057 - accuracy: 0.9994 - val_loss: 0.1085 - val_accuracy: 0.9926\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0073 - accuracy: 0.9992 - val_loss: 0.6607 - val_accuracy: 0.9926\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.1735 - val_accuracy: 0.9926\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 1.7094e-04 - accuracy: 0.9998 - val_loss: 5.4561e-07 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 5.6752e-06 - accuracy: 1.0000 - val_loss: 2.0905e-07 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 9.9522e-04 - accuracy: 0.9998 - val_loss: 1.4024e-07 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 1.7863e-04 - accuracy: 1.0000 - val_loss: 0.0364 - val_accuracy: 0.9963\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 6.0682e-04 - accuracy: 0.9997 - val_loss: 0.0067 - val_accuracy: 0.9926\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 4.1778e-04 - accuracy: 0.9998 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 51s 211ms/step - loss: 1.8056 - accuracy: 0.3581 - val_loss: 0.5294 - val_accuracy: 0.9301\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.9875 - accuracy: 0.6005 - val_loss: 0.2884 - val_accuracy: 0.9963\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.6527 - accuracy: 0.7411 - val_loss: 0.1940 - val_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.4675 - accuracy: 0.8303 - val_loss: 0.1427 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.3616 - accuracy: 0.8816 - val_loss: 0.1097 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.2668 - accuracy: 0.9244 - val_loss: 0.0877 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.2109 - accuracy: 0.9471 - val_loss: 0.0721 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.1792 - accuracy: 0.9586 - val_loss: 0.0601 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.1499 - accuracy: 0.9670 - val_loss: 0.0510 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.1292 - accuracy: 0.9733 - val_loss: 0.0440 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.1059 - accuracy: 0.9808 - val_loss: 0.0384 - val_accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 49s 211ms/step - loss: 0.0239 - accuracy: 0.9937 - val_loss: 5.1466e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 5.6441e-04 - accuracy: 0.9998 - val_loss: 0.0029 - val_accuracy: 0.9963\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 1.5704e-04 - accuracy: 1.0000 - val_loss: 0.0035 - val_accuracy: 0.9963\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 7.9284e-05 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9963\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.0059 - accuracy: 0.9998 - val_loss: 0.0234 - val_accuracy: 0.9963\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 1.3496e-04 - accuracy: 1.0000 - val_loss: 0.0278 - val_accuracy: 0.9963\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 3.6089e-04 - accuracy: 0.9998 - val_loss: 0.0293 - val_accuracy: 0.9963\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 2.3294e-05 - accuracy: 1.0000 - val_loss: 0.0317 - val_accuracy: 0.9963\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 2.0123e-04 - accuracy: 1.0000 - val_loss: 0.0336 - val_accuracy: 0.9963\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 1.0010e-05 - accuracy: 1.0000 - val_loss: 0.0348 - val_accuracy: 0.9963\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 3.2073e-05 - accuracy: 1.0000 - val_loss: 0.0359 - val_accuracy: 0.9963\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 46s 210ms/step - loss: 0.0527 - accuracy: 0.9910 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 6.8492e-04 - accuracy: 0.9998 - val_loss: 0.0306 - val_accuracy: 0.9963\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 0.0011 - accuracy: 0.9995 - val_loss: 0.0259 - val_accuracy: 0.9926\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 3.1342e-05 - accuracy: 1.0000 - val_loss: 9.3601e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 1.2407e-05 - accuracy: 1.0000 - val_loss: 0.0033 - val_accuracy: 0.9963\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0037 - accuracy: 0.9997 - val_loss: 7.4506e-09 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0045 - accuracy: 0.9997 - val_loss: 0.0336 - val_accuracy: 0.9926\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0118 - accuracy: 0.9992 - val_loss: 0.0484 - val_accuracy: 0.9926\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 2.1227e-05 - accuracy: 1.0000 - val_loss: 0.0242 - val_accuracy: 0.9963\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0020 - accuracy: 0.9997 - val_loss: 6.4720e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 3.0914e-04 - accuracy: 0.9998 - val_loss: 0.0137 - val_accuracy: 0.9963\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 50s 211ms/step - loss: 1.7891 - accuracy: 0.4540 - val_loss: 0.3461 - val_accuracy: 0.9816\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.7923 - accuracy: 0.7125 - val_loss: 0.1686 - val_accuracy: 0.9963\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.5121 - accuracy: 0.8216 - val_loss: 0.1048 - val_accuracy: 0.9963\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.3595 - accuracy: 0.8832 - val_loss: 0.0744 - val_accuracy: 0.9963\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.2504 - accuracy: 0.9216 - val_loss: 0.0572 - val_accuracy: 0.9963\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.1906 - accuracy: 0.9508 - val_loss: 0.0465 - val_accuracy: 0.9963\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.1530 - accuracy: 0.9613 - val_loss: 0.0389 - val_accuracy: 0.9963\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.1212 - accuracy: 0.9717 - val_loss: 0.0335 - val_accuracy: 0.9963\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.1013 - accuracy: 0.9802 - val_loss: 0.0294 - val_accuracy: 0.9963\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0913 - accuracy: 0.9814 - val_loss: 0.0264 - val_accuracy: 0.9963\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0723 - accuracy: 0.9862 - val_loss: 0.0238 - val_accuracy: 0.9963\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 49s 213ms/step - loss: 0.0243 - accuracy: 0.9937 - val_loss: 0.0252 - val_accuracy: 0.9890\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 207ms/step - loss: 1.3960e-04 - accuracy: 1.0000 - val_loss: 0.0256 - val_accuracy: 0.9890\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 3.8732e-05 - accuracy: 1.0000 - val_loss: 0.0481 - val_accuracy: 0.9890\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 208ms/step - loss: 1.6857e-05 - accuracy: 1.0000 - val_loss: 0.0502 - val_accuracy: 0.9890\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 1.5248e-05 - accuracy: 1.0000 - val_loss: 0.0494 - val_accuracy: 0.9890\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 8.2752e-05 - accuracy: 1.0000 - val_loss: 0.0483 - val_accuracy: 0.9890\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 1.6366e-04 - accuracy: 0.9998 - val_loss: 0.0201 - val_accuracy: 0.9926\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 9.0079e-06 - accuracy: 1.0000 - val_loss: 0.0197 - val_accuracy: 0.9926\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 1.3890e-06 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9926\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 3.7682e-04 - accuracy: 0.9998 - val_loss: 0.0195 - val_accuracy: 0.9926\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 1.0851e-06 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 0.9926\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 2.3153e-07 - accuracy: 1.0000 - val_loss: 0.0164 - val_accuracy: 0.9926\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 48s 213ms/step - loss: 0.0334 - accuracy: 0.9922 - val_loss: 9.1585e-04 - val_accuracy: 1.0000\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 1.1623e-05 - accuracy: 1.0000 - val_loss: 1.1093e-04 - val_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 2.0808e-06 - accuracy: 1.0000 - val_loss: 4.8294e-05 - val_accuracy: 1.0000\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 1.8581e-07 - accuracy: 1.0000 - val_loss: 2.2738e-05 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 1.8881e-06 - accuracy: 1.0000 - val_loss: 9.8579e-06 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 4.8844e-06 - accuracy: 1.0000 - val_loss: 1.5554e-05 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 1.8155e-04 - accuracy: 1.0000 - val_loss: 0.0330 - val_accuracy: 0.9926\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 2.7794e-06 - accuracy: 1.0000 - val_loss: 0.0128 - val_accuracy: 0.9963\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 9.9103e-05 - accuracy: 1.0000 - val_loss: 0.0416 - val_accuracy: 0.9963\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0493 - val_accuracy: 0.9926\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 9.4174e-05 - accuracy: 1.0000 - val_loss: 0.0699 - val_accuracy: 0.9926\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 50s 213ms/step - loss: 1.6156 - accuracy: 0.4490 - val_loss: 0.3938 - val_accuracy: 0.9890\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 207ms/step - loss: 0.7014 - accuracy: 0.7337 - val_loss: 0.2056 - val_accuracy: 0.9963\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.4408 - accuracy: 0.8571 - val_loss: 0.1269 - val_accuracy: 0.9963\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.2811 - accuracy: 0.9194 - val_loss: 0.0867 - val_accuracy: 0.9963\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.2036 - accuracy: 0.9502 - val_loss: 0.0634 - val_accuracy: 0.9963\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.1590 - accuracy: 0.9671 - val_loss: 0.0486 - val_accuracy: 0.9963\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.1260 - accuracy: 0.9740 - val_loss: 0.0390 - val_accuracy: 0.9963\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0946 - accuracy: 0.9849 - val_loss: 0.0321 - val_accuracy: 0.9963\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0818 - accuracy: 0.9883 - val_loss: 0.0275 - val_accuracy: 0.9963\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0650 - accuracy: 0.9940 - val_loss: 0.0239 - val_accuracy: 0.9963\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0560 - accuracy: 0.9938 - val_loss: 0.0211 - val_accuracy: 0.9963\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 50s 210ms/step - loss: 0.0485 - accuracy: 0.9862 - val_loss: 0.0285 - val_accuracy: 0.9926\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 7.8416e-04 - accuracy: 0.9998 - val_loss: 0.0262 - val_accuracy: 0.9926\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 7.8455e-04 - accuracy: 0.9998 - val_loss: 0.0335 - val_accuracy: 0.9926\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 4.5542e-04 - accuracy: 1.0000 - val_loss: 0.0362 - val_accuracy: 0.9926\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0386 - val_accuracy: 0.9926\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 5.6187e-04 - accuracy: 0.9998 - val_loss: 0.0398 - val_accuracy: 0.9926\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 3.0673e-04 - accuracy: 1.0000 - val_loss: 0.0414 - val_accuracy: 0.9926\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 6.4199e-04 - accuracy: 0.9998 - val_loss: 0.0597 - val_accuracy: 0.9926\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0113 - val_accuracy: 0.9926\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 1.3883e-04 - accuracy: 1.0000 - val_loss: 0.0188 - val_accuracy: 0.9926\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 1.4572e-04 - accuracy: 0.9998 - val_loss: 0.0202 - val_accuracy: 0.9926\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 45s 207ms/step - loss: 0.0767 - accuracy: 0.9883 - val_loss: 0.0735 - val_accuracy: 0.9926\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.1165 - val_accuracy: 0.9926\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 25s 199ms/step - loss: 0.0146 - accuracy: 0.9987 - val_loss: 0.1180 - val_accuracy: 0.9926\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.1504 - val_accuracy: 0.9926\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 0.1192 - val_accuracy: 0.9816\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 2.3065e-04 - accuracy: 1.0000 - val_loss: 0.0814 - val_accuracy: 0.9926\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 5.2775e-05 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 1.3450e-05 - accuracy: 1.0000 - val_loss: 0.0382 - val_accuracy: 0.9963\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 6.7439e-04 - accuracy: 0.9998 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 25s 201ms/step - loss: 1.0657e-04 - accuracy: 1.0000 - val_loss: 0.0760 - val_accuracy: 0.9926\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 0.0243 - accuracy: 0.9992 - val_loss: 0.0469 - val_accuracy: 0.9963\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 1.2731e-04 - accuracy: 1.0000 - val_loss: 1.9722e-07 - val_accuracy: 1.0000\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 51s 210ms/step - loss: 2.3830 - accuracy: 0.3314 - val_loss: 0.7581 - val_accuracy: 0.7316\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 1.7694 - accuracy: 0.4440 - val_loss: 0.4965 - val_accuracy: 0.9559\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 1.3796 - accuracy: 0.5140 - val_loss: 0.3533 - val_accuracy: 0.9926\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 1.1522 - accuracy: 0.5762 - val_loss: 0.2646 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.9670 - accuracy: 0.6279 - val_loss: 0.2043 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.7887 - accuracy: 0.6941 - val_loss: 0.1631 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.6826 - accuracy: 0.7378 - val_loss: 0.1333 - val_accuracy: 1.0000\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.5927 - accuracy: 0.7790 - val_loss: 0.1110 - val_accuracy: 1.0000\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.5056 - accuracy: 0.8108 - val_loss: 0.0934 - val_accuracy: 1.0000\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.4439 - accuracy: 0.8317 - val_loss: 0.0804 - val_accuracy: 0.9963\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.4046 - accuracy: 0.8556 - val_loss: 0.0698 - val_accuracy: 0.9963\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 50s 210ms/step - loss: 0.0396 - accuracy: 0.9913 - val_loss: 0.0518 - val_accuracy: 0.9926\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.0045 - accuracy: 0.9995 - val_loss: 0.0483 - val_accuracy: 0.9926\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0109 - accuracy: 0.9994 - val_loss: 0.0456 - val_accuracy: 0.9926\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 1.5320e-04 - accuracy: 1.0000 - val_loss: 0.0340 - val_accuracy: 0.9926\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 1.5453e-04 - accuracy: 1.0000 - val_loss: 0.0238 - val_accuracy: 0.9926\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 1.3748e-04 - accuracy: 1.0000 - val_loss: 0.0167 - val_accuracy: 0.9926\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.0221 - val_accuracy: 0.9926\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 1.3543e-04 - accuracy: 1.0000 - val_loss: 0.0152 - val_accuracy: 0.9926\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 1.4610e-04 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 0.9963\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 6.4768e-05 - accuracy: 1.0000 - val_loss: 0.0131 - val_accuracy: 0.9963\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 2.0410e-04 - accuracy: 0.9998 - val_loss: 0.0178 - val_accuracy: 0.9926\n",
            "Epoch 12/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0144 - val_accuracy: 0.9926\n",
            "Epoch 13/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 4.7881e-05 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9963\n",
            "Epoch 14/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 2.1918e-05 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9963\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 45s 209ms/step - loss: 0.2339 - accuracy: 0.9895 - val_loss: 0.0231 - val_accuracy: 0.9926\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.0128 - accuracy: 0.9990 - val_loss: 0.0218 - val_accuracy: 0.9926\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 25s 200ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.3097 - val_accuracy: 0.9853\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0136 - accuracy: 0.9989 - val_loss: 4.2862e-07 - val_accuracy: 1.0000\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 1.9757e-05 - accuracy: 1.0000 - val_loss: 0.0000e+00 - val_accuracy: 1.0000\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0044 - accuracy: 0.9997 - val_loss: 0.0900 - val_accuracy: 0.9890\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0260 - accuracy: 0.9998 - val_loss: 0.0781 - val_accuracy: 0.9890\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0106 - accuracy: 0.9994 - val_loss: 0.1420 - val_accuracy: 0.9926\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 7.8878e-06 - accuracy: 1.0000 - val_loss: 0.1293 - val_accuracy: 0.9926\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 2.1464e-05 - accuracy: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9926\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 52s 211ms/step - loss: 2.7061 - accuracy: 0.3213 - val_loss: 0.3936 - val_accuracy: 0.9890\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 1.7668 - accuracy: 0.4725 - val_loss: 0.1957 - val_accuracy: 1.0000\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 1.2356 - accuracy: 0.5895 - val_loss: 0.1283 - val_accuracy: 0.9963\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.9636 - accuracy: 0.6646 - val_loss: 0.0944 - val_accuracy: 0.9963\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.7422 - accuracy: 0.7384 - val_loss: 0.0743 - val_accuracy: 0.9963\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.5779 - accuracy: 0.7956 - val_loss: 0.0613 - val_accuracy: 0.9963\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.4907 - accuracy: 0.8313 - val_loss: 0.0522 - val_accuracy: 0.9963\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.4286 - accuracy: 0.8498 - val_loss: 0.0455 - val_accuracy: 0.9963\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.3521 - accuracy: 0.8768 - val_loss: 0.0407 - val_accuracy: 0.9963\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.3028 - accuracy: 0.8959 - val_loss: 0.0371 - val_accuracy: 0.9963\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.2559 - accuracy: 0.9168 - val_loss: 0.0341 - val_accuracy: 0.9963\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 49s 213ms/step - loss: 0.0389 - accuracy: 0.9921 - val_loss: 0.0293 - val_accuracy: 0.9926\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 207ms/step - loss: 2.0899e-04 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.9890\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0093 - val_accuracy: 0.9963\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 7.1859e-05 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 0.9963\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 5.3716e-04 - accuracy: 0.9997 - val_loss: 0.0069 - val_accuracy: 0.9963\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 5.2566e-05 - accuracy: 1.0000 - val_loss: 0.0061 - val_accuracy: 0.9963\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 1.3702e-04 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9963\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0071 - val_accuracy: 0.9963\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 2.3896e-04 - accuracy: 1.0000 - val_loss: 0.0186 - val_accuracy: 0.9963\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 1.4582e-05 - accuracy: 1.0000 - val_loss: 0.0173 - val_accuracy: 0.9963\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 5.8258e-04 - accuracy: 0.9998 - val_loss: 0.0055 - val_accuracy: 0.9963\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 48s 212ms/step - loss: 0.1481 - accuracy: 0.9881 - val_loss: 0.0672 - val_accuracy: 0.9926\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 0.0062 - accuracy: 0.9994 - val_loss: 0.2512 - val_accuracy: 0.9926\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 1.8224e-05 - accuracy: 1.0000 - val_loss: 0.2069 - val_accuracy: 0.9963\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 1.2983e-04 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9963\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 3.3202e-04 - accuracy: 0.9998 - val_loss: 0.2280 - val_accuracy: 0.9890\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.0271 - val_accuracy: 0.9963\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0029 - accuracy: 0.9998 - val_loss: 0.7784 - val_accuracy: 0.9816\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 2.5901e-05 - accuracy: 1.0000 - val_loss: 0.7770 - val_accuracy: 0.9890\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 2.9599e-05 - accuracy: 1.0000 - val_loss: 0.6121 - val_accuracy: 0.9853\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 205ms/step - loss: 5.5787e-05 - accuracy: 1.0000 - val_loss: 0.5782 - val_accuracy: 0.9926\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 6.7412e-05 - accuracy: 1.0000 - val_loss: 0.3091 - val_accuracy: 0.9926\n",
            "Epoch 1/100\n",
            "126/126 [==============================] - 51s 221ms/step - loss: 2.4325 - accuracy: 0.3487 - val_loss: 0.4069 - val_accuracy: 0.9779\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - 26s 208ms/step - loss: 1.4060 - accuracy: 0.5473 - val_loss: 0.1857 - val_accuracy: 0.9926\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.9514 - accuracy: 0.6727 - val_loss: 0.1127 - val_accuracy: 0.9926\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.6408 - accuracy: 0.7770 - val_loss: 0.0803 - val_accuracy: 0.9926\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 207ms/step - loss: 0.4873 - accuracy: 0.8298 - val_loss: 0.0629 - val_accuracy: 0.9926\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.3862 - accuracy: 0.8651 - val_loss: 0.0527 - val_accuracy: 0.9926\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.3102 - accuracy: 0.8940 - val_loss: 0.0462 - val_accuracy: 0.9926\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.2497 - accuracy: 0.9137 - val_loss: 0.0418 - val_accuracy: 0.9926\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.1946 - accuracy: 0.9348 - val_loss: 0.0388 - val_accuracy: 0.9926\n",
            "Epoch 10/100\n",
            "126/126 [==============================] - 26s 206ms/step - loss: 0.1772 - accuracy: 0.9470 - val_loss: 0.0365 - val_accuracy: 0.9926\n",
            "Epoch 11/100\n",
            "126/126 [==============================] - 26s 207ms/step - loss: 0.1559 - accuracy: 0.9498 - val_loss: 0.0347 - val_accuracy: 0.9926\n"
          ]
        }
      ],
      "source": [
        "mejores_metricas = obtener_mejores_metricas(rangos_drop=[0.3,0.4,0.5,0.6,0.7], rangos_neu=[300,400,600], rangos_opt=[\"Adamax\",\"RMSprop\",\"adadelta\"],callbacks=callbacks3,mod=MobileNet)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R5eXggOM3SGp",
        "outputId": "5db8d563-3e5d-4f8a-9e95-bac94b55748b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['0.0', '0.0', '0.0', '0.0'],\n",
              "       ['0.3', '300', 'Adamax', '0.9963235259056091'],\n",
              "       ['0.3', '300', 'adadelta', '1.0'],\n",
              "       ['0.3', '400', 'Adamax', '1.0'],\n",
              "       ['0.3', '400', 'adadelta', '0.9963235259056091'],\n",
              "       ['0.3', '600', 'Adamax', '1.0'],\n",
              "       ['0.3', '600', 'RMSprop', '0.9816176295280457'],\n",
              "       ['0.3', '600', 'adadelta', '1.0'],\n",
              "       ['0.4', '300', 'Adamax', '1.0'],\n",
              "       ['0.4', '300', 'RMSprop', '0.9889705777168274'],\n",
              "       ['0.4', '300', 'adadelta', '0.9889705777168274'],\n",
              "       ['0.4', '400', 'Adamax', '0.9926470518112183'],\n",
              "       ['0.4', '400', 'RMSprop', '0.9926470518112183'],\n",
              "       ['0.4', '400', 'adadelta', '1.0'],\n",
              "       ['0.4', '600', 'Adamax', '0.9963235259056091'],\n",
              "       ['0.4', '600', 'RMSprop', '0.9963235259056091'],\n",
              "       ['0.4', '600', 'adadelta', '0.9963235259056091'],\n",
              "       ['0.5', '300', 'Adamax', '1.0'],\n",
              "       ['0.5', '300', 'RMSprop', '0.9926470518112183'],\n",
              "       ['0.5', '300', 'adadelta', '0.9926470518112183'],\n",
              "       ['0.5', '400', 'Adamax', '0.9926470518112183'],\n",
              "       ['0.5', '400', 'RMSprop', '0.9963235259056091'],\n",
              "       ['0.5', '400', 'adadelta', '0.9926470518112183'],\n",
              "       ['0.5', '600', 'Adamax', '0.9963235259056091'],\n",
              "       ['0.5', '600', 'RMSprop', '0.9889705777168274'],\n",
              "       ['0.5', '600', 'adadelta', '0.9889705777168274'],\n",
              "       ['0.6', '300', 'Adamax', '0.9963235259056091'],\n",
              "       ['0.6', '300', 'RMSprop', '1.0'],\n",
              "       ['0.6', '300', 'adadelta', '1.0'],\n",
              "       ['0.6', '400', 'Adamax', '0.9963235259056091'],\n",
              "       ['0.6', '400', 'RMSprop', '0.9963235259056091'],\n",
              "       ['0.6', '400', 'adadelta', '0.9963235259056091'],\n",
              "       ['0.6', '600', 'Adamax', '0.9926470518112183'],\n",
              "       ['0.6', '600', 'RMSprop', '0.9926470518112183'],\n",
              "       ['0.6', '600', 'adadelta', '0.9963235259056091'],\n",
              "       ['0.7', '300', 'Adamax', '0.9926470518112183'],\n",
              "       ['0.7', '300', 'RMSprop', '1.0'],\n",
              "       ['0.7', '300', 'adadelta', '0.9963235259056091'],\n",
              "       ['0.7', '400', 'Adamax', '0.9963235259056091'],\n",
              "       ['0.7', '400', 'RMSprop', '0.9926470518112183'],\n",
              "       ['0.7', '400', 'adadelta', '0.9963235259056091'],\n",
              "       ['0.7', '600', 'Adamax', '0.9963235259056091'],\n",
              "       ['0.7', '600', 'RMSprop', '0.9926470518112183'],\n",
              "       ['0.7', '600', 'adadelta', '0.9926470518112183']], dtype='<U32')"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "mejores_metricas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXXE0bw9IhDe"
      },
      "outputs": [],
      "source": [
        "final=g.time()\n",
        "print(f\"Tiempo total de  busqueda por rejilla MobileNet: {final-inicio} Seg\",)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cb_vTVGs2ui"
      },
      "outputs": [],
      "source": [
        "#guardar los resultados al archivo de txt\n",
        "file = open(Guardar_CNNMobilNetV2+\"/resultados_de_busqueda_por_rejilla.txt\", \"w+\")\n",
        "content = str(mejores_metricas)\n",
        "file.write(content)\n",
        "file.close()\n",
        "\n",
        "\n",
        "\n",
        "# Obtener el índice de la fila con el máximo valor de accuracy\n",
        "max_index = np.argmax(mejores_metricas[:, -1])\n",
        "\n",
        "# Obtener los parámetros correspondientes a la fila con el máximo valor de accuracy\n",
        "dropout_max = float(mejores_metricas[max_index, 0])\n",
        "neuronas_max = int(mejores_metricas[max_index, 1])\n",
        "optimizador_max = str(mejores_metricas[max_index, 2])\n",
        "\n",
        "# Recuperamos un modelo CNN estandar con la función VGG() con los parámetros correspondientes al máximo valor de accuracy\n",
        "modelo_MobileNet = MobileNet(dropout1=dropout_max,dropout2=dropout_max+0.1,neuronas=neuronas_max,optimizador=optimizador_max)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NhklgX3s2uj",
        "outputId": "35449434-2e78-49ca-ae57-64b89b043837"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.9033 - accuracy: 0.6683"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r126/126 [==============================] - 74s 407ms/step - loss: 0.9033 - accuracy: 0.6683 - val_loss: 0.2917 - val_accuracy: 0.9779\n",
            "Epoch 2/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.2834 - accuracy: 0.9717"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r126/126 [==============================] - 50s 398ms/step - loss: 0.2834 - accuracy: 0.9717 - val_loss: 0.1188 - val_accuracy: 0.9853\n",
            "Epoch 3/100\n",
            "126/126 [==============================] - ETA: 0s - loss: 0.1406 - accuracy: 0.9944"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 52). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r126/126 [==============================] - 50s 397ms/step - loss: 0.1406 - accuracy: 0.9944 - val_loss: 0.0708 - val_accuracy: 0.9926\n",
            "Epoch 4/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.0825 - accuracy: 0.9981 - val_loss: 0.0521 - val_accuracy: 0.9926\n",
            "Epoch 5/100\n",
            "126/126 [==============================] - 26s 204ms/step - loss: 0.0535 - accuracy: 0.9986 - val_loss: 0.0429 - val_accuracy: 0.9926\n",
            "Epoch 6/100\n",
            "126/126 [==============================] - 26s 201ms/step - loss: 0.0369 - accuracy: 0.9998 - val_loss: 0.0378 - val_accuracy: 0.9926\n",
            "Epoch 7/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0295 - accuracy: 0.9997 - val_loss: 0.0347 - val_accuracy: 0.9926\n",
            "Epoch 8/100\n",
            "126/126 [==============================] - 26s 203ms/step - loss: 0.0235 - accuracy: 0.9995 - val_loss: 0.0327 - val_accuracy: 0.9926\n",
            "Epoch 9/100\n",
            "126/126 [==============================] - 26s 202ms/step - loss: 0.0193 - accuracy: 0.9998 - val_loss: 0.0314 - val_accuracy: 0.9926\n"
          ]
        }
      ],
      "source": [
        "#Entrenamos nuevamente el modelo para obtener las metricas\n",
        "\"\"\"CUANDO EXISTÁN DOS MODELOS ÓPTIMOS CON MISMO ACC: Antes de ejecutar el siguiente código verifique que la carpeta de guardado(Guardar_CNNMobilNetV2) esté vacÍa de lo contrario el modelo\n",
        "y los resultados se mostrarán en funcion del último modelo guardado en lugar del siguiente.\n",
        "\"\"\"\n",
        "history = modelo_MobileNet.fit(train_dataset, epochs=100, validation_data=validation_dataset, callbacks=callbacks3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajgX6op2s2uj",
        "outputId": "df983f3b-007b-42bb-e2e4-0bebb59b773b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 32s 1s/step - loss: 0.0520 - accuracy: 1.0000\n",
            "Test ACC : 1.000\n"
          ]
        }
      ],
      "source": [
        "#EVALUACION FINAL DEL MODELO VGG para determinar su ACC global\n",
        "\n",
        "test_model_mobilenet = keras.models.load_model(Guardar_CNNMobilNetV2)\n",
        "test_loss, test_acc = test_model_mobilenet.evaluate(test_dataset)\n",
        "print(f\"Test ACC : {test_acc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "id": "9YAwHDDYs2uj",
        "outputId": "304824d8-be87-41a7-9103-f244717d7f54"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "graficar_curva_aprendizaje(history,plt=plt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55UY1cl8s2uj",
        "outputId": "7903b4e2-bb9b-4a2d-d154-2d27ed639bea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27/27 [==============================] - 2s 16ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "actual, predicted = get_actual_predicted_labels(dataset=test_dataset,model=test_model_mobilenet)\n",
        "graficar_matriz_confusion(actual, predicted, test_dataset.class_names)\n",
        "#print(actual,predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZensCW1Vs2uj",
        "outputId": "76e76023-3311-4e06-da7f-867022202b80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultado F1_Score: {'angular_leafspot': 1.0, 'hojas_sanas': 1.0, 'leaf_spot': 1.0, 'powdery_mildew': 1.0}\n"
          ]
        }
      ],
      "source": [
        "precision, recall = calcular_precision_recall(actual, predicted, test_dataset.class_names)\n",
        "resultadosf1=calcular_f1_score(precision, recall)\n",
        "print(\"Resultado Precisión: {}\".format(precision))\n",
        "print(\"Resultado Recall: {}\".format( recall))\n",
        "print(\"Resultado F1_Score: {}\".format(resultadosf1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTjnPRnxs2uj",
        "outputId": "ba6023a3-7883-4eb2-8c90-135938687c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Promedio: 1.0\n"
          ]
        }
      ],
      "source": [
        "valores = list(resultadosf1.values())\n",
        "promedio = statistics.mean(valores)\n",
        "print(\"Promedio:\", promedio)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}